## 提要  
1. 深度学习的介绍
2. TensorFlow 框架的介绍
    1. TensorFlow 的结构
    2. 介绍 TensorFlow 的各个组件
        1. 图
        2. 绘画
        3. 张量
        4. 变量
    3. 具体的案例（线性回归的案例）-将 TensorFlow 用起来

## 深度学习介绍  
### 深度学习和机器学习的区别  
#### 特征提取  
![](png/Pasted%20image%2020250909220419.png)  
上面是机器学习：特征提取（特征工程）->算法学习——>输出  
下面是深度学习：自己进行特征的提取和分类算法的步骤  

- 机器学习的特征工程步骤是要靠手动来完成的，而且需要大量的领域专业知识
- 深度学习通过学习大量数据自动得出模型，不需要人工

#### 数据量

!!! tip "说明"  
1. 深度学习需要大量的训练数据集
2. 训练深度神经网络需要大量的算力
- 需要强大的 GPU 服务器进行计算
- 全面管理的分布式训练与预测服务

数据量越大，深度学习的优势越大  

#### 算法代表  
- 机器学习：
    - 朴素贝叶斯、决策树
- 深度学习
    - 神经网络

### 应用场景  
- 图像书别
- 自然语言处理
- 语音技术

### 深度学习框架  
#### 常见的框架的对比  

|    框架名     |  主语言   |        从语言         | 灵活性 | 上手难易 |   开发者    |     |
| :--------: | :----: | :----------------: | :-: | :--: | :------: | --- |
| Tensorflow |  C++   |    cuda/python     |  好  |  难   |  Google  |     |
|   Caffe    |  C++   | cuda/python/Matlab | 一般  |  中等  |   贾杨清    |     |
|  PyTorch   | python |       C/C++        |  好  |  中等  | FaceBook |     |
|   MXNet    |  c++   |    cuda/R/julia    |  好  |  中等  | 李沐和陈天奇等  |     |
|   Torch    |  lua   |       C/cuda       |  好  |  中等  | Facebook |     |
|   Theano   | python |      C++/cuda      |  好  |  易   | 蒙特利尔理工学院 |     |

- PyTorch 更加使用于学术研究，Tensorflow 更适用于工业界生产环境的部署

#### Tensorflow 的特点  
- 高度灵活
- 语言多样
    - 是使用 c++实现的，使用 Python 进行封装
- 设备支持
    - 可以运行在各种的硬件上
- TensorFlow 的可视化

#### 安装  
- CPU 版本
- GPU 版本  
    CPU：诸葛亮  
    综合能力比较强——计算、综合的调动能力  
    但是核心数比较少，适合处理连续型的任务  
    GPU：臭皮匠  
    专攻某一个能力，专做某一个能力比较好，只能进行运算  
    核芯数更多，但每一个核芯速度较慢，更适用于并行的任务

我们现在用的的先是 CPU 版本  
![](png/Pasted%20image%2020250909231224.png)  
虚拟环境  

![](png/Pasted%20image%2020250909233743.png)  
在 pycharm 的设置这里修改解释器用哪个  

代码：  
```Python
import tensorflow.compat.v1 as tf  
tf.compat.v1.disable_eager_execution()  
def ten_demo():  
    """  
    基本结构  
    :return:    """    a=2  
    b=3  
    c=a+b  
    print("普通加法运算的结果:\n",c)  
  
    # TF实现（图）  
    a_t=tf.constant(2)  
    b_t=tf.constant(3)  
    c_t=a_t+b_t  
    print("新的结果:\n",c_t)  
    # 开启会话  
    with tf.Session() as sess:  
        c_t_value=sess.run(c_t)  
        print("c:\n",c_t_value)  
    return None  
  
# 1. 基本结构  
ten_demo()
```

这是 1. x 版本的写法  
我们现在用的是先构件流程图，之后需要调用进行操作执行  

#### 结构分析  
组织成一个构件图阶段和执行图阶段  
构建阶段：数据和操作的执行步骤被描述成一个图  
执行阶段：使用会话执行构建好的图中的操作  

- 图和会话：
    - 图：将计算表示为指令直降的依赖关系
    - 会话：运行流图的机制
- 张量：TF 中的基本数据对象
- 节点：提供图当中执行的操作

## TensorFlow 框架介绍
### 数据流图的介绍  
TensorFlow  
Tensor: 张量——数据  
Flow：流动  

- 构建图阶段：
    - 流程图：定义数据（张量 Tensor）和操作 (节点 Op)
- 执行图阶段：
    - 调用各方资源，将定义好的数据和操作运行起来

### 图与 TensorBoard  
#### 什么是图结构  
- 图结构：  
    数据（Tensor）+操作（Operation）

#### 图的相关操作  
1. 默认图  
    怎么查看默认的图
    1.  调用方法  
        使用tf.get_default_graph() 访问  
        op\sess 都含有图属性，默认在一张图中
    2. 查看属性  
        .graph
2. 自定义图

```Python
def graph_demo():  
    """  
    查看默认的图  
    :return:    """    # 实现加法运算  
    a_t=tf.constant(2)  
    b_t=tf.constant(3)  
    c_t=a_t+b_t  
    print("新的结果:\n",c_t)  
    # 查看默认图  
    # 方法1：调用方法  
    default_g=tf.get_default_graph()  
    print("default_g:\n",default_g)  
    # 2：查看属性  
    print("a_t的图属性:\n",a_t.graph)  
    print("c_t的图属性:\n", c_t.graph)  
    # 开启会话  
    with tf.Session() as sess:  
        c_t_value=sess.run(c_t)  
        print("c:\n",c_t_value)  
        print("sessin的图属性:\n",sess.graph)  
    return None
```

输出：  

> default_g:  
 <tensorflow.python.framework.ops.Graph object at 0x0000027793B72BC0>  
a_t的图属性:  
 <tensorflow.python.framework.ops.Graph object at 0x0000027793B72BC0>  
c_t的图属性:  
 <tensorflow.python.framework.ops.Graph object at 0x0000027793B72BC0>  
c:  
 5  
sessin的图属性:  
 <tensorflow.python.framework.ops.Graph object at 0x0000027793B72BC0>

最后返回的结果就是图在的内存地址  

---
**创建图**  
`new_g=tf.Graph()`  新创建一个图  
`tf.Session()` 开启会话（括号里面没有时，默认的是开启默认图的对话）  
`with...as...` 在代码执行结束之后会话会自动关闭  
在 `with` 代码块内部（即 `sess` 作用域内），可以通过 `sess.run()` 方法执行 TensorFlow 计算图中的操作（如模型训练、预测等）  

**要想开启自创图的会话：**  
```Python
with tf.Session(graph=new_g) as new_sess:  
    c_new_value = new_sess.run(c_new)  
    print("c:\n", c_new_value)
```

必须在括号中填入想要运行的图（要设置属性）  
#### TensorBoard 的可视化学习  
1. 数据序列化-events 文件
    `tf.summary.FileWriter(path,graph=sess.graph)`
2. 启动 TensorBoard
    `TensorBoard`
    `(tf-cpu-env) PS D:\dev\pythonProject3> tensorboard --logdir="./tmp/summary"`
    ![](png/Pasted%20image%2020250910185849.png)
    图中的 const 代表操作名称（指令名称）
> a_t:  
> Tensor("Const:0", shape=(), dtype=int32)  
> b_t:  
> Tensor("Const_1:0", shape=(), dtype=int32)  

这里的 const 为创建一个常数的动作，其输出就是创建的常数，0 代表创建常数的数量为 1  
#### Op  
数据：Tensor 对象  
操作对象：Operation 对象-OP  

---
常见的 OP  

|   类型    |                            实例                            |
| :-----: | :------------------------------------------------------: |
|  标量运算   |    add, sub, mul, div, exp, log, greater, less, equal    |
|  向量运算   | concat, slice, splot, **constant**, rank, shape, shuffle |
|  矩阵运算   |         matmul, matrixinverse, matrixdeterminant         |
| 带状态的运算  |               Variable, assign, assignadd                |
| 神经网络组件  |      softmax, sigmoid, relu, convolution, max_pool       |
|  存储，恢复  |                      Save, Restore                       |
| 队列及同步运算 |       Enqueue, Dequeue, MutexAcquire, MutexRelease       |
|   控制流   |        Merge, Switch, Enter, Leave, NextIteration        |

操作函数-操作对象  
!!! tip "什么是"
    - 操作函数：
        tf. constant (Tensor)
        tf. add (Tensor 对象 1 和 Tensor 对象 2)
    - 操作对象：（相当于函数内部的一个对象，是通过操作函数创建的）
        输入 Tensor 对象->创建Const 对象->输出 Tensor 对象
        输入 Tensor 对象 1、2——>创建 Add 对象——>输出 Tensor 对象 3

!!! tip "说明"
    一个操作对象（Operation）是 TensorFlow 图中的一个节点，可以接收 0 个或者多个输入 Tensor，并且可以输出 0 个或者多个 Tensor，Operation 对象是通过 op 构造函数（如 tf.matmul ()）创建的。  
    例如：`c = tf.matmul(a, b)` 创建了一个 Operation 对象，类型为 MatMul 类型，它将张量 a、b 作为输入，c 作为输出，并且输出数据，打印的时候也是打印的数据。其中 tf.matmul () 是函数，在执行 matmul 函数的过程中会通过 MatMul 类创建一个与之对应的对象。    
所以我们返回的都是数据，中间的操作 op 看不见，但是在打印之后会看见  
`Tensor("Const_1:0", shape=(), dtype=int32)` 可见是由 const 操作函数产生的，输出的结果是有操作的名称和整数（返回数据的数目，0 代表一个）构成的  



