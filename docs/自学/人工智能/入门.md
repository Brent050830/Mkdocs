## 人工智能概述  
### 机器学习与人工智能、深度学习  
三者之间是包含与被包含的关系  

- 人工智能：最大的概念  
    最开始的时候是为了实现自动的下棋，那个时候就是人工智能了  
    在 1958 年，有最开始的人工智能的会议。
- 机器学习：实际上这个东西在上个世纪八十年代上就得到了广泛的应用
- 深度学习：在图像识别中取得了不错的效果
    - 应用在挖掘数据
    - 应用在图像的识别
    - 应用在自然语言的处理——翻译，还有很多的聊天的人工智能

### 什么是机器学习  
#### 定义  
机器学习是从**数据**中自动分析获得**模型**，并利用模型对**未知的数据进行预测**  

#### 解释  
利用以往的规律进行学习  

> [!tip] 例子  
> 比如使用人工智能识别猫和狗的照片，就是使用大量的图片进行训练得到的  
> 还有房屋价格的预测等等  

但是这些历史数据应该是怎么样的？

#### 数据集的组成  
- 结构：特征值+目标值

> [!tip] 注  
> 对于每一行数据我们可以称之为样本  
> 有些数据集可以没有目标值  

### 机器学习算法分类  
要使得机器有着识别猫和狗的能力，应该从机器中进行学习  
我们需要的也是特征值和目标值  
这里的目标值就是猫？还是狗  

---
所以这里的目标值是类别，属于**分类问题**  
但是对于房屋价格的预测，最后的目标值是一种连续型的数据，属于**回归问题**  
当我们遇到的数据集中**没有目标值**时，称为**无监督学习**  

- 监督学习
    - 分类问题
    - 回归问题
- 无监督学习

---

> [!quote] 例子  
> 预测气温是多少度，是回归问题  
> 预测明天的天气，是分类问题  
> 人脸的年龄预测：看怎么定义，可以是回归/分类  
> 人脸的识别：分类  

#### 机器学习算法的分类  
- 监督学习：
    - 分类：K-近邻、贝叶斯、决策树与随机森林、逻辑回归
    - 回归：线性回归，岭回归
- 无监督学习
    - 聚类 k-means

### 机器学习的开发流程  
!!! Tip "流程"  
    1. 获取数据  
    2. 数据处理  
    3. 特征工程  
    4. 机器学习算法训练-模型  
    5. 模型评估  
![](png/Pasted%20image%2020250731180031.png)  

### 学习框架和资料介绍  
重点的问题：  

1. 算法是核心，数据和计算是基础
2. 找准定位  
大部分复杂模型的算法设计都是算法工程师在做，实战类的书籍  

---
书籍：  
- 机器学习-周志华
- 统计学习方法-李航
- 深度学习-"花书"

#### 常见的深度学习的框架  
一般是 pytorch 和 TF 使用的多一点  

## 特征工程  
### 数据集  
#### 可用数据集   
公司内部：百度之类的  
数据接口：花钱  
数据集  

---
所以在学习阶段我们会用到哪些数据集？  
1. Sklearn
2. Kaggle
3. Ucl  
我们现在主要介绍一下 sklearn  
- Python 语言的机器学习工具
- 包括很多的知名的机器学习算法的实现
- 易于上手
- 安装 pip install Scikit-learn (在 cmd 中运行安装)（使用的是 pycharm 的话在里面的终端安装即可）
- 安装好之后直接在 python 中好像可以直接使用  
    如下的代码块

```python
# 1. 导入数据集模块
from sklearn import datasets

# 2. 加载经典数据集（以鸢尾花数据集为例）
iris = datasets.load_iris()  # 这是一个内置的小数据集，无需下载

# 3. 查看数据集内容
print("特征数据（前5行）：\n", iris.data[:5])  # 数据集的特征（输入变量）
print("\n标签数据：\n", iris.target)  # 数据集的标签（输出变量/分类结果）
print("\n特征名称：\n", iris.feature_names)  # 每个特征的名称
print("\n标签名称：\n", iris.target_names)  # 每个标签对应的类别名称
print("\n数据集描述：\n", iris.DESCR)  # 数据集的详细说明
```

> [!tip] 介绍  
> 他的文档是非常完善的  
> 可以直接在文档中进行相关的学习  
> [网址](https://scikit-learn.org.cn/)  

### 如何使用这个数据集  
#### API 介绍  
- sklearn. datasets
    - 加载获取流行数据集
    - datasets. load_\*()
        - 获取**小规模**的数据集
    - datasets. fetch_\*(data_home=None)
        - 获取**大量**的数据集，需要从网络上下载

#### 小数据集  
- datasets. load_iris ()  
    加载并返回鸢尾花数据集
- datasets. load_boston ()  
    加载并返回波士顿房价数据集

#### 大数据集  
- sklearn.datasets.fetch_20newsgroups(data_home=None,subset='train')
    - 其中的 train 为训练的数据集，还可以为test 为测试的数据集，所有的就是 all，一般选择的是这个

#### 数据集返回值  
上述的返回的数据类型都是字典类型，可以使用 `[""]` 的方式获取，或者使用`.` 的方式获取  

- data：特征数据数组
- targets：标签数组
- DERCR：数据描述
- feature_names: 特征名
- target_names：标签名

```python
from sklearn.datasets import load_iris
# 获取鸢尾花数据集
iris = load_iris()
print("鸢尾花数据集的返回值: \n", iris)
print("返回值是一个继承自字典的Bench")
print("鸢尾花的特征值:\n", iris["data"])
print("鸢尾花的目标值: \n", iris.target)
print("鸢尾花特征的名字: \n", iris.feature_names)
print("鸢尾花目标值的名字: \n", iris.target_names)
print("鸢尾花的描述: \n", iris.DESCR)
```

首先使用下面的代码**输出所有的数据**

```python
from sklearn.datasets import load_iris  
# 获取鸢尾花数据集  
  
def datasets_demo():  
    iris = load_iris()  
    print("鸢尾花数据集：\n",iris)  
    return None  
datasets_demo()
```
输出的结果为  ：  

![](png/Pasted%20image%2020250822004756.png)  

![](png/Pasted%20image%2020250822004825.png)  

---

使用  
```Python
print("查看数据集描述：\n",iris["DESCR"])
```

输出了数据集的**特征**：  

![](png/Pasted%20image%2020250822005149.png)  

> [!tip] 输出的特征  
> sepal length:   4.3  7.9   5.84   0.83    0.7826  
> sepal width:    2.0  4.4   3.05   0.43   -0.4194  
> petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)  
> petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)  

`print("查看特征值的名字,\n",iris.feature_names)`  
输出的结果就是：` ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']`  

#### 数据集的划分  
机器学习的数据集一般会分为两个部分：  
- 训练数据：用于训练、构件模型
- 测试数据：在模型检验时使用，用于评估**模型是否有效**  
划分的比例：  
- 训练集：70.75.80
- 测试集：上面的相减

---
!!! tip "划分"  
    - sklearn.model_selection.train_test_split(arrays, \*options)     
        - x 数据集的特征值  
        - y 数据集的标签值  
        - test_size：测试集的大小，一般为 float  
        - random_state：随机数种子，不同的种子生成不同的随机采样数，相同的种子采样结果相同  
        - return 训练集特征值，测试集特征值，训练集目标值，测试集目标值
```Python
from sklearn.datasets import load_iris  
from sklearn.model_selection import train_test_split  
# 获取鸢尾花数据集  
  
def datasets_demo():  
    iris = load_iris()  
    # print("鸢尾花数据集：\n",iris)  
    # print("查看数据集描述：\n",iris["DESCR"])  
    # print("查看特征值的名字,\n",iris.feature_names)  
    # 数据集划分  
    x_train,x_test,y_train,y_test=train_test_split(iris.data,iris.target,test_size=0.2)# 默认的情况下是0.25  
    print("训练集的特征值为\n",x_train,x_train.shape)# 后一个是输出数据集的行数
```

通过这种方式输出，获取测试集和训练集的特征值和标签值（就是字典的标签和特征）  

### 特征工程的介绍  
使用的**算法，特征工程**导致的效果的差别  

---
**数据和特征**决定了机器学习的上限，而**模型和算法**只是逼近这个上限  

#### 什么是特征工程  

> [!tip] 什么  
> 使用专业的背景知识和技巧处理数据，使得特征能在机器学习中更好地作用。  

使用的是：  
- sklearn：特征工程
- pandas：数据清洗、数据处理  
    包括：  
        特征抽取  
        特征预处理  
        特征降维

#### 特征提取  

> [!tip] 什么事特征提取呢  
> 有一个数据集  
> 使用机器学习算法——统计方法——数学公式（但是数学公式不能处理字符串）  
> 所以需要将**数据集中的字符串转换为数值的类型**  

---
所以需要的转换：
- 字典特征提取（特征离散化）
- 文本特征提取
- 图像特征提取（深度学习介绍的）

#### 字典特征提取  
**对字典数据进行特征值化**  

- `sklearn.feature_extraction.DictVectorizer(sparse=True,...)`
    - `vector`：（数学中向量，物理中的矢量）  
        使用矩阵进行存储（matrix），也就是使用**二维数组**进行存储  
        向量是一维数组  
        所以每一个样本就是一个向量，n 个样本就形成了举证
    - 父类：转换器类  
        DictVectorizer. fit_transform (X)：字典或者是包含字典的迭代器返回值，返回 spare 矩阵

> [!tip] 实际上  
> 就是将字典中的类别转换为 one-hot 编码

!!! tip "使用的方法"  
    1. 引入下面的：`from sklearn.feature_extraction import DictVectorizer`    抽取的代码  
    2. 加上下面的：
       
    ```Python
    def dict_demo():  
        data = [  
            {'city': '北京', 'temperature': 100},  
            {'city': '上海', 'temperature': 60},  
            {'city': '深圳', 'temperature': 30}  
        ]  
    #     1、实例化一个转化器类  
        transfer=DictVectorizer()  
        # 2、 调用fit_transform()  
        data_new=transfer.fit_transform(data)  
        print("data_new:",data_new)  
    dict_demo()
    ```  

    3.  最后的输出结果为：  
        ![](png/Pasted%20image%2020250824230413.png)  

---

为什么会出现这种结果？  
