<!DOCTYPE html><html lang=zh class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content=Brent的笔记本><meta name=author content=Brent><link href=https://brent050830.xyz/%E8%87%AA%E5%AD%A6/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E5%85%A5%E9%97%A8/ rel=canonical><link href=../../../%E5%A4%A7%E4%B8%89%E7%A7%8B%E5%86%AC/%E8%AE%BE%E8%AE%A1/%E8%AE%BE%E8%AE%A1/ rel=prev><link href=../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ rel=next><link rel=icon href=../../../None><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.20"><title>机器学习 - Brent_note</title><link rel=stylesheet href=../../../assets/stylesheets/main.e53b48f4.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><style>:root{--md-admonition-icon--note:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1%207.775V2.75C1%201.784%201.784%201%202.75%201h5.025c.464%200%20.91.184%201.238.513l6.25%206.25a1.75%201.75%200%200%201%200%202.474l-5.026%205.026a1.75%201.75%200%200%201-2.474%200l-6.25-6.25A1.75%201.75%200%200%201%201%207.775m1.5%200c0%20.066.026.13.073.177l6.25%206.25a.25.25%200%200%200%20.354%200l5.025-5.025a.25.25%200%200%200%200-.354l-6.25-6.25a.25.25%200%200%200-.177-.073H2.75a.25.25%200%200%200-.25.25ZM6%205a1%201%200%201%201%200%202%201%201%200%200%201%200-2%22/%3E%3C/svg%3E');--md-admonition-icon--abstract:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2.5%201.75v11.5c0%20.138.112.25.25.25h3.17a.75.75%200%200%201%200%201.5H2.75A1.75%201.75%200%200%201%201%2013.25V1.75C1%20.784%201.784%200%202.75%200h8.5C12.216%200%2013%20.784%2013%201.75v7.736a.75.75%200%200%201-1.5%200V1.75a.25.25%200%200%200-.25-.25h-8.5a.25.25%200%200%200-.25.25m13.274%209.537zl-4.557%204.45a.75.75%200%200%201-1.055-.008l-1.943-1.95a.75.75%200%200%201%201.062-1.058l1.419%201.425%204.026-3.932a.75.75%200%201%201%201.048%201.074M4.75%204h4.5a.75.75%200%200%201%200%201.5h-4.5a.75.75%200%200%201%200-1.5M4%207.75A.75.75%200%200%201%204.75%207h2a.75.75%200%200%201%200%201.5h-2A.75.75%200%200%201%204%207.75%22/%3E%3C/svg%3E');--md-admonition-icon--info:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M0%208a8%208%200%201%201%2016%200A8%208%200%200%201%200%208m8-6.5a6.5%206.5%200%201%200%200%2013%206.5%206.5%200%200%200%200-13M6.5%207.75A.75.75%200%200%201%207.25%207h1a.75.75%200%200%201%20.75.75v2.75h.25a.75.75%200%200%201%200%201.5h-2a.75.75%200%200%201%200-1.5h.25v-2h-.25a.75.75%200%200%201-.75-.75M8%206a1%201%200%201%201%200-2%201%201%200%200%201%200%202%22/%3E%3C/svg%3E');--md-admonition-icon--tip:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M3.499.75a.75.75%200%200%201%201.5%200v.996C5.9%202.903%206.793%203.65%207.662%204.376l.24.202c-.036-.694.055-1.422.426-2.163C9.1.873%2010.794-.045%2012.622.26%2014.408.558%2016%201.94%2016%204.25c0%201.278-.954%202.575-2.44%202.734l.146.508.065.22c.203.701.412%201.455.476%202.226.142%201.707-.4%203.03-1.487%203.898C11.714%2014.671%2010.27%2015%208.75%2015h-6a.75.75%200%200%201%200-1.5h1.376a4.5%204.5%200%200%201-.563-1.191%203.84%203.84%200%200%201-.05-2.063%204.65%204.65%200%200%201-2.025-.293.75.75%200%200%201%20.525-1.406c1.357.507%202.376-.006%202.698-.318l.009-.01a.747.747%200%200%201%201.06%200%20.75.75%200%200%201-.012%201.074c-.912.92-.992%201.835-.768%202.586.221.74.745%201.337%201.196%201.621H8.75c1.343%200%202.398-.296%203.074-.836.635-.507%201.036-1.31.928-2.602-.05-.603-.216-1.224-.422-1.93l-.064-.221c-.12-.407-.246-.84-.353-1.29a2.4%202.4%200%200%201-.507-.441%203.1%203.1%200%200%201-.633-1.248.75.75%200%200%201%201.455-.364c.046.185.144.436.31.627.146.168.353.305.712.305.738%200%201.25-.615%201.25-1.25%200-1.47-.95-2.315-2.123-2.51-1.172-.196-2.227.387-2.706%201.345-.46.92-.27%201.774.019%203.062l.042.19.01.05c.348.443.666.949.94%201.553a.75.75%200%201%201-1.365.62c-.553-1.217-1.32-1.94-2.3-2.768L6.7%205.527c-.814-.68-1.75-1.462-2.692-2.619a3.7%203.7%200%200%200-1.023.88c-.406.495-.663%201.036-.722%201.508.116.122.306.21.591.239.388.038.797-.06%201.032-.19a.75.75%200%200%201%20.728%201.31c-.515.287-1.23.439-1.906.373-.682-.067-1.473-.38-1.879-1.193L.75%205.677V5.5c0-.984.48-1.94%201.077-2.664.46-.559%201.05-1.055%201.673-1.353z%22/%3E%3C/svg%3E');--md-admonition-icon--success:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M13.78%204.22a.75.75%200%200%201%200%201.06l-7.25%207.25a.75.75%200%200%201-1.06%200L2.22%209.28a.75.75%200%200%201%20.018-1.042.75.75%200%200%201%201.042-.018L6%2010.94l6.72-6.72a.75.75%200%200%201%201.06%200%22/%3E%3C/svg%3E');--md-admonition-icon--question:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M0%208a8%208%200%201%201%2016%200A8%208%200%200%201%200%208m8-6.5a6.5%206.5%200%201%200%200%2013%206.5%206.5%200%200%200%200-13M6.92%206.085h.001a.749.749%200%201%201-1.342-.67c.169-.339.436-.701.849-.977C6.845%204.16%207.369%204%208%204a2.76%202.76%200%200%201%201.637.525c.503.377.863.965.863%201.725%200%20.448-.115.83-.329%201.15-.205.307-.47.513-.692.662-.109.072-.22.138-.313.195l-.006.004a6%206%200%200%200-.26.16%201%201%200%200%200-.276.245.75.75%200%200%201-1.248-.832c.184-.264.42-.489.692-.661q.154-.1.313-.195l.007-.004c.1-.061.182-.11.258-.161a1%201%200%200%200%20.277-.245C8.96%206.514%209%206.427%209%206.25a.61.61%200%200%200-.262-.525A1.27%201.27%200%200%200%208%205.5c-.369%200-.595.09-.74.187a1%201%200%200%200-.34.398M9%2011a1%201%200%201%201-2%200%201%201%200%200%201%202%200%22/%3E%3C/svg%3E');--md-admonition-icon--warning:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M6.457%201.047c.659-1.234%202.427-1.234%203.086%200l6.082%2011.378A1.75%201.75%200%200%201%2014.082%2015H1.918a1.75%201.75%200%200%201-1.543-2.575Zm1.763.707a.25.25%200%200%200-.44%200L1.698%2013.132a.25.25%200%200%200%20.22.368h12.164a.25.25%200%200%200%20.22-.368Zm.53%203.996v2.5a.75.75%200%200%201-1.5%200v-2.5a.75.75%200%200%201%201.5%200M9%2011a1%201%200%201%201-2%200%201%201%200%200%201%202%200%22/%3E%3C/svg%3E');--md-admonition-icon--failure:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M2.344%202.343za8%208%200%200%201%2011.314%2011.314A8.002%208.002%200%200%201%20.234%2010.089a8%208%200%200%201%202.11-7.746m1.06%2010.253a6.5%206.5%200%201%200%209.108-9.275%206.5%206.5%200%200%200-9.108%209.275M6.03%204.97%208%206.94l1.97-1.97a.749.749%200%200%201%201.275.326.75.75%200%200%201-.215.734L9.06%208l1.97%201.97a.749.749%200%200%201-.326%201.275.75.75%200%200%201-.734-.215L8%209.06l-1.97%201.97a.749.749%200%200%201-1.275-.326.75.75%200%200%201%20.215-.734L6.94%208%204.97%206.03a.75.75%200%200%201%20.018-1.042.75.75%200%200%201%201.042-.018%22/%3E%3C/svg%3E');--md-admonition-icon--danger:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M9.504.43a1.516%201.516%200%200%201%202.437%201.713L10.415%205.5h2.123c1.57%200%202.346%201.909%201.22%203.004l-7.34%207.142a1.25%201.25%200%200%201-.871.354h-.302a1.25%201.25%200%200%201-1.157-1.723L5.633%2010.5H3.462c-1.57%200-2.346-1.909-1.22-3.004zm1.047%201.074L3.286%208.571A.25.25%200%200%200%203.462%209H6.75a.75.75%200%200%201%20.694%201.034l-1.713%204.188%206.982-6.793A.25.25%200%200%200%2012.538%207H9.25a.75.75%200%200%201-.683-1.06l2.008-4.418.003-.006-.004-.009-.006-.006-.008-.001q-.005%200-.009.004%22/%3E%3C/svg%3E');--md-admonition-icon--bug:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M4.72.22a.75.75%200%200%201%201.06%200l1%20.999a3.5%203.5%200%200%201%202.441%200l.999-1a.748.748%200%200%201%201.265.332.75.75%200%200%201-.205.729l-.775.776c.616.63.995%201.493.995%202.444v.327q0%20.15-.025.292c.408.14.764.392%201.029.722l1.968-.787a.75.75%200%200%201%20.556%201.392L13%207.258V9h2.25a.75.75%200%200%201%200%201.5H13v.5q-.002.615-.141%201.186l2.17.868a.75.75%200%200%201-.557%201.392l-2.184-.873A5%205%200%200%201%208%2016a5%205%200%200%201-4.288-2.427l-2.183.873a.75.75%200%200%201-.558-1.392l2.17-.868A5%205%200%200%201%203%2011v-.5H.75a.75.75%200%200%201%200-1.5H3V7.258L.971%206.446a.75.75%200%200%201%20.558-1.392l1.967.787c.265-.33.62-.583%201.03-.722a1.7%201.7%200%200%201-.026-.292V4.5c0-.951.38-1.814.995-2.444L4.72%201.28a.75.75%200%200%201%200-1.06m.53%206.28a.75.75%200%200%200-.75.75V11a3.5%203.5%200%201%200%207%200V7.25a.75.75%200%200%200-.75-.75ZM6.173%205h3.654A.17.17%200%200%200%2010%204.827V4.5a2%202%200%201%200-4%200v.327c0%20.096.077.173.173.173%22/%3E%3C/svg%3E');--md-admonition-icon--example:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M5%205.782V2.5h-.25a.75.75%200%200%201%200-1.5h6.5a.75.75%200%200%201%200%201.5H11v3.282l3.666%205.76C15.619%2013.04%2014.543%2015%2012.767%2015H3.233c-1.776%200-2.852-1.96-1.899-3.458Zm-2.4%206.565a.75.75%200%200%200%20.633%201.153h9.534a.75.75%200%200%200%20.633-1.153L12.225%2010.5h-8.45ZM9.5%202.5h-3V6c0%20.143-.04.283-.117.403L4.73%209h6.54L9.617%206.403A.75.75%200%200%201%209.5%206Z%22/%3E%3C/svg%3E');--md-admonition-icon--quote:url('data:image/svg+xml;charset=utf-8,%3Csvg%20xmlns%3D%22http%3A//www.w3.org/2000/svg%22%20viewBox%3D%220%200%2016%2016%22%3E%3Cpath%20d%3D%22M1.75%202.5h10.5a.75.75%200%200%201%200%201.5H1.75a.75.75%200%200%201%200-1.5m4%205h8.5a.75.75%200%200%201%200%201.5h-8.5a.75.75%200%200%201%200-1.5m0%205h8.5a.75.75%200%200%201%200%201.5h-8.5a.75.75%200%200%201%200-1.5M2.5%207.75v6a.75.75%200%200%201-1.5%200v-6a.75.75%200%200%201%201.5%200%22/%3E%3C/svg%3E');}</style><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=JetBrains+Mono,+LXGW+WenKai+Screen+GB+Screen:300,300i,400,400i,700,700i%7CJetBrains+Mono,+Consolas:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"JetBrains Mono, LXGW WenKai Screen GB Screen";--md-code-font:"JetBrains Mono, Consolas"}</style><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.css><link rel=stylesheet href=../../../stylesheets/yuanjiao.css><link rel=stylesheet href=../../../stylesheets/extra.css><link rel=stylesheet href=../../../stylesheets/fold_toc.css><link rel=stylesheet href=../../../assets/stylesheets/obsidian.min.css><link rel=stylesheet href=../../../assets/stylesheets/obsidian.min.css.map><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><link href=../../../assets/stylesheets/glightbox.min.css rel=stylesheet><script src=../../../assets/javascripts/glightbox.min.js></script><style id=glightbox-style>
            html.glightbox-open { overflow: initial; height: 100%; }
            .gslide-title { margin-top: 0px; user-select: text; }
            .gslide-desc { color: #666; user-select: text; }
            .gslide-image img { background: white; }
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color); }
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color); }
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color); }
        </style></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=custom> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#_1 class=md-skip> 跳转至 </a> </div> <div data-md-component=announce> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=页眉> <a href=../../.. title=Brent_note class="md-header__button md-logo" aria-label=Brent_note data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> Brent_note </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> 机器学习 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=deep-purple data-md-color-accent=custom aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3zm3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95zm-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31"></path></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=custom aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5s-1.65.15-2.39.42zM3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29zm.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14zM20.65 7l-1.77 3.79a7.02 7.02 0 0 0-2.38-4.15zm-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29zM12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44z"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=搜索 placeholder=搜索 autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav class=md-search__options aria-label=查找> <a href=javascript:void(0) class="md-search__icon md-icon" title=分享 aria-label=分享 data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg> </a> <button type=reset class="md-search__icon md-icon" title=清空当前内容 aria-label=清空当前内容 tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> </nav> </header> <div class=md-container data-md-component=container> <nav class=md-tabs aria-label=标签 data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../../.. class=md-tabs__link> 🏫主页 </a> </li> <li class=md-tabs__item> <a href=../../../%E6%9D%82%E9%A1%B9/%E8%BD%A6%E9%98%9F/1/ class=md-tabs__link> 🗃️杂项 </a> </li> <li class=md-tabs__item> <a href=../../../%E5%A4%A7%E4%B8%89%E7%A7%8B%E5%86%AC/%E6%8E%A7%E5%88%B6/%E6%8E%A7%E5%88%B61/ class=md-tabs__link> 📑三秋冬 </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=./ class=md-tabs__link> 🤖自学 </a> </li> <li class=md-tabs__item> <a href=../../../%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94/ class=md-tabs__link> 🖊️随笔 </a> </li> <li class=md-tabs__item> <a href=../../../tag/ class=md-tabs__link> 🕑标签 </a> </li> </ul> </div> </nav> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted" aria-label=导航栏 data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title=Brent_note class="md-nav__button md-logo" aria-label=Brent_note data-md-component=logo> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"></path></svg> </a> Brent_note </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> 🏫主页 </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> 🗃️杂项 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> 🗃️杂项 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_1> <label class=md-nav__link for=__nav_2_1 id=__nav_2_1_label tabindex=0> <span class=md-ellipsis> 车队 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_1_label aria-expanded=false> <label class=md-nav__title for=__nav_2_1> <span class="md-nav__icon md-icon"></span> 车队 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E6%9D%82%E9%A1%B9/%E8%BD%A6%E9%98%9F/1/ class=md-nav__link> <span class=md-ellipsis> 学习 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E6%9D%82%E9%A1%B9/%E8%BD%A6%E9%98%9F/creo/ class=md-nav__link> <span class=md-ellipsis> creo </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_2_2> <label class=md-nav__link for=__nav_2_2 id=__nav_2_2_label tabindex=0> <span class=md-ellipsis> srtp </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_2_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2_2> <span class="md-nav__icon md-icon"></span> srtp </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E6%9D%82%E9%A1%B9/srtp/1/ class=md-nav__link> <span class=md-ellipsis> 学习 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E6%9D%82%E9%A1%B9/srtp/2/ class=md-nav__link> <span class=md-ellipsis> case </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> 📑三秋冬 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> 📑三秋冬 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> 自动控制原理 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> 自动控制原理 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E5%A4%A7%E4%B8%89%E7%A7%8B%E5%86%AC/%E6%8E%A7%E5%88%B6/%E6%8E%A7%E5%88%B61/ class=md-nav__link> <span class=md-ellipsis> 预习 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_2> <label class=md-nav__link for=__nav_3_2 id=__nav_3_2_label tabindex=0> <span class=md-ellipsis> 传热学 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_2_label aria-expanded=false> <label class=md-nav__title for=__nav_3_2> <span class="md-nav__icon md-icon"></span> 传热学 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E5%A4%A7%E4%B8%89%E7%A7%8B%E5%86%AC/%E4%BC%A0%E7%83%AD%E5%AD%A6/%E4%BC%A0%E7%83%AD%E5%AD%A61/ class=md-nav__link> <span class=md-ellipsis> 前 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_3> <label class=md-nav__link for=__nav_3_3 id=__nav_3_3_label tabindex=0> <span class=md-ellipsis> 动力系统 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3_3> <span class="md-nav__icon md-icon"></span> 动力系统 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E5%A4%A7%E4%B8%89%E7%A7%8B%E5%86%AC/%E5%8A%A8%E5%8A%9B%E7%B3%BB%E7%BB%9F/%E5%8A%A8%E5%8A%9B%E7%B3%BB%E7%BB%9F1/ class=md-nav__link> <span class=md-ellipsis> 前 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_4> <label class=md-nav__link for=__nav_3_4 id=__nav_3_4_label tabindex=0> <span class=md-ellipsis> 设计叁 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_4_label aria-expanded=false> <label class=md-nav__title for=__nav_3_4> <span class="md-nav__icon md-icon"></span> 设计叁 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E5%A4%A7%E4%B8%89%E7%A7%8B%E5%86%AC/%E8%AE%BE%E8%AE%A1/%E8%AE%BE%E8%AE%A1/ class=md-nav__link> <span class=md-ellipsis> 前 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> 🤖自学 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> 🤖自学 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4_1 checked> <label class=md-nav__link for=__nav_4_1 id=__nav_4_1_label tabindex=0> <span class=md-ellipsis> 人工智能 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_4_1_label aria-expanded=true> <label class=md-nav__title for=__nav_4_1> <span class="md-nav__icon md-icon"></span> 人工智能 </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> 机器学习 </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> 机器学习 </span> </a> <nav class="md-nav md-nav--secondary " aria-label=toc.title> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> toc.title </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 人工智能概述 </span> </a> <nav class=md-nav aria-label=人工智能概述> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 机器学习与人工智能、深度学习 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 什么是机器学习 </span> </a> <nav class=md-nav aria-label=什么是机器学习> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 定义 </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 解释 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 数据集的组成 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 机器学习算法分类 </span> </a> <nav class=md-nav aria-label=机器学习算法分类> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 机器学习算法的分类 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 机器学习的开发流程 </span> </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 学习框架和资料介绍 </span> </a> <nav class=md-nav aria-label=学习框架和资料介绍> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 常见的深度学习的框架 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 特征工程 </span> </a> <nav class=md-nav aria-label=特征工程> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_13 class=md-nav__link> <span class=md-ellipsis> 数据集 </span> </a> <nav class=md-nav aria-label=数据集> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> 可用数据集 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_15 class=md-nav__link> <span class=md-ellipsis> 如何使用这个数据集 </span> </a> <nav class=md-nav aria-label=如何使用这个数据集> <ul class=md-nav__list> <li class=md-nav__item> <a href=#api class=md-nav__link> <span class=md-ellipsis> API 介绍 </span> </a> </li> <li class=md-nav__item> <a href=#_16 class=md-nav__link> <span class=md-ellipsis> 小数据集 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> 大数据集 </span> </a> </li> <li class=md-nav__item> <a href=#_18 class=md-nav__link> <span class=md-ellipsis> 数据集返回值 </span> </a> </li> <li class=md-nav__item> <a href=#_19 class=md-nav__link> <span class=md-ellipsis> 数据集的划分 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_20 class=md-nav__link> <span class=md-ellipsis> 特征工程的介绍 </span> </a> <nav class=md-nav aria-label=特征工程的介绍> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_21 class=md-nav__link> <span class=md-ellipsis> 什么是特征工程 </span> </a> </li> <li class=md-nav__item> <a href=#_22 class=md-nav__link> <span class=md-ellipsis> 特征提取 </span> </a> </li> <li class=md-nav__item> <a href=#_23 class=md-nav__link> <span class=md-ellipsis> 字典特征提取 </span> </a> </li> <li class=md-nav__item> <a href=#_24 class=md-nav__link> <span class=md-ellipsis> 文本特征提取 </span> </a> </li> <li class=md-nav__item> <a href=#_25 class=md-nav__link> <span class=md-ellipsis> 文本特征提取的其他方法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#tf-idf class=md-nav__link> <span class=md-ellipsis> 新的提取方法——TF-idf 文本特征提取 </span> </a> <nav class=md-nav aria-label="新的提取方法——TF-idf 文本特征提取"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#api_1 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_26 class=md-nav__link> <span class=md-ellipsis> 特征预处理 </span> </a> <nav class=md-nav aria-label=特征预处理> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_27 class=md-nav__link> <span class=md-ellipsis> 什么是特征预处理 </span> </a> </li> <li class=md-nav__item> <a href=#_28 class=md-nav__link> <span class=md-ellipsis> 归一化 </span> </a> </li> <li class=md-nav__item> <a href=#_29 class=md-nav__link> <span class=md-ellipsis> 标准化 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_30 class=md-nav__link> <span class=md-ellipsis> 特征降维 </span> </a> <nav class=md-nav aria-label=特征降维> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_31 class=md-nav__link> <span class=md-ellipsis> 降维 </span> </a> </li> <li class=md-nav__item> <a href=#_32 class=md-nav__link> <span class=md-ellipsis> 降维的两种方法 </span> </a> </li> <li class=md-nav__item> <a href=#_33 class=md-nav__link> <span class=md-ellipsis> 特征选择 </span> </a> </li> <li class=md-nav__item> <a href=#_34 class=md-nav__link> <span class=md-ellipsis> 过滤式 </span> </a> <nav class=md-nav aria-label=过滤式> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_35 class=md-nav__link> <span class=md-ellipsis> 低方差特征过滤 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_36 class=md-nav__link> <span class=md-ellipsis> 相关系数的求法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_37 class=md-nav__link> <span class=md-ellipsis> 主成分分析 </span> </a> <nav class=md-nav aria-label=主成分分析> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_38 class=md-nav__link> <span class=md-ellipsis> 什么是主成分分析 </span> </a> </li> <li class=md-nav__item> <a href=#api_2 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#_39 class=md-nav__link> <span class=md-ellipsis> 计算 </span> </a> </li> <li class=md-nav__item> <a href=#_40 class=md-nav__link> <span class=md-ellipsis> 案例分析：探究用户对物品类别喜好的细分 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_41 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_42 class=md-nav__link> <span class=md-ellipsis> 分类算法 </span> </a> <nav class=md-nav aria-label=分类算法> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sklearn class=md-nav__link> <span class=md-ellipsis> sklearn 的转换器和预估器 </span> </a> <nav class=md-nav aria-label="sklearn 的转换器和预估器"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_43 class=md-nav__link> <span class=md-ellipsis> 转换器 </span> </a> </li> <li class=md-nav__item> <a href=#_44 class=md-nav__link> <span class=md-ellipsis> 估计器 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#k-knn class=md-nav__link> <span class=md-ellipsis> K-近邻算法（KNN 算法） </span> </a> <nav class=md-nav aria-label="K-近邻算法（KNN 算法）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_45 class=md-nav__link> <span class=md-ellipsis> 什么是 </span> </a> </li> <li class=md-nav__item> <a href=#k-api class=md-nav__link> <span class=md-ellipsis> k-近邻算法 API </span> </a> </li> <li class=md-nav__item> <a href=#_46 class=md-nav__link> <span class=md-ellipsis> 案例：鸢尾花案例 </span> </a> </li> <li class=md-nav__item> <a href=#_47 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_48 class=md-nav__link> <span class=md-ellipsis> 模型选择与调优 </span> </a> <nav class=md-nav aria-label=模型选择与调优> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_49 class=md-nav__link> <span class=md-ellipsis> 什么是交叉验证 </span> </a> </li> <li class=md-nav__item> <a href=#_50 class=md-nav__link> <span class=md-ellipsis> 超参数网格搜索 </span> </a> </li> <li class=md-nav__item> <a href=#api_3 class=md-nav__link> <span class=md-ellipsis> 模型选择与调优 API </span> </a> </li> <li class=md-nav__item> <a href=#facebook class=md-nav__link> <span class=md-ellipsis> 预测 facebook 签到位置 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_51 class=md-nav__link> <span class=md-ellipsis> 朴素贝叶斯算法 </span> </a> <nav class=md-nav aria-label=朴素贝叶斯算法> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_52 class=md-nav__link> <span class=md-ellipsis> 什么是朴素贝叶斯算法的分类方式 </span> </a> </li> <li class=md-nav__item> <a href=#_53 class=md-nav__link> <span class=md-ellipsis> 概率的基础知识 </span> </a> </li> <li class=md-nav__item> <a href=#api_4 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#20 class=md-nav__link> <span class=md-ellipsis> 案例：20 类新闻分类 </span> </a> </li> <li class=md-nav__item> <a href=#_54 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_55 class=md-nav__link> <span class=md-ellipsis> 决策树 </span> </a> <nav class=md-nav aria-label=决策树> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_56 class=md-nav__link> <span class=md-ellipsis> 认识决策树 </span> </a> </li> <li class=md-nav__item> <a href=#_57 class=md-nav__link> <span class=md-ellipsis> 决策树的分类原理详解 </span> </a> </li> <li class=md-nav__item> <a href=#api_5 class=md-nav__link> <span class=md-ellipsis> 决策树的 API </span> </a> </li> <li class=md-nav__item> <a href=#_58 class=md-nav__link> <span class=md-ellipsis> 决策树的可视化 </span> </a> </li> <li class=md-nav__item> <a href=#_59 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> <li class=md-nav__item> <a href=#_60 class=md-nav__link> <span class=md-ellipsis> 泰坦尼克号乘客生存的预测案例 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_61 class=md-nav__link> <span class=md-ellipsis> 随机森林 </span> </a> <nav class=md-nav aria-label=随机森林> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_62 class=md-nav__link> <span class=md-ellipsis> 什么是集成学习方法 </span> </a> </li> <li class=md-nav__item> <a href=#_63 class=md-nav__link> <span class=md-ellipsis> 随机森林的原理过程 </span> </a> </li> <li class=md-nav__item> <a href=#api_6 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#_64 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_65 class=md-nav__link> <span class=md-ellipsis> 回归与聚类算法 </span> </a> <nav class=md-nav aria-label=回归与聚类算法> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_66 class=md-nav__link> <span class=md-ellipsis> 线性回归 </span> </a> <nav class=md-nav aria-label=线性回归> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_67 class=md-nav__link> <span class=md-ellipsis> 线性回归的原理 </span> </a> </li> <li class=md-nav__item> <a href=#_68 class=md-nav__link> <span class=md-ellipsis> 线性回归的损失和优化原理（理解记忆） </span> </a> </li> <li class=md-nav__item> <a href=#_69 class=md-nav__link> <span class=md-ellipsis> 优化算法 </span> </a> </li> <li class=md-nav__item> <a href=#_70 class=md-nav__link> <span class=md-ellipsis> 梯度下降 </span> </a> </li> <li class=md-nav__item> <a href=#api_7 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#_71 class=md-nav__link> <span class=md-ellipsis> 波士顿房价预测 </span> </a> </li> <li class=md-nav__item> <a href=#_72 class=md-nav__link> <span class=md-ellipsis> 模型的评估 </span> </a> </li> <li class=md-nav__item> <a href=#_73 class=md-nav__link> <span class=md-ellipsis> 梯度下降优化器 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_74 class=md-nav__link> <span class=md-ellipsis> 欠拟合与过拟合 </span> </a> <nav class=md-nav aria-label=欠拟合与过拟合> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_75 class=md-nav__link> <span class=md-ellipsis> 什么是欠拟合与过拟合 </span> </a> </li> <li class=md-nav__item> <a href=#_76 class=md-nav__link> <span class=md-ellipsis> 解决方法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_77 class=md-nav__link> <span class=md-ellipsis> 线性回归的改进——岭回归 </span> </a> <nav class=md-nav aria-label=线性回归的改进——岭回归> <ul class=md-nav__list> <li class=md-nav__item> <a href=#l-2 class=md-nav__link> <span class=md-ellipsis> 带有 L 2 正则化的线性回归——岭回归 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#- class=md-nav__link> <span class=md-ellipsis> 分类算法-逻辑回归与二分类 </span> </a> <nav class=md-nav aria-label=分类算法-逻辑回归与二分类> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_78 class=md-nav__link> <span class=md-ellipsis> 应用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_79 class=md-nav__link> <span class=md-ellipsis> 逻辑回归的原理 </span> </a> </li> <li class=md-nav__item> <a href=#api_8 class=md-nav__link> <span class=md-ellipsis> 逻辑回归API 调用 </span> </a> </li> <li class=md-nav__item> <a href=#_80 class=md-nav__link> <span class=md-ellipsis> 案例：癌症分类预测的案例 </span> </a> </li> <li class=md-nav__item> <a href=#_81 class=md-nav__link> <span class=md-ellipsis> 分类的评估方法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_82 class=md-nav__link> <span class=md-ellipsis> 模型的保存和加载 </span> </a> <nav class=md-nav aria-label=模型的保存和加载> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sklearn_1 class=md-nav__link> <span class=md-ellipsis> sklearn 中的 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#-k-means class=md-nav__link> <span class=md-ellipsis> 无监督学习-K-means 算法 </span> </a> <nav class=md-nav aria-label="无监督学习-K-means 算法"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_83 class=md-nav__link> <span class=md-ellipsis> 什么是无监督学习 </span> </a> </li> <li class=md-nav__item> <a href=#_84 class=md-nav__link> <span class=md-ellipsis> 包含的算法 </span> </a> </li> <li class=md-nav__item> <a href=#k-means class=md-nav__link> <span class=md-ellipsis> K-means 原理 </span> </a> </li> <li class=md-nav__item> <a href=#api_9 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#instacart-market class=md-nav__link> <span class=md-ellipsis> 案例：Instacart Market 用户聚类 </span> </a> </li> <li class=md-nav__item> <a href=#kmeans class=md-nav__link> <span class=md-ellipsis> Kmeans 性能评估的指标 </span> </a> </li> <li class=md-nav__item> <a href=#_85 class=md-nav__link> <span class=md-ellipsis> 聚类的总结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_86 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ class=md-nav__link> <span class=md-ellipsis> 深度学习 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> 🖊️随笔 </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> 🖊️随笔 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../%E9%9A%8F%E7%AC%94/%E9%9A%8F%E7%AC%94/ class=md-nav__link> <span class=md-ellipsis> 随笔 </span> </a> </li> <li class=md-nav__item> <a href=../../../%E9%9A%8F%E7%AC%94/%E6%9D%82%E4%BA%8B/%E6%9D%82%E4%BA%8B/ class=md-nav__link> <span class=md-ellipsis> 杂事 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../tag/ class=md-nav__link> <span class=md-ellipsis> 🕑标签 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--secondary " aria-label=toc.title> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> toc.title </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#_1 class=md-nav__link> <span class=md-ellipsis> 人工智能概述 </span> </a> <nav class=md-nav aria-label=人工智能概述> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_2 class=md-nav__link> <span class=md-ellipsis> 机器学习与人工智能、深度学习 </span> </a> </li> <li class=md-nav__item> <a href=#_3 class=md-nav__link> <span class=md-ellipsis> 什么是机器学习 </span> </a> <nav class=md-nav aria-label=什么是机器学习> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_4 class=md-nav__link> <span class=md-ellipsis> 定义 </span> </a> </li> <li class=md-nav__item> <a href=#_5 class=md-nav__link> <span class=md-ellipsis> 解释 </span> </a> </li> <li class=md-nav__item> <a href=#_6 class=md-nav__link> <span class=md-ellipsis> 数据集的组成 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_7 class=md-nav__link> <span class=md-ellipsis> 机器学习算法分类 </span> </a> <nav class=md-nav aria-label=机器学习算法分类> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_8 class=md-nav__link> <span class=md-ellipsis> 机器学习算法的分类 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_9 class=md-nav__link> <span class=md-ellipsis> 机器学习的开发流程 </span> </a> </li> <li class=md-nav__item> <a href=#_10 class=md-nav__link> <span class=md-ellipsis> 学习框架和资料介绍 </span> </a> <nav class=md-nav aria-label=学习框架和资料介绍> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_11 class=md-nav__link> <span class=md-ellipsis> 常见的深度学习的框架 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_12 class=md-nav__link> <span class=md-ellipsis> 特征工程 </span> </a> <nav class=md-nav aria-label=特征工程> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_13 class=md-nav__link> <span class=md-ellipsis> 数据集 </span> </a> <nav class=md-nav aria-label=数据集> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_14 class=md-nav__link> <span class=md-ellipsis> 可用数据集 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_15 class=md-nav__link> <span class=md-ellipsis> 如何使用这个数据集 </span> </a> <nav class=md-nav aria-label=如何使用这个数据集> <ul class=md-nav__list> <li class=md-nav__item> <a href=#api class=md-nav__link> <span class=md-ellipsis> API 介绍 </span> </a> </li> <li class=md-nav__item> <a href=#_16 class=md-nav__link> <span class=md-ellipsis> 小数据集 </span> </a> </li> <li class=md-nav__item> <a href=#_17 class=md-nav__link> <span class=md-ellipsis> 大数据集 </span> </a> </li> <li class=md-nav__item> <a href=#_18 class=md-nav__link> <span class=md-ellipsis> 数据集返回值 </span> </a> </li> <li class=md-nav__item> <a href=#_19 class=md-nav__link> <span class=md-ellipsis> 数据集的划分 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_20 class=md-nav__link> <span class=md-ellipsis> 特征工程的介绍 </span> </a> <nav class=md-nav aria-label=特征工程的介绍> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_21 class=md-nav__link> <span class=md-ellipsis> 什么是特征工程 </span> </a> </li> <li class=md-nav__item> <a href=#_22 class=md-nav__link> <span class=md-ellipsis> 特征提取 </span> </a> </li> <li class=md-nav__item> <a href=#_23 class=md-nav__link> <span class=md-ellipsis> 字典特征提取 </span> </a> </li> <li class=md-nav__item> <a href=#_24 class=md-nav__link> <span class=md-ellipsis> 文本特征提取 </span> </a> </li> <li class=md-nav__item> <a href=#_25 class=md-nav__link> <span class=md-ellipsis> 文本特征提取的其他方法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#tf-idf class=md-nav__link> <span class=md-ellipsis> 新的提取方法——TF-idf 文本特征提取 </span> </a> <nav class=md-nav aria-label="新的提取方法——TF-idf 文本特征提取"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#api_1 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_26 class=md-nav__link> <span class=md-ellipsis> 特征预处理 </span> </a> <nav class=md-nav aria-label=特征预处理> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_27 class=md-nav__link> <span class=md-ellipsis> 什么是特征预处理 </span> </a> </li> <li class=md-nav__item> <a href=#_28 class=md-nav__link> <span class=md-ellipsis> 归一化 </span> </a> </li> <li class=md-nav__item> <a href=#_29 class=md-nav__link> <span class=md-ellipsis> 标准化 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_30 class=md-nav__link> <span class=md-ellipsis> 特征降维 </span> </a> <nav class=md-nav aria-label=特征降维> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_31 class=md-nav__link> <span class=md-ellipsis> 降维 </span> </a> </li> <li class=md-nav__item> <a href=#_32 class=md-nav__link> <span class=md-ellipsis> 降维的两种方法 </span> </a> </li> <li class=md-nav__item> <a href=#_33 class=md-nav__link> <span class=md-ellipsis> 特征选择 </span> </a> </li> <li class=md-nav__item> <a href=#_34 class=md-nav__link> <span class=md-ellipsis> 过滤式 </span> </a> <nav class=md-nav aria-label=过滤式> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_35 class=md-nav__link> <span class=md-ellipsis> 低方差特征过滤 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_36 class=md-nav__link> <span class=md-ellipsis> 相关系数的求法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_37 class=md-nav__link> <span class=md-ellipsis> 主成分分析 </span> </a> <nav class=md-nav aria-label=主成分分析> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_38 class=md-nav__link> <span class=md-ellipsis> 什么是主成分分析 </span> </a> </li> <li class=md-nav__item> <a href=#api_2 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#_39 class=md-nav__link> <span class=md-ellipsis> 计算 </span> </a> </li> <li class=md-nav__item> <a href=#_40 class=md-nav__link> <span class=md-ellipsis> 案例分析：探究用户对物品类别喜好的细分 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_41 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_42 class=md-nav__link> <span class=md-ellipsis> 分类算法 </span> </a> <nav class=md-nav aria-label=分类算法> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sklearn class=md-nav__link> <span class=md-ellipsis> sklearn 的转换器和预估器 </span> </a> <nav class=md-nav aria-label="sklearn 的转换器和预估器"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_43 class=md-nav__link> <span class=md-ellipsis> 转换器 </span> </a> </li> <li class=md-nav__item> <a href=#_44 class=md-nav__link> <span class=md-ellipsis> 估计器 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#k-knn class=md-nav__link> <span class=md-ellipsis> K-近邻算法（KNN 算法） </span> </a> <nav class=md-nav aria-label="K-近邻算法（KNN 算法）"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_45 class=md-nav__link> <span class=md-ellipsis> 什么是 </span> </a> </li> <li class=md-nav__item> <a href=#k-api class=md-nav__link> <span class=md-ellipsis> k-近邻算法 API </span> </a> </li> <li class=md-nav__item> <a href=#_46 class=md-nav__link> <span class=md-ellipsis> 案例：鸢尾花案例 </span> </a> </li> <li class=md-nav__item> <a href=#_47 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_48 class=md-nav__link> <span class=md-ellipsis> 模型选择与调优 </span> </a> <nav class=md-nav aria-label=模型选择与调优> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_49 class=md-nav__link> <span class=md-ellipsis> 什么是交叉验证 </span> </a> </li> <li class=md-nav__item> <a href=#_50 class=md-nav__link> <span class=md-ellipsis> 超参数网格搜索 </span> </a> </li> <li class=md-nav__item> <a href=#api_3 class=md-nav__link> <span class=md-ellipsis> 模型选择与调优 API </span> </a> </li> <li class=md-nav__item> <a href=#facebook class=md-nav__link> <span class=md-ellipsis> 预测 facebook 签到位置 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_51 class=md-nav__link> <span class=md-ellipsis> 朴素贝叶斯算法 </span> </a> <nav class=md-nav aria-label=朴素贝叶斯算法> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_52 class=md-nav__link> <span class=md-ellipsis> 什么是朴素贝叶斯算法的分类方式 </span> </a> </li> <li class=md-nav__item> <a href=#_53 class=md-nav__link> <span class=md-ellipsis> 概率的基础知识 </span> </a> </li> <li class=md-nav__item> <a href=#api_4 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#20 class=md-nav__link> <span class=md-ellipsis> 案例：20 类新闻分类 </span> </a> </li> <li class=md-nav__item> <a href=#_54 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_55 class=md-nav__link> <span class=md-ellipsis> 决策树 </span> </a> <nav class=md-nav aria-label=决策树> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_56 class=md-nav__link> <span class=md-ellipsis> 认识决策树 </span> </a> </li> <li class=md-nav__item> <a href=#_57 class=md-nav__link> <span class=md-ellipsis> 决策树的分类原理详解 </span> </a> </li> <li class=md-nav__item> <a href=#api_5 class=md-nav__link> <span class=md-ellipsis> 决策树的 API </span> </a> </li> <li class=md-nav__item> <a href=#_58 class=md-nav__link> <span class=md-ellipsis> 决策树的可视化 </span> </a> </li> <li class=md-nav__item> <a href=#_59 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> <li class=md-nav__item> <a href=#_60 class=md-nav__link> <span class=md-ellipsis> 泰坦尼克号乘客生存的预测案例 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_61 class=md-nav__link> <span class=md-ellipsis> 随机森林 </span> </a> <nav class=md-nav aria-label=随机森林> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_62 class=md-nav__link> <span class=md-ellipsis> 什么是集成学习方法 </span> </a> </li> <li class=md-nav__item> <a href=#_63 class=md-nav__link> <span class=md-ellipsis> 随机森林的原理过程 </span> </a> </li> <li class=md-nav__item> <a href=#api_6 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#_64 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_65 class=md-nav__link> <span class=md-ellipsis> 回归与聚类算法 </span> </a> <nav class=md-nav aria-label=回归与聚类算法> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_66 class=md-nav__link> <span class=md-ellipsis> 线性回归 </span> </a> <nav class=md-nav aria-label=线性回归> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_67 class=md-nav__link> <span class=md-ellipsis> 线性回归的原理 </span> </a> </li> <li class=md-nav__item> <a href=#_68 class=md-nav__link> <span class=md-ellipsis> 线性回归的损失和优化原理（理解记忆） </span> </a> </li> <li class=md-nav__item> <a href=#_69 class=md-nav__link> <span class=md-ellipsis> 优化算法 </span> </a> </li> <li class=md-nav__item> <a href=#_70 class=md-nav__link> <span class=md-ellipsis> 梯度下降 </span> </a> </li> <li class=md-nav__item> <a href=#api_7 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#_71 class=md-nav__link> <span class=md-ellipsis> 波士顿房价预测 </span> </a> </li> <li class=md-nav__item> <a href=#_72 class=md-nav__link> <span class=md-ellipsis> 模型的评估 </span> </a> </li> <li class=md-nav__item> <a href=#_73 class=md-nav__link> <span class=md-ellipsis> 梯度下降优化器 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_74 class=md-nav__link> <span class=md-ellipsis> 欠拟合与过拟合 </span> </a> <nav class=md-nav aria-label=欠拟合与过拟合> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_75 class=md-nav__link> <span class=md-ellipsis> 什么是欠拟合与过拟合 </span> </a> </li> <li class=md-nav__item> <a href=#_76 class=md-nav__link> <span class=md-ellipsis> 解决方法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_77 class=md-nav__link> <span class=md-ellipsis> 线性回归的改进——岭回归 </span> </a> <nav class=md-nav aria-label=线性回归的改进——岭回归> <ul class=md-nav__list> <li class=md-nav__item> <a href=#l-2 class=md-nav__link> <span class=md-ellipsis> 带有 L 2 正则化的线性回归——岭回归 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#- class=md-nav__link> <span class=md-ellipsis> 分类算法-逻辑回归与二分类 </span> </a> <nav class=md-nav aria-label=分类算法-逻辑回归与二分类> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_78 class=md-nav__link> <span class=md-ellipsis> 应用场景 </span> </a> </li> <li class=md-nav__item> <a href=#_79 class=md-nav__link> <span class=md-ellipsis> 逻辑回归的原理 </span> </a> </li> <li class=md-nav__item> <a href=#api_8 class=md-nav__link> <span class=md-ellipsis> 逻辑回归API 调用 </span> </a> </li> <li class=md-nav__item> <a href=#_80 class=md-nav__link> <span class=md-ellipsis> 案例：癌症分类预测的案例 </span> </a> </li> <li class=md-nav__item> <a href=#_81 class=md-nav__link> <span class=md-ellipsis> 分类的评估方法 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_82 class=md-nav__link> <span class=md-ellipsis> 模型的保存和加载 </span> </a> <nav class=md-nav aria-label=模型的保存和加载> <ul class=md-nav__list> <li class=md-nav__item> <a href=#sklearn_1 class=md-nav__link> <span class=md-ellipsis> sklearn 中的 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#-k-means class=md-nav__link> <span class=md-ellipsis> 无监督学习-K-means 算法 </span> </a> <nav class=md-nav aria-label="无监督学习-K-means 算法"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#_83 class=md-nav__link> <span class=md-ellipsis> 什么是无监督学习 </span> </a> </li> <li class=md-nav__item> <a href=#_84 class=md-nav__link> <span class=md-ellipsis> 包含的算法 </span> </a> </li> <li class=md-nav__item> <a href=#k-means class=md-nav__link> <span class=md-ellipsis> K-means 原理 </span> </a> </li> <li class=md-nav__item> <a href=#api_9 class=md-nav__link> <span class=md-ellipsis> API </span> </a> </li> <li class=md-nav__item> <a href=#instacart-market class=md-nav__link> <span class=md-ellipsis> 案例：Instacart Market 用户聚类 </span> </a> </li> <li class=md-nav__item> <a href=#kmeans class=md-nav__link> <span class=md-ellipsis> Kmeans 性能评估的指标 </span> </a> </li> <li class=md-nav__item> <a href=#_85 class=md-nav__link> <span class=md-ellipsis> 聚类的总结 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#_86 class=md-nav__link> <span class=md-ellipsis> 总结 </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <h1>机器学习</h1> <div class="admonition info"> <p class=admonition-title>📖 阅读信息</p> <p>阅读时间：<strong>14</strong> 分钟 | 中文字符：<strong>5503</strong> | 有效代码行数：<strong>412</strong></p> </div> <h2 id=_1>人工智能概述<a class=headerlink href=#_1 title="Permanent link">¶</a></h2> <h3 id=_2>机器学习与人工智能、深度学习<a class=headerlink href=#_2 title="Permanent link">¶</a></h3> <p>三者之间是包含与被包含的关系 </p> <ul> <li>人工智能：最大的概念<br> 最开始的时候是为了实现自动的下棋，那个时候就是人工智能了<br> 在 1958 年，有最开始的人工智能的会议。</li> <li>机器学习：实际上这个东西在上个世纪八十年代上就得到了广泛的应用</li> <li>深度学习：在图像识别中取得了不错的效果<ul> <li>应用在挖掘数据</li> <li>应用在图像的识别</li> <li>应用在自然语言的处理——翻译，还有很多的聊天的人工智能</li> </ul> </li> </ul> <h3 id=_3>什么是机器学习<a class=headerlink href=#_3 title="Permanent link">¶</a></h3> <h4 id=_4>定义<a class=headerlink href=#_4 title="Permanent link">¶</a></h4> <p>机器学习是从<strong>数据</strong>中自动分析获得<strong>模型</strong>，并利用模型对<strong>未知的数据进行预测</strong> </p> <h4 id=_5>解释<a class=headerlink href=#_5 title="Permanent link">¶</a></h4> <p>利用以往的规律进行学习 </p> <div class="admonition tip"> <p class=admonition-title>例子 </p> <p>比如使用人工智能识别猫和狗的照片，就是使用大量的图片进行训练得到的 </p> <p>还有房屋价格的预测等等 </p> </div> <p>但是这些历史数据应该是怎么样的？</p> <h4 id=_6>数据集的组成<a class=headerlink href=#_6 title="Permanent link">¶</a></h4> <ul> <li>结构：特征值+目标值</li> </ul> <div class="admonition tip"> <p class=admonition-title>注 </p> <p>对于每一行数据我们可以称之为样本 </p> <p>有些数据集可以没有目标值 </p> </div> <h3 id=_7>机器学习算法分类<a class=headerlink href=#_7 title="Permanent link">¶</a></h3> <p>要使得机器有着识别猫和狗的能力，应该从机器中进行学习<br> 我们需要的也是特征值和目标值<br> 这里的目标值就是猫？还是狗 </p> <hr> <p>所以这里的目标值是类别，属于<strong>分类问题</strong><br> 但是对于房屋价格的预测，最后的目标值是一种连续型的数据，属于<strong>回归问题</strong><br> 当我们遇到的数据集中<strong>没有目标值</strong>时，称为<strong>无监督学习</strong> </p> <ul> <li>监督学习<ul> <li>分类问题</li> <li>回归问题</li> </ul> </li> <li>无监督学习</li> </ul> <hr> <div class="admonition quote"> <p class=admonition-title>例子 </p> <p>预测气温是多少度，是回归问题 </p> <p>预测明天的天气，是分类问题 </p> <p>人脸的年龄预测：看怎么定义，可以是回归/分类 </p> <p>人脸的识别：分类 </p> </div> <h4 id=_8>机器学习算法的分类<a class=headerlink href=#_8 title="Permanent link">¶</a></h4> <ul> <li>监督学习：<ul> <li>分类：K-近邻、贝叶斯、决策树与随机森林、逻辑回归</li> <li>回归：线性回归，岭回归</li> </ul> </li> <li>无监督学习<ul> <li>聚类 k-means</li> </ul> </li> </ul> <h3 id=_9>机器学习的开发流程<a class=headerlink href=#_9 title="Permanent link">¶</a></h3> <div class="admonition tip"> <p class=admonition-title>流程</p> <ol> <li>获取数据 </li> <li>数据处理 </li> <li>特征工程 </li> <li>机器学习算法训练-模型 </li> <li>模型评估 </li> </ol> </div> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250731180031.png><img alt src=../png/Pasted%20image%2020250731180031.png></a> </p> <h3 id=_10>学习框架和资料介绍<a class=headerlink href=#_10 title="Permanent link">¶</a></h3> <p>重点的问题： </p> <ol> <li>算法是核心，数据和计算是基础</li> <li>找准定位<br> 大部分复杂模型的算法设计都是算法工程师在做，实战类的书籍 </li> </ol> <hr> <p>书籍：<br> - 机器学习-周志华 - 统计学习方法-李航 - 深度学习-"花书"</p> <h4 id=_11>常见的深度学习的框架<a class=headerlink href=#_11 title="Permanent link">¶</a></h4> <p>一般是 pytorch 和 TF 使用的多一点 </p> <h2 id=_12>特征工程<a class=headerlink href=#_12 title="Permanent link">¶</a></h2> <h3 id=_13>数据集<a class=headerlink href=#_13 title="Permanent link">¶</a></h3> <h4 id=_14>可用数据集<a class=headerlink href=#_14 title="Permanent link">¶</a></h4> <p>公司内部：百度之类的<br> 数据接口：花钱<br> 数据集 </p> <hr> <p>所以在学习阶段我们会用到哪些数据集？<br> 1. Sklearn 2. Kaggle 3. Ucl<br> 我们现在主要介绍一下 sklearn<br> - Python 语言的机器学习工具 - 包括很多的知名的机器学习算法的实现 - 易于上手 - 安装 pip install Scikit-learn (在 cmd 中运行安装)（使用的是 pycharm 的话在里面的终端安装即可） - 安装好之后直接在 python 中好像可以直接使用<br> 如下的代码块</p> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-0-1> 1</a></span>
<span class=normal><a href=#__codelineno-0-2> 2</a></span>
<span class=normal><a href=#__codelineno-0-3> 3</a></span>
<span class=normal><a href=#__codelineno-0-4> 4</a></span>
<span class=normal><a href=#__codelineno-0-5> 5</a></span>
<span class=normal><a href=#__codelineno-0-6> 6</a></span>
<span class=normal><a href=#__codelineno-0-7> 7</a></span>
<span class=normal><a href=#__codelineno-0-8> 8</a></span>
<span class=normal><a href=#__codelineno-0-9> 9</a></span>
<span class=normal><a href=#__codelineno-0-10>10</a></span>
<span class=normal><a href=#__codelineno-0-11>11</a></span>
<span class=normal><a href=#__codelineno-0-12>12</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-0-1 name=__codelineno-0-1></a><span class=c1># 1. 导入数据集模块</span>
<a id=__codelineno-0-2 name=__codelineno-0-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn</span><span class=w> </span><span class=kn>import</span> <span class=n>datasets</span>
<a id=__codelineno-0-3 name=__codelineno-0-3></a>
<a id=__codelineno-0-4 name=__codelineno-0-4></a><span class=c1># 2. 加载经典数据集（以鸢尾花数据集为例）</span>
<a id=__codelineno-0-5 name=__codelineno-0-5></a><span class=n>iris</span> <span class=o>=</span> <span class=n>datasets</span><span class=o>.</span><span class=n>load_iris</span><span class=p>()</span>  <span class=c1># 这是一个内置的小数据集，无需下载</span>
<a id=__codelineno-0-6 name=__codelineno-0-6></a>
<a id=__codelineno-0-7 name=__codelineno-0-7></a><span class=c1># 3. 查看数据集内容</span>
<a id=__codelineno-0-8 name=__codelineno-0-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>"特征数据（前5行）：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>  <span class=c1># 数据集的特征（输入变量）</span>
<a id=__codelineno-0-9 name=__codelineno-0-9></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>标签数据：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span><span class=p>)</span>  <span class=c1># 数据集的标签（输出变量/分类结果）</span>
<a id=__codelineno-0-10 name=__codelineno-0-10></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>特征名称：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>feature_names</span><span class=p>)</span>  <span class=c1># 每个特征的名称</span>
<a id=__codelineno-0-11 name=__codelineno-0-11></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>标签名称：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>target_names</span><span class=p>)</span>  <span class=c1># 每个标签对应的类别名称</span>
<a id=__codelineno-0-12 name=__codelineno-0-12></a><span class=nb>print</span><span class=p>(</span><span class=s2>"</span><span class=se>\n</span><span class=s2>数据集描述：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>DESCR</span><span class=p>)</span>  <span class=c1># 数据集的详细说明</span>
</code></pre></div></td></tr></tbody></table></div> <div class="admonition tip"> <p class=admonition-title>介绍 </p> <p>他的文档是非常完善的 </p> <p>可以直接在文档中进行相关的学习 </p> <p><a href=https://scikit-learn.org.cn/ >网址</a> </p> </div> <h3 id=_15>如何使用这个数据集<a class=headerlink href=#_15 title="Permanent link">¶</a></h3> <h4 id=api>API 介绍<a class=headerlink href=#api title="Permanent link">¶</a></h4> <ul> <li>sklearn. datasets<ul> <li>加载获取流行数据集</li> <li>datasets. load_*()<ul> <li>获取<strong>小规模</strong>的数据集</li> </ul> </li> <li>datasets. fetch_*(data_home=None)<ul> <li>获取<strong>大量</strong>的数据集，需要从网络上下载</li> </ul> </li> </ul> </li> </ul> <h4 id=_16>小数据集<a class=headerlink href=#_16 title="Permanent link">¶</a></h4> <ul> <li>datasets. load_iris ()<br> 加载并返回鸢尾花数据集</li> <li>datasets. load_boston ()<br> 加载并返回波士顿房价数据集</li> </ul> <h4 id=_17>大数据集<a class=headerlink href=#_17 title="Permanent link">¶</a></h4> <ul> <li>sklearn. datasets. fetch_20 newsgroups (data_home=None, subset='train')<ul> <li>其中的 train 为训练的数据集，还可以为 test 为测试的数据集，所有的就是 all，一般选择的是这个</li> </ul> </li> </ul> <h4 id=_18>数据集返回值<a class=headerlink href=#_18 title="Permanent link">¶</a></h4> <p>上述的返回的数据类型都是字典类型，可以使用 <code>[""]</code> 的方式获取，或者使用 <code>.</code> 的方式获取 </p> <ul> <li>data：特征数据数组</li> <li>targets：标签数组</li> <li>DERCR：数据描述</li> <li>feature_names: 特征名</li> <li>target_names：标签名</li> </ul> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-1-1> 1</a></span>
<span class=normal><a href=#__codelineno-1-2> 2</a></span>
<span class=normal><a href=#__codelineno-1-3> 3</a></span>
<span class=normal><a href=#__codelineno-1-4> 4</a></span>
<span class=normal><a href=#__codelineno-1-5> 5</a></span>
<span class=normal><a href=#__codelineno-1-6> 6</a></span>
<span class=normal><a href=#__codelineno-1-7> 7</a></span>
<span class=normal><a href=#__codelineno-1-8> 8</a></span>
<span class=normal><a href=#__codelineno-1-9> 9</a></span>
<span class=normal><a href=#__codelineno-1-10>10</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-1-1 name=__codelineno-1-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_iris</span>
<a id=__codelineno-1-2 name=__codelineno-1-2></a><span class=c1># 获取鸢尾花数据集</span>
<a id=__codelineno-1-3 name=__codelineno-1-3></a><span class=n>iris</span> <span class=o>=</span> <span class=n>load_iris</span><span class=p>()</span>
<a id=__codelineno-1-4 name=__codelineno-1-4></a><span class=nb>print</span><span class=p>(</span><span class=s2>"鸢尾花数据集的返回值: </span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=p>)</span>
<a id=__codelineno-1-5 name=__codelineno-1-5></a><span class=nb>print</span><span class=p>(</span><span class=s2>"返回值是一个继承自字典的Bench"</span><span class=p>)</span>
<a id=__codelineno-1-6 name=__codelineno-1-6></a><span class=nb>print</span><span class=p>(</span><span class=s2>"鸢尾花的特征值:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=p>[</span><span class=s2>"data"</span><span class=p>])</span>
<a id=__codelineno-1-7 name=__codelineno-1-7></a><span class=nb>print</span><span class=p>(</span><span class=s2>"鸢尾花的目标值: </span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>target</span><span class=p>)</span>
<a id=__codelineno-1-8 name=__codelineno-1-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>"鸢尾花特征的名字: </span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>feature_names</span><span class=p>)</span>
<a id=__codelineno-1-9 name=__codelineno-1-9></a><span class=nb>print</span><span class=p>(</span><span class=s2>"鸢尾花目标值的名字: </span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>target_names</span><span class=p>)</span>
<a id=__codelineno-1-10 name=__codelineno-1-10></a><span class=nb>print</span><span class=p>(</span><span class=s2>"鸢尾花的描述: </span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>iris</span><span class=o>.</span><span class=n>DESCR</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div> <p>首先使用下面的代码<strong>输出所有的数据</strong></p> <p></p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-2-1>1</a></span>
<span class=normal><a href=#__codelineno-2-2>2</a></span>
<span class=normal><a href=#__codelineno-2-3>3</a></span>
<span class=normal><a href=#__codelineno-2-4>4</a></span>
<span class=normal><a href=#__codelineno-2-5>5</a></span>
<span class=normal><a href=#__codelineno-2-6>6</a></span>
<span class=normal><a href=#__codelineno-2-7>7</a></span>
<span class=normal><a href=#__codelineno-2-8>8</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-2-1 name=__codelineno-2-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_iris</span>  
<a id=__codelineno-2-2 name=__codelineno-2-2></a><span class=c1># 获取鸢尾花数据集  </span>
<a id=__codelineno-2-3 name=__codelineno-2-3></a>
<a id=__codelineno-2-4 name=__codelineno-2-4></a><span class=k>def</span><span class=w> </span><span class=nf>datasets_demo</span><span class=p>():</span>  
<a id=__codelineno-2-5 name=__codelineno-2-5></a>    <span class=n>iris</span> <span class=o>=</span> <span class=n>load_iris</span><span class=p>()</span>  
<a id=__codelineno-2-6 name=__codelineno-2-6></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"鸢尾花数据集：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>iris</span><span class=p>)</span>  
<a id=__codelineno-2-7 name=__codelineno-2-7></a>    <span class=k>return</span> <span class=kc>None</span>  
<a id=__codelineno-2-8 name=__codelineno-2-8></a><span class=n>datasets_demo</span><span class=p>()</span>
</code></pre></div></td></tr></tbody></table></div> 输出的结果为 ： <p></p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250822004756.png><img alt src=../png/Pasted%20image%2020250822004756.png></a> </p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250822004825.png><img alt src=../png/Pasted%20image%2020250822004825.png></a> </p> <hr> <p>使用<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-3-1>1</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-3-1 name=__codelineno-3-1></a><span class=nb>print</span><span class=p>(</span><span class=s2>"查看数据集描述：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>iris</span><span class=p>[</span><span class=s2>"DESCR"</span><span class=p>])</span>
</code></pre></div></td></tr></tbody></table></div><p></p> <p>输出了数据集的<strong>特征</strong>： </p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250822005149.png><img alt src=../png/Pasted%20image%2020250822005149.png></a> </p> <div class="admonition tip"> <p class=admonition-title>输出的特征 </p> <p>sepal length: 4.3 7.9 5.84 0.83 0.7826 </p> <p>sepal width: 2.0 4.4 3.05 0.43 -0.4194 </p> <p>petal length: 1.0 6.9 3.76 1.76 0.9490 (high!) </p> <p>petal width: 0.1 2.5 1.20 0.76 0.9565 (high!) </p> </div> <p><code>print("查看特征值的名字,\n",iris.feature_names)</code><br> 输出的结果就是：<code>['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']</code> </p> <h4 id=_19>数据集的划分<a class=headerlink href=#_19 title="Permanent link">¶</a></h4> <p>机器学习的数据集一般会分为两个部分：<br> - 训练数据：用于训练、构件模型 - 测试数据：在模型检验时使用，用于评估<strong>模型是否有效</strong><br> 划分的比例：<br> - 训练集：70.75.80 - 测试集：上面的相减</p> <hr> <div class="admonition tip"> <p class=admonition-title>划分</p> <ul> <li>sklearn. model_selection. train_test_split (arrays, *options) <ul> <li>x 数据集的特征值 </li> <li>y 数据集的标签值 </li> <li>test_size：测试集的大小，一般为 float </li> <li>random_state：随机数种子，不同的种子生成不同的随机采样数，相同的种子采样结果相同 </li> <li>return 训练集特征值，测试集特征值，训练集目标值，测试集目标值</li> </ul> </li> </ul> </div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-4-1> 1</a></span>
<span class=normal><a href=#__codelineno-4-2> 2</a></span>
<span class=normal><a href=#__codelineno-4-3> 3</a></span>
<span class=normal><a href=#__codelineno-4-4> 4</a></span>
<span class=normal><a href=#__codelineno-4-5> 5</a></span>
<span class=normal><a href=#__codelineno-4-6> 6</a></span>
<span class=normal><a href=#__codelineno-4-7> 7</a></span>
<span class=normal><a href=#__codelineno-4-8> 8</a></span>
<span class=normal><a href=#__codelineno-4-9> 9</a></span>
<span class=normal><a href=#__codelineno-4-10>10</a></span>
<span class=normal><a href=#__codelineno-4-11>11</a></span>
<span class=normal><a href=#__codelineno-4-12>12</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-4-1 name=__codelineno-4-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_iris</span>  
<a id=__codelineno-4-2 name=__codelineno-4-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>  
<a id=__codelineno-4-3 name=__codelineno-4-3></a><span class=c1># 获取鸢尾花数据集  </span>
<a id=__codelineno-4-4 name=__codelineno-4-4></a>
<a id=__codelineno-4-5 name=__codelineno-4-5></a><span class=k>def</span><span class=w> </span><span class=nf>datasets_demo</span><span class=p>():</span>  
<a id=__codelineno-4-6 name=__codelineno-4-6></a>    <span class=n>iris</span> <span class=o>=</span> <span class=n>load_iris</span><span class=p>()</span>  
<a id=__codelineno-4-7 name=__codelineno-4-7></a>    <span class=c1># print("鸢尾花数据集：\n",iris)  </span>
<a id=__codelineno-4-8 name=__codelineno-4-8></a>    <span class=c1># print("查看数据集描述：\n",iris["DESCR"])  </span>
<a id=__codelineno-4-9 name=__codelineno-4-9></a>    <span class=c1># print("查看特征值的名字,\n",iris.feature_names)  </span>
<a id=__codelineno-4-10 name=__codelineno-4-10></a>    <span class=c1># 数据集划分  </span>
<a id=__codelineno-4-11 name=__codelineno-4-11></a>    <span class=n>x_train</span><span class=p>,</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_train</span><span class=p>,</span><span class=n>y_test</span><span class=o>=</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>,</span><span class=n>iris</span><span class=o>.</span><span class=n>target</span><span class=p>,</span><span class=n>test_size</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)</span><span class=c1># 默认的情况下是0.25  </span>
<a id=__codelineno-4-12 name=__codelineno-4-12></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"训练集的特征值为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>x_train</span><span class=p>,</span><span class=n>x_train</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span><span class=c1># 后一个是输出数据集的行数</span>
</code></pre></div></td></tr></tbody></table></div> <p>通过这种方式输出，获取测试集和训练集的特征值和标签值（就是字典的标签和特征） </p> <h3 id=_20>特征工程的介绍<a class=headerlink href=#_20 title="Permanent link">¶</a></h3> <p>使用的<strong>算法，特征工程</strong>导致的效果的差别 </p> <hr> <p><strong>数据和特征</strong>决定了机器学习的上限，而<strong>模型和算法</strong>只是逼近这个上限 </p> <h4 id=_21>什么是特征工程<a class=headerlink href=#_21 title="Permanent link">¶</a></h4> <div class="admonition tip"> <p class=admonition-title>什么 </p> <p>使用专业的背景知识和技巧处理数据，使得特征能在机器学习中更好地作用。 </p> </div> <p>使用的是： </p> <ul> <li>sklearn：特征工程</li> <li>pandas：数据清洗、数据处理<br> 包括：<br> 特征抽取<br> 特征预处理<br> 特征降维</li> </ul> <h4 id=_22>特征提取<a class=headerlink href=#_22 title="Permanent link">¶</a></h4> <div class="admonition tip"> <p class=admonition-title>什么事特征提取呢 </p> <p>有一个数据集 </p> <p>使用机器学习算法——统计方法——数学公式（但是数学公式不能处理字符串） </p> <p>所以需要将<strong>数据集中的字符串转换为数值的类型</strong> </p> </div> <hr> <p>所以需要的转换： - 字典特征提取（特征离散化） - 文本特征提取 - 图像特征提取（深度学习介绍的）</p> <h4 id=_23>字典特征提取<a class=headerlink href=#_23 title="Permanent link">¶</a></h4> <p><strong>对字典数据进行特征值化</strong> </p> <ul> <li><code>sklearn.feature_extraction.DictVectorizer(sparse=True,...)</code><ul> <li><code>vector</code>：（数学中向量，物理中的矢量）<br> 使用矩阵进行存储（matrix），也就是使用<strong>二维数组</strong>进行存储<br> 向量是一维数组<br> 所以每一个样本就是一个向量，n 个样本就形成了举证</li> <li>父类：转换器类<br> DictVectorizer. fit_transform (X)：字典或者是包含字典的迭代器返回值，返回 spare 矩阵</li> </ul> </li> </ul> <div class="admonition tip"> <p class=admonition-title>实际上 </p> <p>就是将字典中的类别转换为 one-hot 编码</p> </div> <div class="admonition tip"> <p class=admonition-title>使用的方法</p> <ol> <li>引入下面的：<code>from sklearn.feature_extraction import DictVectorizer</code> 抽取的代码 </li> <li>加上下面的：</li> </ol> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-5-1> 1</a></span>
<span class=normal><a href=#__codelineno-5-2> 2</a></span>
<span class=normal><a href=#__codelineno-5-3> 3</a></span>
<span class=normal><a href=#__codelineno-5-4> 4</a></span>
<span class=normal><a href=#__codelineno-5-5> 5</a></span>
<span class=normal><a href=#__codelineno-5-6> 6</a></span>
<span class=normal><a href=#__codelineno-5-7> 7</a></span>
<span class=normal><a href=#__codelineno-5-8> 8</a></span>
<span class=normal><a href=#__codelineno-5-9> 9</a></span>
<span class=normal><a href=#__codelineno-5-10>10</a></span>
<span class=normal><a href=#__codelineno-5-11>11</a></span>
<span class=normal><a href=#__codelineno-5-12>12</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-5-1 name=__codelineno-5-1></a><span class=k>def</span><span class=w> </span><span class=nf>dict_demo</span><span class=p>():</span>  
<a id=__codelineno-5-2 name=__codelineno-5-2></a>    <span class=n>data</span> <span class=o>=</span> <span class=p>[</span>  
<a id=__codelineno-5-3 name=__codelineno-5-3></a>        <span class=p>{</span><span class=s1>'city'</span><span class=p>:</span> <span class=s1>'北京'</span><span class=p>,</span> <span class=s1>'temperature'</span><span class=p>:</span> <span class=mi>100</span><span class=p>},</span>  
<a id=__codelineno-5-4 name=__codelineno-5-4></a>        <span class=p>{</span><span class=s1>'city'</span><span class=p>:</span> <span class=s1>'上海'</span><span class=p>,</span> <span class=s1>'temperature'</span><span class=p>:</span> <span class=mi>60</span><span class=p>},</span>  
<a id=__codelineno-5-5 name=__codelineno-5-5></a>        <span class=p>{</span><span class=s1>'city'</span><span class=p>:</span> <span class=s1>'深圳'</span><span class=p>,</span> <span class=s1>'temperature'</span><span class=p>:</span> <span class=mi>30</span><span class=p>}</span>  
<a id=__codelineno-5-6 name=__codelineno-5-6></a>    <span class=p>]</span>  
<a id=__codelineno-5-7 name=__codelineno-5-7></a><span class=c1>#     1、实例化一个转化器类  </span>
<a id=__codelineno-5-8 name=__codelineno-5-8></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>DictVectorizer</span><span class=p>()</span>  
<a id=__codelineno-5-9 name=__codelineno-5-9></a>    <span class=c1># 2、 调用fit_transform()  </span>
<a id=__codelineno-5-10 name=__codelineno-5-10></a>    <span class=n>data_new</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-5-11 name=__codelineno-5-11></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data_new:"</span><span class=p>,</span><span class=n>data_new</span><span class=p>)</span>  
<a id=__codelineno-5-12 name=__codelineno-5-12></a><span class=n>dict_demo</span><span class=p>()</span>
</code></pre></div></td></tr></tbody></table></div> <ol> <li>最后的输出结果为：<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250824230413.png><img alt src=../png/Pasted%20image%2020250824230413.png></a> </li> </ol> </div> <hr> <p>为什么会出现这种结果？<br> 这个我们就需要分析一下了<br> 主要是因为上面有着<strong>默认</strong>的 <code>sparse=True,...</code> （在什么都不加的时候）<br> 所以将上面的代码中的一句改为 <code>transfer=DictVectorizer(sparse=False)</code> 这种，输出结果就对了<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250825002811.png><img alt src=../png/Pasted%20image%2020250825002811.png></a> </p> <hr> <p><strong>上面的两种形式是等价的</strong><br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250824230413.png><img alt src=../png/Pasted%20image%2020250824230413.png></a><br> 这个是稀疏矩阵，两行是一组 </p> <div class="admonition question"> <p class=admonition-title>特点 </p> <p>将非零值使用位置来表示出来 </p> <p>比如前两行，1 的位置是（1,0），100 的位置是（0,3） </p> <p>这种的目的是什么呢 </p> <p>种类非常多时，0 就会非常多，所以使用这种方法可以<strong>节省内存</strong> </p> </div> <p>通过这样 <code>print("特征名字：\n",transfer.get_feature_names_out())</code> 输出特征名字<br> 输出的结果为：<br> 特征名字：<br> ['city=上海' 'city=北京' 'city=深圳' 'temperature']</p> <p>所以对于字典中的特征都进行了 one-hot 编码 </p> <div class="admonition tip"> <p class=admonition-title>应用场景</p> <ol> <li>数据集中的类别特征比较多时 <ol> <li>将数据集的特征——&gt;字典类型 </li> <li>DictVectorizer 类型转换 </li> </ol> </li> <li>本身拿到的数据的类型就是字典类型</li> </ol> </div> <h4 id=_24>文本特征提取<a class=headerlink href=#_24 title="Permanent link">¶</a></h4> <ul> <li>将单词作为特征来分类是比较合理的</li> <li>句子、单词、短语、字母中<br> 这些中使用单词作为特征<br> 特征：特征词</li> </ul> <hr> <div class="admonition tip"> <p class=admonition-title>方法</p> </div> <ol> <li><code>sklearn.feature_extraction.text.CountVectorizer(stop_words=[])</code> <ol> <li>返回词频矩阵</li> </ol> </li> <li><code>CountVectorizer.fit_transform(X)</code>，X：文本或者是包含文本字符串的可迭代对象，返回值：返回 sparse 矩阵</li> <li><code>CountVectorizer.inverse_transform(X)</code>：X 为 array 数组或者是 sparse 矩阵，返回值为：转换之前的数据格</li> </ol> <hr> <p>举例：<br> 首先引入下面的：<code>from sklearn.feature_extraction.text import CountVectorizer</code><br> 其次加上下面的代码：<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-6-1> 1</a></span>
<span class=normal><a href=#__codelineno-6-2> 2</a></span>
<span class=normal><a href=#__codelineno-6-3> 3</a></span>
<span class=normal><a href=#__codelineno-6-4> 4</a></span>
<span class=normal><a href=#__codelineno-6-5> 5</a></span>
<span class=normal><a href=#__codelineno-6-6> 6</a></span>
<span class=normal><a href=#__codelineno-6-7> 7</a></span>
<span class=normal><a href=#__codelineno-6-8> 8</a></span>
<span class=normal><a href=#__codelineno-6-9> 9</a></span>
<span class=normal><a href=#__codelineno-6-10>10</a></span>
<span class=normal><a href=#__codelineno-6-11>11</a></span>
<span class=normal><a href=#__codelineno-6-12>12</a></span>
<span class=normal><a href=#__codelineno-6-13>13</a></span>
<span class=normal><a href=#__codelineno-6-14>14</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-6-1 name=__codelineno-6-1></a><span class=k>def</span><span class=w> </span><span class=nf>count_demo</span><span class=p>():</span>  
<a id=__codelineno-6-2 name=__codelineno-6-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-6-3 name=__codelineno-6-3></a><span class=sd>    文本特征抽取：countvectorizer  </span>
<a id=__codelineno-6-4 name=__codelineno-6-4></a><span class=sd>    :return:    """</span>    <span class=n>data</span> <span class=o>=</span> <span class=p>[</span><span class=s2>"life is short,i like like python"</span><span class=p>,</span>  
<a id=__codelineno-6-5 name=__codelineno-6-5></a>     <span class=s2>"life is too long,i dislike python"</span><span class=p>]</span>  
<a id=__codelineno-6-6 name=__codelineno-6-6></a>
<a id=__codelineno-6-7 name=__codelineno-6-7></a>    <span class=c1># 1.实例化一个转换器类  </span>
<a id=__codelineno-6-8 name=__codelineno-6-8></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>CountVectorizer</span><span class=p>()</span>  
<a id=__codelineno-6-9 name=__codelineno-6-9></a>    <span class=c1># 2.调用fit_transform  </span>
<a id=__codelineno-6-10 name=__codelineno-6-10></a>    <span class=n>data_new</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-6-11 name=__codelineno-6-11></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data_new:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>data_new</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>  
<a id=__codelineno-6-12 name=__codelineno-6-12></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"特征名字：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>transfer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>())</span>  
<a id=__codelineno-6-13 name=__codelineno-6-13></a>    <span class=k>return</span> <span class=kc>None</span>  
<a id=__codelineno-6-14 name=__codelineno-6-14></a><span class=n>count_demo</span><span class=p>()</span>
</code></pre></div></td></tr></tbody></table></div> 最后的结果为<br> data_new:<br> [[0 1 1 2 0 1 1 0]<br> [1 1 1 0 1 1 0 1]]<br> 特征名字：<br> ['dislike' 'is' 'life' 'like' 'long' 'python' 'short' 'too'] <p></p> <hr> <ol> <li>CountVectorizer () 的方法<br> 统计每个样本特征出现的次数（不统计单个的字母和标点符号）<br> stop_words 停用的词，可以将觉得没有用处的词以列表的形式传进去<br> 还有专门的停用词表<br> 例如 <code>transfer=CountVectorizer(stop_words=["is","to"])</code>，最后的输出结果就是没有 is 和 to 了</li> </ol> <div class="admonition tip"> <p class=admonition-title>出现的是中文的文本时怎么办 </p> <p>就直接将里面的英文改为中文 </p> <p>但是最后的输出结果为 </p> <p>[[0 1] </p> <p>[1 0]] </p> <p>特征名字： </p> <p>['天安门上太阳升' '我爱北京天安门'] </p> <p>所以要有需要的效果的话，需要使用<strong>空格隔开对应的词语</strong> </p> <p>data = ["我爱北京天安门", </p> <p>"天安门上太阳升"]</p> </div> <p>最后的输出结果变成了：<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250825193939.png><img alt src=../png/Pasted%20image%2020250825193939.png></a><br> 还是没有管单个的词语<br> 用于分词的可以使用<strong>结巴分词</strong>，或者之后使用一些专业的库进行分词 </p> <h4 id=_25>文本特征提取的其他方法<a class=headerlink href=#_25 title="Permanent link">¶</a></h4> <p>首先使用清华镜像网站安装 jieba（在内部的终端中）<code>pip install jieba -i https://pypi.tuna.tsinghua.edu.cn/simple/</code> ，并在开头进行引用 </p> <hr> <p>首先看一下这个的功能<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-7-1>1</a></span>
<span class=normal><a href=#__codelineno-7-2>2</a></span>
<span class=normal><a href=#__codelineno-7-3>3</a></span>
<span class=normal><a href=#__codelineno-7-4>4</a></span>
<span class=normal><a href=#__codelineno-7-5>5</a></span>
<span class=normal><a href=#__codelineno-7-6>6</a></span>
<span class=normal><a href=#__codelineno-7-7>7</a></span>
<span class=normal><a href=#__codelineno-7-8>8</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-7-1 name=__codelineno-7-1></a><span class=kn>import</span><span class=w> </span><span class=nn>jieba</span> <span class=c1>#调用</span>
<a id=__codelineno-7-2 name=__codelineno-7-2></a><span class=k>def</span><span class=w> </span><span class=nf>cut_word</span><span class=p>(</span><span class=n>text</span><span class=p>):</span>  
<a id=__codelineno-7-3 name=__codelineno-7-3></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-7-4 name=__codelineno-7-4></a><span class=sd>    进行中文分词："我爱北京天安门"-&gt;"我 爱 北京 天安门"  </span>
<a id=__codelineno-7-5 name=__codelineno-7-5></a><span class=sd>    :param text:    :return:    """</span>    <span class=n>a</span><span class=o>=</span><span class=s2>" "</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>jieba</span><span class=o>.</span><span class=n>cut</span><span class=p>(</span><span class=n>text</span><span class=p>)))</span><span class=c1>#此时是生成器的形式，要强制转换为列表的形式  </span>
<a id=__codelineno-7-6 name=__codelineno-7-6></a>    <span class=nb>print</span><span class=p>(</span><span class=n>a</span><span class=p>)</span>  
<a id=__codelineno-7-7 name=__codelineno-7-7></a>    <span class=nb>print</span><span class=p>(</span><span class=nb>type</span><span class=p>(</span><span class=n>a</span><span class=p>))</span>  
<a id=__codelineno-7-8 name=__codelineno-7-8></a>    <span class=k>return</span> <span class=n>a</span>
</code></pre></div></td></tr></tbody></table></div> 上面函数的输出结果为 <p></p> <div class="admonition tip"> <p class=admonition-title>结果 </p> <p>我爱北京天安门 </p> <p><class &#x27;str&#x27;> </class></p> <p>其中的" ".join (list (jieba.cut (text))) 的意思是 </p> <ol> <li> <p><code>jieba.cut(text)</code>：使用 jieba 库的&nbsp;<code>cut</code>&nbsp;方法对文本&nbsp;<code>text</code>&nbsp;进行分词，返回一个可迭代的分词结果（生成器） </p> </li> <li> <p><code>list(jieba.cut(text))</code>：将分词结果转换为列表，每个元素是一个词语。 </p> </li> <li> <p><code>" ".join(...)</code>：用空格作为分隔符，将列表中的所有词语拼接成一个完整的字符串。</p> </li> </ol> </div> <hr> <p>之后就可以自动的中文分词，中文<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-8-1> 1</a></span>
<span class=normal><a href=#__codelineno-8-2> 2</a></span>
<span class=normal><a href=#__codelineno-8-3> 3</a></span>
<span class=normal><a href=#__codelineno-8-4> 4</a></span>
<span class=normal><a href=#__codelineno-8-5> 5</a></span>
<span class=normal><a href=#__codelineno-8-6> 6</a></span>
<span class=normal><a href=#__codelineno-8-7> 7</a></span>
<span class=normal><a href=#__codelineno-8-8> 8</a></span>
<span class=normal><a href=#__codelineno-8-9> 9</a></span>
<span class=normal><a href=#__codelineno-8-10>10</a></span>
<span class=normal><a href=#__codelineno-8-11>11</a></span>
<span class=normal><a href=#__codelineno-8-12>12</a></span>
<span class=normal><a href=#__codelineno-8-13>13</a></span>
<span class=normal><a href=#__codelineno-8-14>14</a></span>
<span class=normal><a href=#__codelineno-8-15>15</a></span>
<span class=normal><a href=#__codelineno-8-16>16</a></span>
<span class=normal><a href=#__codelineno-8-17>17</a></span>
<span class=normal><a href=#__codelineno-8-18>18</a></span>
<span class=normal><a href=#__codelineno-8-19>19</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-8-1 name=__codelineno-8-1></a><span class=k>def</span><span class=w> </span><span class=nf>cout_chinese_demo</span><span class=p>():</span>  
<a id=__codelineno-8-2 name=__codelineno-8-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-8-3 name=__codelineno-8-3></a><span class=sd>    中文文本的特征抽取  </span>
<a id=__codelineno-8-4 name=__codelineno-8-4></a><span class=sd>    :return:    """</span>    <span class=n>data</span><span class=o>=</span><span class=p>[</span><span class=s2>"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span><span class=p>,</span>  
<a id=__codelineno-8-5 name=__codelineno-8-5></a>          <span class=s2>"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span><span class=p>,</span>  
<a id=__codelineno-8-6 name=__codelineno-8-6></a>          <span class=s2>"如果只用一种方式了解某样事物，你就不会真正了解它。解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span><span class=p>]</span>  
<a id=__codelineno-8-7 name=__codelineno-8-7></a>    <span class=c1># 1、将中文文本进行分词  </span>
<a id=__codelineno-8-8 name=__codelineno-8-8></a>    <span class=n>data_new</span><span class=o>=</span><span class=p>[]</span>  
<a id=__codelineno-8-9 name=__codelineno-8-9></a>    <span class=k>for</span> <span class=n>sent</span> <span class=ow>in</span> <span class=n>data</span><span class=p>:</span>  
<a id=__codelineno-8-10 name=__codelineno-8-10></a>        <span class=n>data_new</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>cut_word</span><span class=p>(</span><span class=n>sent</span><span class=p>))</span>  
<a id=__codelineno-8-11 name=__codelineno-8-11></a>    <span class=c1># 2、实例化一个转换器类  </span>
<a id=__codelineno-8-12 name=__codelineno-8-12></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>CountVectorizer</span><span class=p>(</span><span class=n>stop_words</span><span class=o>=</span><span class=p>[</span><span class=s2>"一种"</span><span class=p>,</span><span class=s2>"所以"</span><span class=p>])</span>  
<a id=__codelineno-8-13 name=__codelineno-8-13></a>    <span class=c1># 3、调用fit_transfrom，输出的结果为矩阵  </span>
<a id=__codelineno-8-14 name=__codelineno-8-14></a>    <span class=n>data_f</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>data_new</span><span class=p>)</span>  
<a id=__codelineno-8-15 name=__codelineno-8-15></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data_new:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>data_f</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>  
<a id=__codelineno-8-16 name=__codelineno-8-16></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"特征名字：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>transfer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>())</span>  
<a id=__codelineno-8-17 name=__codelineno-8-17></a>    <span class=k>return</span> <span class=kc>None</span>  
<a id=__codelineno-8-18 name=__codelineno-8-18></a><span class=c1># cut_word("我爱北京天安门")  </span>
<a id=__codelineno-8-19 name=__codelineno-8-19></a><span class=n>cout_chinese_demo</span><span class=p>()</span>
</code></pre></div></td></tr></tbody></table></div> 实际上就是多了一步，除此之外还多了一个函数<br> 最后的输出结果为<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250825230349.png><img alt src=../png/Pasted%20image%2020250825230349.png></a> <p></p> <p>但是这个输出结果的顺序排的不好，因为我们会想把出现次数高的排在前面 </p> <h3 id=tf-idf>新的提取方法——TF-idf 文本特征提取<a class=headerlink href=#tf-idf title="Permanent link">¶</a></h3> <p><strong>关键词</strong>：在某一个类别文章中，出现的次数很多，但是在其他类别的文章中出现的很少 </p> <ul> <li>主要的思想：某个词或短语在一篇文章中出现的概率高，并且在其他文章中很少出现，则认为此词具有很好的类别区分能力，适合用来分类</li> <li>作用：用于评估一字词对于某一文件集或者一个语料库中的其中一份文件的重要程度</li> </ul> <hr> <ul> <li>TfdfVectorize<br> TF-IDF——重要程度<br> 例如：<strong>两个词</strong>：“经济”，“非常”<br> 一共 1000 篇文章<br> 其中 100 篇文章有“<strong>非常</strong>”<br> 10 篇文章——“经济”<br> 两篇文章：<br> 文章 A（100 词）：10 次“经济”：0.2<br> TF：10/100=0.1<br> idf=lg 1000/10=2<br> 文章 B（100 词）：10 次“非常” : 0.1<br> TF: 10/100=0.1<br> idf: log 10 (1000/100)=1</li> </ul> <p>公式： </p> <ul> <li>词频（TF）指的是给定的词语在该文件中出现的频率</li> <li>逆向文档频率（idf）：一个词语普遍重要性的度量——由<strong>总文件数目除以包含该词语文件的数目，再将得到的商取以 10 为底的对数</strong><br> 最后的计算公式：（两个数值相乘即可） </li> </ul> <div class=arithmatex>\[ \mathrm{tfidf_{i,j}=tf_{i,j}\times idf_i} \]</div> <p>最后得到的结果就是<strong>重要程度</strong> </p> <h4 id=api_1>API<a class=headerlink href=#api_1 title="Permanent link">¶</a></h4> <ul> <li><code>sklearn.feature extraction.text.TfidfVectorizer(stop words=None,...)</code> 实例化</li> <li>返回词的权重矩阵<ul> <li><code>TfidfVectorizer.fitttransform(X)</code><br> x: 文本或者包含文本的字符串的可迭代对象<br> 返回值：返回 sparse 矩阵（使用 toarray 变为数组的形式）</li> </ul> </li> </ul> <p>加上后面的 <code>from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer</code><br> 再有后面的代码：<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-9-1> 1</a></span>
<span class=normal><a href=#__codelineno-9-2> 2</a></span>
<span class=normal><a href=#__codelineno-9-3> 3</a></span>
<span class=normal><a href=#__codelineno-9-4> 4</a></span>
<span class=normal><a href=#__codelineno-9-5> 5</a></span>
<span class=normal><a href=#__codelineno-9-6> 6</a></span>
<span class=normal><a href=#__codelineno-9-7> 7</a></span>
<span class=normal><a href=#__codelineno-9-8> 8</a></span>
<span class=normal><a href=#__codelineno-9-9> 9</a></span>
<span class=normal><a href=#__codelineno-9-10>10</a></span>
<span class=normal><a href=#__codelineno-9-11>11</a></span>
<span class=normal><a href=#__codelineno-9-12>12</a></span>
<span class=normal><a href=#__codelineno-9-13>13</a></span>
<span class=normal><a href=#__codelineno-9-14>14</a></span>
<span class=normal><a href=#__codelineno-9-15>15</a></span>
<span class=normal><a href=#__codelineno-9-16>16</a></span>
<span class=normal><a href=#__codelineno-9-17>17</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-9-1 name=__codelineno-9-1></a><span class=k>def</span><span class=w> </span><span class=nf>tfidf_demo</span><span class=p>():</span>  
<a id=__codelineno-9-2 name=__codelineno-9-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-9-3 name=__codelineno-9-3></a><span class=sd>    使用tf-idf的方法进行文本特征提取  </span>
<a id=__codelineno-9-4 name=__codelineno-9-4></a><span class=sd>    :return:    """</span>    <span class=n>data</span><span class=o>=</span><span class=p>[</span><span class=s2>"一种还是一种今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。"</span><span class=p>,</span>  
<a id=__codelineno-9-5 name=__codelineno-9-5></a>          <span class=s2>"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。"</span><span class=p>,</span>  
<a id=__codelineno-9-6 name=__codelineno-9-6></a>          <span class=s2>"如果只用一种方式了解某样事物，你就不会真正了解它。解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。"</span><span class=p>]</span>  
<a id=__codelineno-9-7 name=__codelineno-9-7></a>    <span class=c1># 将中文文本进行分词  </span>
<a id=__codelineno-9-8 name=__codelineno-9-8></a>    <span class=n>data_new</span><span class=o>=</span><span class=p>[]</span>  
<a id=__codelineno-9-9 name=__codelineno-9-9></a>    <span class=k>for</span> <span class=n>sent</span> <span class=ow>in</span> <span class=n>data</span><span class=p>:</span>  
<a id=__codelineno-9-10 name=__codelineno-9-10></a>        <span class=n>data_new</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>cut_word</span><span class=p>(</span><span class=n>sent</span><span class=p>))</span>  
<a id=__codelineno-9-11 name=__codelineno-9-11></a>    <span class=c1># 实例化一个转换器类,新的转换器  </span>
<a id=__codelineno-9-12 name=__codelineno-9-12></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>TfidfVectorizer</span><span class=p>(</span><span class=n>stop_words</span><span class=o>=</span><span class=p>[</span><span class=s2>"一种"</span><span class=p>,</span><span class=s2>"所以"</span><span class=p>])</span>  <span class=c1>#主要改这个地方</span>
<a id=__codelineno-9-13 name=__codelineno-9-13></a>    <span class=c1># 调用fit_transfrom  </span>
<a id=__codelineno-9-14 name=__codelineno-9-14></a>    <span class=n>data_f</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>data_new</span><span class=p>)</span>  
<a id=__codelineno-9-15 name=__codelineno-9-15></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data_new:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>data_f</span><span class=o>.</span><span class=n>toarray</span><span class=p>())</span>  
<a id=__codelineno-9-16 name=__codelineno-9-16></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"特征名字：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>transfer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>())</span>  
<a id=__codelineno-9-17 name=__codelineno-9-17></a>    <span class=k>return</span> <span class=kc>None</span>
</code></pre></div></td></tr></tbody></table></div><p></p> <p>最后的输出结果<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250826155338.png><img alt src=../png/Pasted%20image%2020250826155338.png></a></p> <h3 id=_26>特征预处理<a class=headerlink href=#_26 title="Permanent link">¶</a></h3> <h4 id=_27>什么是特征预处理<a class=headerlink href=#_27 title="Permanent link">¶</a></h4> <p>通过一些转换函数将特征数据转换成更加<strong>适合算法模型</strong>的特征数据过程 </p> <ul> <li>包含内容<br> 数值型数据的无量纲化<ul> <li>归一化</li> <li>标准化</li> </ul> </li> <li>特征预处理 API：<code>sklearn.preprocessing</code></li> </ul> <hr> <p>我们为什么要进行归一化？<br> 使用距离公式计算两个样本之间的距离，但是由于某一特征的数值过大，导致距离取决于数值大的特征，但是我们现在认为特征是同等重要的<br> 所以我们用到无量纲化，使得<strong>特征变为同一规格</strong> </p> <h4 id=_28>归一化<a class=headerlink href=#_28 title="Permanent link">¶</a></h4> <p><strong>定义</strong>：<br> 通过对原始数据进行变换把数据映射到默认的[0,1]之间<br> <strong>定义</strong>： </p> <div class=arithmatex>\[ X^{\prime}=\frac{x-min}{max-min}\quad X^{\prime\prime}=X^{\prime}*(mx-mi)+mi \]</div> <div class="admonition tip"> <p class=admonition-title>说明 </p> <p>作用于每一列，max 为一列的最大值，min 为一列的最小值，<span class=arithmatex>\(x^{''}\)</span> 为最终的结果 </p> <p>mx, mi 分别为指定区间，默认 mx 为 1，mi 为 0 </p> </div> <p>实际上就是将每一列的数值放缩平移到数轴上的[0,1]区间 </p> <p><strong>方法</strong>： </p> <ul> <li><code>sklearn.preprocessing.MinMaxScaler (feature range=(0,1)...)</code><ul> <li><code>MinMaxScalar.fit transform(X)</code><ul> <li>x: numpy array 格式的数据 [n_samples, n_features]（就是一个数组）</li> </ul> </li> <li>返回值：转换后的形状形同的 array</li> </ul> </li> </ul> <hr> <p>例子： </p> <div class="admonition tip"> <p class=admonition-title>方法</p> <ul> <li>首先使用 panda 函数获取数据：<code>data=pd.read_csv("dating.txt",sep='\t')</code>，panda 也是需要安装的，其中的 dating. text 文件必须在同样的目录下 </li> <li>实例化转化器类： <ul> <li>头文件：<code>from sklearn.preprocessing import MinMaxScaler</code> </li> <li><code>transfer=MinMaxScaler(feature_range=(2,3))</code> </li> </ul> </li> <li> <ul> <li><code>data_new=transfer.fit_transform(data)</code><br> 最后的代码：</li> </ul> <p>调用转化： </p> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-10-1> 1</a></span>
<span class=normal><a href=#__codelineno-10-2> 2</a></span>
<span class=normal><a href=#__codelineno-10-3> 3</a></span>
<span class=normal><a href=#__codelineno-10-4> 4</a></span>
<span class=normal><a href=#__codelineno-10-5> 5</a></span>
<span class=normal><a href=#__codelineno-10-6> 6</a></span>
<span class=normal><a href=#__codelineno-10-7> 7</a></span>
<span class=normal><a href=#__codelineno-10-8> 8</a></span>
<span class=normal><a href=#__codelineno-10-9> 9</a></span>
<span class=normal><a href=#__codelineno-10-10>10</a></span>
<span class=normal><a href=#__codelineno-10-11>11</a></span>
<span class=normal><a href=#__codelineno-10-12>12</a></span>
<span class=normal><a href=#__codelineno-10-13>13</a></span>
<span class=normal><a href=#__codelineno-10-14>14</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-10-1 name=__codelineno-10-1></a><span class=k>def</span><span class=w> </span><span class=nf>minmax_demo</span><span class=p>():</span>  
<a id=__codelineno-10-2 name=__codelineno-10-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-10-3 name=__codelineno-10-3></a><span class=sd>    归一化  </span>
<a id=__codelineno-10-4 name=__codelineno-10-4></a><span class=sd>    :return:    """</span><span class=c1>#     1. 获取数据  </span>
<a id=__codelineno-10-5 name=__codelineno-10-5></a>    <span class=n>data</span><span class=o>=</span><span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>"dating.txt"</span><span class=p>,</span><span class=n>sep</span><span class=o>=</span><span class=s1>'</span><span class=se>\t</span><span class=s1>'</span><span class=p>)</span>  
<a id=__codelineno-10-6 name=__codelineno-10-6></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-10-7 name=__codelineno-10-7></a>    <span class=n>data</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,:</span><span class=mi>3</span><span class=p>]</span>  
<a id=__codelineno-10-8 name=__codelineno-10-8></a><span class=c1># 2.实例化一个转换器类  </span>
<a id=__codelineno-10-9 name=__codelineno-10-9></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>MinMaxScaler</span><span class=p>(</span><span class=n>feature_range</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span><span class=mi>3</span><span class=p>))</span>  
<a id=__codelineno-10-10 name=__codelineno-10-10></a>
<a id=__codelineno-10-11 name=__codelineno-10-11></a><span class=c1># 3. 调用fit_transform转化  </span>
<a id=__codelineno-10-12 name=__codelineno-10-12></a>    <span class=n>data_new</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-10-13 name=__codelineno-10-13></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data_new:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>data_new</span><span class=p>)</span>  
<a id=__codelineno-10-14 name=__codelineno-10-14></a>    <span class=k>return</span> <span class=kc>None</span>
</code></pre></div></td></tr></tbody></table></div> </li> </ul> </div> <div class="admonition tip"> <p class=admonition-title>输出结果</p> <p>data_new:<br> [[2.43582641 2.58819286 2.53237967]<br> [2. 2.48794044 3. ]<br> [2.19067405 2. 2.43571351]<br> [3. 3. 2.19139157]<br> [2.3933518 2.01947089 2. ]] </p> </div> <hr> <p>分析一下上面的有什么<strong>缺点</strong>：<br> 如果有异常值的话，一般是最大值或者是最小值产生异常<br> 而我们归一化的时候使用的就是最大值和最小值，非常容易受到异常值的影响<br> <strong>所以这种方法的鲁棒性非常差，只适合传统精确小数据的场景</strong> </p> <h4 id=_29>标准化<a class=headerlink href=#_29 title="Permanent link">¶</a></h4> <ul> <li>定义：<br> 对原始数据变换为均值为 0，标准差为 1 的范围内</li> <li> <p>公式</p> <div class=arithmatex>\[ X^{\prime}=\frac{x-\mathrm{mean}}{\sigma} \]</div> <p>mean 为平均值，<span class=arithmatex>\(\sigma\)</span> 为标准差</p> </li> </ul> <p>所以我们现在再看一下，异常值在有大量数据的情况下不会使标准差产生太大的影响 </p> <hr> <ul> <li><code>sklearn.preprocessing.StandardScaler( )</code><ul> <li>处理之后，每列数据都聚焦在均值为 0. 标准差为 1 的</li> <li><code>StandardScaler.fit_transform(X)</code><ul> <li>X：numpy array 格式的数据（数组形式的）</li> </ul> </li> <li>返回值：转换后形状形同的 array</li> </ul> </li> </ul> <div class="admonition tip"> <p class=admonition-title>步骤</p> <ul> <li>在头文件中加上：<code>from sklearn.preprocessing import MinMaxScaler,StandardScaler</code> </li> <li>加上下面的代码： </li> </ul> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-11-1> 1</a></span>
<span class=normal><a href=#__codelineno-11-2> 2</a></span>
<span class=normal><a href=#__codelineno-11-3> 3</a></span>
<span class=normal><a href=#__codelineno-11-4> 4</a></span>
<span class=normal><a href=#__codelineno-11-5> 5</a></span>
<span class=normal><a href=#__codelineno-11-6> 6</a></span>
<span class=normal><a href=#__codelineno-11-7> 7</a></span>
<span class=normal><a href=#__codelineno-11-8> 8</a></span>
<span class=normal><a href=#__codelineno-11-9> 9</a></span>
<span class=normal><a href=#__codelineno-11-10>10</a></span>
<span class=normal><a href=#__codelineno-11-11>11</a></span>
<span class=normal><a href=#__codelineno-11-12>12</a></span>
<span class=normal><a href=#__codelineno-11-13>13</a></span>
<span class=normal><a href=#__codelineno-11-14>14</a></span>
<span class=normal><a href=#__codelineno-11-15>15</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-11-1 name=__codelineno-11-1></a><span class=k>def</span><span class=w> </span><span class=nf>stand_demo</span><span class=p>():</span>  
<a id=__codelineno-11-2 name=__codelineno-11-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-11-3 name=__codelineno-11-3></a><span class=sd>    标准化  </span>
<a id=__codelineno-11-4 name=__codelineno-11-4></a><span class=sd>    :return:    """</span>    <span class=c1>#     1. 获取数据  </span>
<a id=__codelineno-11-5 name=__codelineno-11-5></a>    <span class=n>data</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>"dating.txt"</span><span class=p>,</span> <span class=n>sep</span><span class=o>=</span><span class=s1>'</span><span class=se>\t</span><span class=s1>'</span><span class=p>)</span>  
<a id=__codelineno-11-6 name=__codelineno-11-6></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-11-7 name=__codelineno-11-7></a>    <span class=n>data</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span> <span class=p>:</span><span class=mi>3</span><span class=p>]</span>  
<a id=__codelineno-11-8 name=__codelineno-11-8></a>    <span class=c1># 2.实例化一个转换器类  </span>
<a id=__codelineno-11-9 name=__codelineno-11-9></a>    <span class=n>transfer</span> <span class=o>=</span> <span class=n>StandardScaler</span><span class=p>()</span>  
<a id=__codelineno-11-10 name=__codelineno-11-10></a>
<a id=__codelineno-11-11 name=__codelineno-11-11></a>    <span class=c1># 3. 调用fit_transform转化  </span>
<a id=__codelineno-11-12 name=__codelineno-11-12></a>    <span class=n>data_new</span> <span class=o>=</span> <span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-11-13 name=__codelineno-11-13></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data_new:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>data_new</span><span class=p>)</span>  
<a id=__codelineno-11-14 name=__codelineno-11-14></a>    <span class=k>return</span> <span class=kc>None</span>  
<a id=__codelineno-11-15 name=__codelineno-11-15></a><span class=n>stand_demo</span><span class=p>()</span>
</code></pre></div></td></tr></tbody></table></div> <ul> <li>最后的输出结果为<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250826180723.png><img alt src=../png/Pasted%20image%2020250826180723.png></a> </li> </ul> </div> <h3 id=_30>特征降维<a class=headerlink href=#_30 title="Permanent link">¶</a></h3> <h4 id=_31>降维<a class=headerlink href=#_31 title="Permanent link">¶</a></h4> <ul> <li>降维：字面上就是降低维度<br> 对于数组来说：维数就是数组嵌套的数目<br> 0 维就是标量（数字）<br> 1 维向量<br> 2 维矩阵<br> n 维</li> <li>二维数组<br> 此处的降维：<strong>降低特征的个数</strong><br> 得到一组<strong>不相关</strong>的主要变量的过程（极大线性无关组）</li> <li>相关特征：<ul> <li>相对湿度和降雨量相关</li> <li>等等，有很多数据是相关的，有很多冗余的数据</li> </ul> </li> </ul> <h4 id=_32>降维的两种方法<a class=headerlink href=#_32 title="Permanent link">¶</a></h4> <ul> <li>特征选择</li> <li>主成分分析</li> </ul> <h4 id=_33>特征选择<a class=headerlink href=#_33 title="Permanent link">¶</a></h4> <ul> <li>定义：<br> 数据中包含冗余和相关变量，旨在从<strong>原有的特征中找出主要的特征</strong></li> <li>方法：<ul> <li>过滤式（filter）：<br> 方差选择法：低方差特征过滤<br> 相关系数：衡量两个特征之间的相关性（相关程度）</li> <li>嵌入式：<br> 决策树——第二天的内容<br> 正则化——第三天的内容<br> 深度学习——第五天的内容</li> </ul> </li> </ul> <h4 id=_34>过滤式<a class=headerlink href=#_34 title="Permanent link">¶</a></h4> <h5 id=_35>低方差特征过滤<a class=headerlink href=#_35 title="Permanent link">¶</a></h5> <p>删除低方差的一些特征 </p> <ul> <li>API：<ul> <li><code>sklearn.feature_selection.VarianceThreshold(threshold=0.0)</code><ul> <li>删除所有的低方差特性（阈值就是后面括号内的值，低于那个的都删掉，默认为 0）</li> <li><code>{Variance.fit transform(X)</code><br> x: 为数组<br> 默认的返回值为所有非 0 的方差特征，即删除所有样本中具有相同值的特征</li> </ul> </li> </ul> </li> </ul> <hr> <div class="admonition tip"> <p class=admonition-title>步骤</p> <ol> <li>在头部引入头文件：<code>from sklearn.feature_selection import VarianceThreshold</code> </li> <li> <p>下面的代码</p> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-12-1> 1</a></span>
<span class=normal><a href=#__codelineno-12-2> 2</a></span>
<span class=normal><a href=#__codelineno-12-3> 3</a></span>
<span class=normal><a href=#__codelineno-12-4> 4</a></span>
<span class=normal><a href=#__codelineno-12-5> 5</a></span>
<span class=normal><a href=#__codelineno-12-6> 6</a></span>
<span class=normal><a href=#__codelineno-12-7> 7</a></span>
<span class=normal><a href=#__codelineno-12-8> 8</a></span>
<span class=normal><a href=#__codelineno-12-9> 9</a></span>
<span class=normal><a href=#__codelineno-12-10>10</a></span>
<span class=normal><a href=#__codelineno-12-11>11</a></span>
<span class=normal><a href=#__codelineno-12-12>12</a></span>
<span class=normal><a href=#__codelineno-12-13>13</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-12-1 name=__codelineno-12-1></a><span class=k>def</span><span class=w> </span><span class=nf>variance_demo</span><span class=p>():</span>  
<a id=__codelineno-12-2 name=__codelineno-12-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-12-3 name=__codelineno-12-3></a><span class=sd>    过滤低方差特征  </span>
<a id=__codelineno-12-4 name=__codelineno-12-4></a><span class=sd>    :return:    """</span>    <span class=c1>#     获取数据  </span>
<a id=__codelineno-12-5 name=__codelineno-12-5></a>    <span class=n>data</span><span class=o>=</span><span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>"va.csv"</span><span class=p>)</span>  
<a id=__codelineno-12-6 name=__codelineno-12-6></a>    <span class=n>data</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=mi>3</span><span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>  
<a id=__codelineno-12-7 name=__codelineno-12-7></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-12-8 name=__codelineno-12-8></a>    <span class=c1># 实例化一个转换器类  </span>
<a id=__codelineno-12-9 name=__codelineno-12-9></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>VarianceThreshold</span><span class=p>(</span><span class=n>threshold</span><span class=o>=</span><span class=mi>1000</span><span class=p>)</span>  
<a id=__codelineno-12-10 name=__codelineno-12-10></a>    <span class=c1># 调用fit_transform  </span>
<a id=__codelineno-12-11 name=__codelineno-12-11></a>    <span class=n>data_new</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-12-12 name=__codelineno-12-12></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data_new:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>data_new</span><span class=p>,</span><span class=n>data_new</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  
<a id=__codelineno-12-13 name=__codelineno-12-13></a>    <span class=k>return</span> <span class=kc>None</span>
</code></pre></div></td></tr></tbody></table></div> </li> <li> <p>最后的输出结果为：（要注意调整输出特征的条件） <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250826231618.png><img alt src=../png/Pasted%20image%2020250826231618.png></a></p> </li> </ol> </div> <h4 id=_36>相关系数的求法<a class=headerlink href=#_36 title="Permanent link">¶</a></h4> <ul> <li>皮尔逊相关系数<ul> <li>反应变量之间相关关系密切程度的统计指标</li> </ul> </li> <li> <p>公式</p> <div class=arithmatex>\[ r=\frac{n\sum xy-\sum x\sum y}{\sqrt{n\sum x^2-(\sum x)^2}\sqrt{n\sum y^2-(\sum y)^2}} \]</div> <p>值的绝对值越接近 1，则两个变量的相关程度越大</p> </li> </ul> <div class="admonition tip"> <p class=admonition-title>方法</p> <ul> <li>在前面引入：<code>from scipy.stats import pearsonr</code> </li> <li>加上下面的代码：</li> </ul> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-13-1>1</a></span>
<span class=normal><a href=#__codelineno-13-2>2</a></span>
<span class=normal><a href=#__codelineno-13-3>3</a></span>
<span class=normal><a href=#__codelineno-13-4>4</a></span>
<span class=normal><a href=#__codelineno-13-5>5</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-13-1 name=__codelineno-13-1></a><span class=c1># 计算两个变量之间的相关系数  </span>
<a id=__codelineno-13-2 name=__codelineno-13-2></a><span class=n>r1</span><span class=o>=</span><span class=n>pearsonr</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=s2>"quantity"</span><span class=p>],</span><span class=n>data</span><span class=p>[</span><span class=s2>"unit_price"</span><span class=p>])</span>  
<a id=__codelineno-13-3 name=__codelineno-13-3></a><span class=nb>print</span><span class=p>(</span><span class=s2>"r:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>r1</span><span class=p>)</span>  
<a id=__codelineno-13-4 name=__codelineno-13-4></a><span class=n>r2</span><span class=o>=</span><span class=n>pearsonr</span><span class=p>(</span><span class=n>data</span><span class=p>[</span><span class=s2>"total_sales"</span><span class=p>],</span><span class=n>data</span><span class=p>[</span><span class=s2>"unit_price"</span><span class=p>])</span>  
<a id=__codelineno-13-5 name=__codelineno-13-5></a><span class=nb>print</span><span class=p>(</span><span class=s2>"r:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>r2</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div> </div> <p>计算之后的相关性很高的特征怎么办 </p> <ol> <li>选择其中的一个</li> <li>加权求和</li> <li>主成分分析<br> 从而将相关性高的成分处理掉 </li> </ol> <h3 id=_37>主成分分析<a class=headerlink href=#_37 title="Permanent link">¶</a></h3> <h4 id=_38>什么是主成分分析<a class=headerlink href=#_38 title="Permanent link">¶</a></h4> <ul> <li>定义：将高维数据转化为低位数据的过程中，可能会有舍弃原有的数据，创造新的变量的过程</li> <li>作用：是数据维数压缩，尽可能降低原数据的维数（复杂度），损失少量信息</li> <li>应用：回归分析或者聚类分析当中</li> </ul> <p>我们在拍出三维的视图时，在将三维降到二维的过程中，怎么弄使得信息的损失最少（降维后的信息保留原有的特征） </p> <p>将二维的数据转化为一维的时候，找到一个合适的直线，通过矩阵运算得出主成分分析的结果 </p> <h4 id=api_2>API<a class=headerlink href=#api_2 title="Permanent link">¶</a></h4> <p>怎么在 sklearn 中使用 </p> <ul> <li><code>sklearn.decomposition.PCA(n_components=None)</code><ul> <li>将数据分解为较低维数空间</li> <li>n_components:<ul> <li>小数：表示保留百分之多少的信息</li> <li>整数：减少到多少的特征</li> </ul> </li> <li>PCA. fit_transform (X)</li> <li>返回值为：转换后指定维度的 array</li> </ul> </li> </ul> <h4 id=_39>计算<a class=headerlink href=#_39 title="Permanent link">¶</a></h4> <div class="admonition tip"> <p class=admonition-title>代码</p> <ul> <li>开头调用：<code>from sklearn.decomposition import PCA</code> </li> <li>之后的代码：</li> </ul> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-14-1> 1</a></span>
<span class=normal><a href=#__codelineno-14-2> 2</a></span>
<span class=normal><a href=#__codelineno-14-3> 3</a></span>
<span class=normal><a href=#__codelineno-14-4> 4</a></span>
<span class=normal><a href=#__codelineno-14-5> 5</a></span>
<span class=normal><a href=#__codelineno-14-6> 6</a></span>
<span class=normal><a href=#__codelineno-14-7> 7</a></span>
<span class=normal><a href=#__codelineno-14-8> 8</a></span>
<span class=normal><a href=#__codelineno-14-9> 9</a></span>
<span class=normal><a href=#__codelineno-14-10>10</a></span>
<span class=normal><a href=#__codelineno-14-11>11</a></span>
<span class=normal><a href=#__codelineno-14-12>12</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-14-1 name=__codelineno-14-1></a><span class=k>def</span><span class=w> </span><span class=nf>pca_demo</span><span class=p>():</span>  
<a id=__codelineno-14-2 name=__codelineno-14-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-14-3 name=__codelineno-14-3></a><span class=sd>    pca降维  </span>
<a id=__codelineno-14-4 name=__codelineno-14-4></a><span class=sd>    :return:    """</span>    <span class=n>data</span><span class=o>=</span><span class=p>[</span><span class=mi>2</span><span class=p>,</span><span class=mi>8</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>],[</span><span class=mi>6</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>8</span><span class=p>],[</span><span class=mi>5</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>9</span><span class=p>,</span><span class=mi>1</span><span class=p>](</span><span class=mi>2</span><span class=p>,</span><span class=mi>8</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>5</span><span class=p>],[</span><span class=mi>6</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>0</span><span class=p>,</span><span class=mi>8</span><span class=p>],[</span><span class=mi>5</span><span class=p>,</span><span class=mi>4</span><span class=p>,</span><span class=mi>9</span><span class=p>,</span><span class=mf>1.</span><span class=n>md</span><span class=p>){</span><span class=c1>#e2a168d4a18e20f238432327edc0afe2}  </span>
<a id=__codelineno-14-5 name=__codelineno-14-5></a>
<a id=__codelineno-14-6 name=__codelineno-14-6></a>    <span class=c1>#实例化一个转化器  </span>
<a id=__codelineno-14-7 name=__codelineno-14-7></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>PCA</span><span class=p>(</span><span class=n>n_components</span><span class=o>=</span><span class=mf>0.95</span><span class=p>)</span>  <span class=c1>#保留了95%的信息</span>
<a id=__codelineno-14-8 name=__codelineno-14-8></a>
<a id=__codelineno-14-9 name=__codelineno-14-9></a>    <span class=c1>#调用  </span>
<a id=__codelineno-14-10 name=__codelineno-14-10></a>    <span class=n>data_new</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>data</span><span class=p>)</span>  
<a id=__codelineno-14-11 name=__codelineno-14-11></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"data_new:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>data_new</span><span class=p>)</span>  
<a id=__codelineno-14-12 name=__codelineno-14-12></a>    <span class=k>return</span> <span class=kc>None</span>
</code></pre></div></td></tr></tbody></table></div> </div> <p>最后的输出结果： </p> <div class="admonition tip"> <p class=admonition-title>结果 </p> <p>data_new: </p> <p>[[-1.28620952 e-15 3.82970843 e+00] </p> <p>[-5.74456265 e+00 -1.91485422 e+00] </p> <p>[ 5.74456265 e+00 -1.91485422 e+00]]</p> </div> <h4 id=_40>案例分析：探究用户对物品类别喜好的细分<a class=headerlink href=#_40 title="Permanent link">¶</a></h4> <p>用户物品类别之间的关系 </p> <ol> <li>需要将 user_id 和 aisle 放在同一个表中 </li> <li>将行索引变为用户 ID，列索引变为某一物品的数量（检查表和透视表）</li> <li>特征冗余过多——&gt;PCA 降维</li> </ol> <div class="admonition tip"> <p class=admonition-title>合并</p> <ol> <li>合并 aisles 和 products, 使用 <code>pd.merge</code> </li> <li><code>aisles</code>&nbsp;和&nbsp;<code>products</code>&nbsp;是两个要合并的 DataFrame（数据表） </li> <li><code>on=["aisle_id","aisle_id"]</code>&nbsp;指定了合并的依据是这两个 DataFrame 中都存在的&nbsp;<code>aisle_id</code>&nbsp;列<br> 简单说，这段代码的作用是：根据&nbsp;<code>aisle_id</code>&nbsp;这一列，将&nbsp;<code>aisles</code>&nbsp;和&nbsp;<code>products</code>&nbsp;两个数据表中相关联的记录合并到一起，生成一个新的数据表&nbsp;<code>tab1</code>。</li> </ol> </div> <div class="admonition tip"> <p class=admonition-title>笔记</p> <ol> <li>首先应该安装 jupyter，在 cmd 中使用 pip 安装 </li> <li>之后在 cmd 中打开，选择打开的目录为数据所在的文件 <code>jupyter notebook --notebook-dir=D:\dev\pythonProject1</code> </li> <li>引入头文件，读取数据：<br> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-15-1>1</a></span>
<span class=normal><a href=#__codelineno-15-2>2</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-15-1 name=__codelineno-15-1></a><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>pandas</span>  
<a id=__codelineno-15-2 name=__codelineno-15-2></a><span class=kn>import</span><span class=w> </span><span class=nn>pandas</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>pd</span>  
</code></pre></div></td></tr></tbody></table></div></li> <li>进行数据的读取：<br> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-16-1>1</a></span>
<span class=normal><a href=#__codelineno-16-2>2</a></span>
<span class=normal><a href=#__codelineno-16-3>3</a></span>
<span class=normal><a href=#__codelineno-16-4>4</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-16-1 name=__codelineno-16-1></a><span class=n>products</span><span class=o>=</span><span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>"./archive/products.csv"</span><span class=p>)</span>  
<a id=__codelineno-16-2 name=__codelineno-16-2></a><span class=n>order_products</span><span class=o>=</span><span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>"./archive/order_products__prior.csv"</span><span class=p>)</span>  
<a id=__codelineno-16-3 name=__codelineno-16-3></a><span class=n>orders</span><span class=o>=</span><span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>"./archive/orders.csv"</span><span class=p>)</span>  
<a id=__codelineno-16-4 name=__codelineno-16-4></a><span class=n>aisles</span><span class=o>=</span><span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=s2>"./archive/aisles.csv"</span><span class=p>)</span>  
</code></pre></div></td></tr></tbody></table></div></li> <li>进行多次的数据的合并<br> <code>tab1 = pd.merge(aisles,products, on=["aisle_id","aisle_id"])</code><br> <code>tab2 = pd.merge(tab1 , order_products, on="product_id")</code><br> <code>tab3=pd.merge(tab2,orders,on="order_id")</code> </li> <li>找到所需数据之间的关系（# 3. 找到 user_id 和 aisle 之间的关系）<br> <code>table = pd.crosstab(tab3["user_id"],tab3["aisle"])</code> </li> <li>之后进行数据的降维（之前的内容）（为了简化，可以取一部分）<br> <code>data=table[:20000]</code></li> </ol> </div> <p><code>206209 rows × 134 columns</code> 这是原始的数据，经过简化之后的数据为<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250827220950.png><img alt src=../png/Pasted%20image%2020250827220950.png></a><br> 可见，在 95%的简化之后，列数据减少了很多 </p> <h3 id=_41>总结<a class=headerlink href=#_41 title="Permanent link">¶</a></h3> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.png><img alt src=../png/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.png></a> </p> <h2 id=_42>分类算法<a class=headerlink href=#_42 title="Permanent link">¶</a></h2> <p>目标值：<strong>类别</strong>的话就是分类算法 </p> <h3 id=sklearn>sklearn 的转换器和预估器<a class=headerlink href=#sklearn title="Permanent link">¶</a></h3> <h4 id=_43>转换器<a class=headerlink href=#_43 title="Permanent link">¶</a></h4> <p>我们之前一直在用的就是转换器（特征工程的父类） </p> <ol> <li>实例化（就是一个转换器类）</li> <li>调用 fit_transform（先是 fit，之后是 transform）</li> <li>在标准化的时候<ol> <li>fit：计算每一列的平均值和标准差</li> <li>transform：带入公式中进行最终的转换</li> </ol> </li> </ol> <h4 id=_44>估计器<a class=headerlink href=#_44 title="Permanent link">¶</a></h4> <p>估计器 (estimator)，是一类实现了算法的 API </p> <div class="admonition tip"> <p class=admonition-title>步骤</p> <ol> <li>实例化一个 estimator </li> <li>estimator. fit (x_train, y_train), 这里的 fit 也是在计算 <ol> <li>调用完毕之后模型已经生成了 </li> </ol> </li> <li>模型的评估： <ol> <li>直接比对真实值和预测值<br> y_predict=estimator. predict (x_test)<br> y_test==y_predict </li> <li>计算准确率<br> estimator. score (x_test, y_test)</li> </ol> </li> </ol> </div> <h3 id=k-knn>K-近邻算法（KNN 算法）<a class=headerlink href=#k-knn title="Permanent link">¶</a></h3> <h4 id=_45>什么是<a class=headerlink href=#_45 title="Permanent link">¶</a></h4> <p>通过你的邻居判断出你的类别 </p> <ul> <li>原理：<br> 一个样本中在特征空间中的 k 个<strong>最相似</strong>（即特征空间中<strong>最临近</strong>）的样本中的大多数属于某一个类别，则该样本也属于这个类别<br> 但是 k=1 的时候容易收到异常值的影响</li> <li> <p>计算距离：<br> 距离公式，我们在几何中常用的欧式距离</p> <div class=arithmatex>\[ \begin{aligned}&amp;\text{a(a1,a2,a3),b(b1,b2,b3)}\\&amp;\sqrt{(a1-b1)^{2}+(a2-b2)^{2}+(a3-b3)^{2}}\end{aligned} \]</div> <p>还有曼哈顿距离：就是绝对值距离<br> 明可夫斯基距离 - 电影类型分析<br> k=1：爱情片（最近的已知电影）<br> k-2：爱情片<br> ……<br> k=6 时，不行，因为已知的一共只有六个<br> 当我们的 k 值取值过大时，容易分错（样本不均衡的时候，容易收到影响） - 同样，像之前一样，因为要有求距离，所以需要无量纲化处理 - 使用标准化无量纲化处理</p> </li> </ul> <hr> <h4 id=k-api>k-近邻算法 API<a class=headerlink href=#k-api title="Permanent link">¶</a></h4> <ul> <li><code>sklearn.neighbors.KNeighborsClassifier(n_neighbors=5,algorithm='auto')</code><ul> <li><code>n_neighbors</code>: <code>int</code>, 可选（默认= 5），<code>k_neighbors</code> 查询默认使用的邻居数 （这就是 k 值）</li> <li><code>algorithm</code>: <code>{'auto', 'ball_tree', 'kd_tree', 'brute'}</code>，可选用予计算最近邻居的算法：<code>'ball_tree'</code> 将会使用 <code>BallTree</code>，<code>'kd_tree'</code> 将会使用 <code>KDTree</code>。<code>'auto'</code> 将尝试根据传递给 <code>fit</code> 方法的值来决定最合适的算法。（不同实现方式影响效率）</li> </ul> </li> </ul> <h4 id=_46>案例：鸢尾花案例<a class=headerlink href=#_46 title="Permanent link">¶</a></h4> <div class="admonition tip"> <p class=admonition-title>步骤</p> <ol> <li>获取数据 </li> <li>数据集划分 </li> <li>特征工程 <ol> <li>标准化 </li> </ol> </li> <li>KNN 预估器流程 </li> <li>模型评估</li> </ol> </div> <p>代码： </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-17-1> 1</a></span>
<span class=normal><a href=#__codelineno-17-2> 2</a></span>
<span class=normal><a href=#__codelineno-17-3> 3</a></span>
<span class=normal><a href=#__codelineno-17-4> 4</a></span>
<span class=normal><a href=#__codelineno-17-5> 5</a></span>
<span class=normal><a href=#__codelineno-17-6> 6</a></span>
<span class=normal><a href=#__codelineno-17-7> 7</a></span>
<span class=normal><a href=#__codelineno-17-8> 8</a></span>
<span class=normal><a href=#__codelineno-17-9> 9</a></span>
<span class=normal><a href=#__codelineno-17-10>10</a></span>
<span class=normal><a href=#__codelineno-17-11>11</a></span>
<span class=normal><a href=#__codelineno-17-12>12</a></span>
<span class=normal><a href=#__codelineno-17-13>13</a></span>
<span class=normal><a href=#__codelineno-17-14>14</a></span>
<span class=normal><a href=#__codelineno-17-15>15</a></span>
<span class=normal><a href=#__codelineno-17-16>16</a></span>
<span class=normal><a href=#__codelineno-17-17>17</a></span>
<span class=normal><a href=#__codelineno-17-18>18</a></span>
<span class=normal><a href=#__codelineno-17-19>19</a></span>
<span class=normal><a href=#__codelineno-17-20>20</a></span>
<span class=normal><a href=#__codelineno-17-21>21</a></span>
<span class=normal><a href=#__codelineno-17-22>22</a></span>
<span class=normal><a href=#__codelineno-17-23>23</a></span>
<span class=normal><a href=#__codelineno-17-24>24</a></span>
<span class=normal><a href=#__codelineno-17-25>25</a></span>
<span class=normal><a href=#__codelineno-17-26>26</a></span>
<span class=normal><a href=#__codelineno-17-27>27</a></span>
<span class=normal><a href=#__codelineno-17-28>28</a></span>
<span class=normal><a href=#__codelineno-17-29>29</a></span>
<span class=normal><a href=#__codelineno-17-30>30</a></span>
<span class=normal><a href=#__codelineno-17-31>31</a></span>
<span class=normal><a href=#__codelineno-17-32>32</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-17-1 name=__codelineno-17-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_iris</span>  <span class=c1># 引入数据</span>
<a id=__codelineno-17-2 name=__codelineno-17-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span>  <span class=n>train_test_split</span>  <span class=c1># 模型划分</span>
<a id=__codelineno-17-3 name=__codelineno-17-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.neighbors</span><span class=w> </span><span class=kn>import</span> <span class=n>KNeighborsClassifier</span>  <span class=c1># KNN算法</span>
<a id=__codelineno-17-4 name=__codelineno-17-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>  <span class=c1># 标准化</span>
<a id=__codelineno-17-5 name=__codelineno-17-5></a>
<a id=__codelineno-17-6 name=__codelineno-17-6></a>
<a id=__codelineno-17-7 name=__codelineno-17-7></a><span class=k>def</span><span class=w> </span><span class=nf>knn_iris</span><span class=p>():</span>  
<a id=__codelineno-17-8 name=__codelineno-17-8></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-17-9 name=__codelineno-17-9></a><span class=sd>    使用算法对鸢尾花进行分类  </span>
<a id=__codelineno-17-10 name=__codelineno-17-10></a><span class=sd>    :return:    """</span>    <span class=c1># 获取数据  </span>
<a id=__codelineno-17-11 name=__codelineno-17-11></a>    <span class=n>iris</span><span class=o>=</span><span class=n>load_iris</span><span class=p>()</span>  
<a id=__codelineno-17-12 name=__codelineno-17-12></a>    <span class=c1># 划分数据集  </span>
<a id=__codelineno-17-13 name=__codelineno-17-13></a>    <span class=n>x_train</span><span class=p>,</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_train</span><span class=p>,</span><span class=n>y_test</span><span class=o>=</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>,</span><span class=n>iris</span><span class=o>.</span><span class=n>target</span><span class=p>,</span><span class=n>random_state</span><span class=o>=</span><span class=mi>22</span><span class=p>)</span>  
<a id=__codelineno-17-14 name=__codelineno-17-14></a>
<a id=__codelineno-17-15 name=__codelineno-17-15></a>    <span class=c1># 标准化  </span>
<a id=__codelineno-17-16 name=__codelineno-17-16></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>StandardScaler</span><span class=p>()</span>  
<a id=__codelineno-17-17 name=__codelineno-17-17></a>    <span class=n>x_train</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>x_train</span><span class=p>)</span><span class=c1># 对训练集进行标准化  </span>
<a id=__codelineno-17-18 name=__codelineno-17-18></a>    <span class=n>x_test</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-17-19 name=__codelineno-17-19></a>    <span class=c1># 算法预估器  </span>
<a id=__codelineno-17-20 name=__codelineno-17-20></a>    <span class=n>estimator</span><span class=o>=</span><span class=n>KNeighborsClassifier</span><span class=p>(</span><span class=n>n_neighbors</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>  
<a id=__codelineno-17-21 name=__codelineno-17-21></a>    <span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>  
<a id=__codelineno-17-22 name=__codelineno-17-22></a>    <span class=c1># 模型评估  </span>
<a id=__codelineno-17-23 name=__codelineno-17-23></a>        <span class=c1># 方法一：比较真实值和预测值  </span>
<a id=__codelineno-17-24 name=__codelineno-17-24></a>    <span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-17-25 name=__codelineno-17-25></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"y_predict:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-17-26 name=__codelineno-17-26></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"直接比较的准确率：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_test</span><span class=o>==</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-17-27 name=__codelineno-17-27></a>        <span class=c1># 方法二：计算准确率  </span>
<a id=__codelineno-17-28 name=__codelineno-17-28></a>    <span class=n>score</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_test</span><span class=p>)</span>  
<a id=__codelineno-17-29 name=__codelineno-17-29></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"准确率为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>score</span><span class=p>)</span>  
<a id=__codelineno-17-30 name=__codelineno-17-30></a>    <span class=k>return</span> <span class=kc>None</span>  
<a id=__codelineno-17-31 name=__codelineno-17-31></a><span class=c1># 代码1：KNN算法鸢尾花分类  </span>
<a id=__codelineno-17-32 name=__codelineno-17-32></a><span class=n>knn_iris</span><span class=p>()</span>
</code></pre></div></td></tr></tbody></table></div><p></p> <h4 id=_47>总结<a class=headerlink href=#_47 title="Permanent link">¶</a></h4> <ul> <li>优点：<ul> <li>简单，易于理解，易于实现，无需训练</li> </ul> </li> <li>缺点：<ul> <li>懒惰算法：对测试样本分类是的计算量大，内存开销大</li> <li>必须指定 k 值，k 值选择不当则分类精度不能保证</li> </ul> </li> <li>使用场景：小数据场景</li> </ul> <h3 id=_48>模型选择与调优<a class=headerlink href=#_48 title="Permanent link">¶</a></h3> <h4 id=_49>什么是交叉验证<a class=headerlink href=#_49 title="Permanent link">¶</a></h4> <p><strong>交叉验证</strong>：将得到的<strong>训练数据</strong>分为训练和验证集： 将数据氛围 4 分。其中的一份作为验证集，然后进行 4 次测试，每次都换不同的验证集，即得到 4 组模型的结果，取平均值作为最终的结果 </p> <p>针对<strong>训练集</strong>进行这样的划分，从而使得训练得出的模型更加准确 </p> <h4 id=_50>超参数网格搜索<a class=headerlink href=#_50 title="Permanent link">¶</a></h4> <p>有很多参数是需要手动指定的（k），手动过程过于复杂，所以需要对模型预设几种超参数组合。<strong>每组超参数使用交叉验证，得到最有效的参数</strong> </p> <h4 id=api_3>模型选择与调优 API<a class=headerlink href=#api_3 title="Permanent link">¶</a></h4> <ul> <li><code>sklearn.model_selection.GridSearchCV(estimator, param_grid=None, cv=None)</code><ul> <li>对估计器的指定参数值进行详尽搜索</li> <li><code>estimator</code>：估计器对象 （也是一个预估器的类）</li> <li><code>param_grid</code>：估计器参数（<code>dict</code>，如 <code>{"n_neighbors": [1, 3, 5]}</code> ）（k 的取值，使用字典来传进来）</li> <li><code>cv</code>：指定几折交叉验证 </li> <li><code>fit()</code>：输入训练数据 </li> <li><code>score()</code>：准确率 </li> <li>结果分析: <ul> <li>最佳参数：<code>best_params_</code> </li> <li>最佳结果：<code>best_score_</code> </li> <li>最佳估计器：<code>best_estimator_</code> </li> <li>交叉验证结果：<code>cv_results_</code></li> </ul> </li> </ul> </li> </ul> <p>与上一节相比更改的地方： </p> <ol> <li>导入新的库 <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-18-1>1</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-18-1 name=__codelineno-18-1></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>GridSearchCV</span>
</code></pre></div></td></tr></tbody></table></div></li> <li>算法预估器变为下面的形式： <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-19-1>1</a></span>
<span class=normal><a href=#__codelineno-19-2>2</a></span>
<span class=normal><a href=#__codelineno-19-3>3</a></span>
<span class=normal><a href=#__codelineno-19-4>4</a></span>
<span class=normal><a href=#__codelineno-19-5>5</a></span>
<span class=normal><a href=#__codelineno-19-6>6</a></span>
<span class=normal><a href=#__codelineno-19-7>7</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-19-1 name=__codelineno-19-1></a><span class=c1># 算法预估器  </span>
<a id=__codelineno-19-2 name=__codelineno-19-2></a><span class=n>estimator</span><span class=o>=</span><span class=n>KNeighborsClassifier</span><span class=p>()</span>  
<a id=__codelineno-19-3 name=__codelineno-19-3></a><span class=c1># 加入网格搜索和交叉验证  </span>
<a id=__codelineno-19-4 name=__codelineno-19-4></a><span class=c1># 参数准备  </span>
<a id=__codelineno-19-5 name=__codelineno-19-5></a><span class=n>param_dict</span><span class=o>=</span><span class=p>{</span><span class=s2>"n_neighbors"</span><span class=p>:[</span><span class=mi>1</span><span class=p>,</span><span class=mi>3</span><span class=p>,</span><span class=mi>5</span><span class=p>,</span><span class=mi>7</span><span class=p>,</span><span class=mi>9</span><span class=p>,</span><span class=mi>11</span><span class=p>]}</span>  
<a id=__codelineno-19-6 name=__codelineno-19-6></a><span class=n>estimator</span><span class=o>=</span><span class=n>GridSearchCV</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span><span class=n>param_grid</span><span class=o>=</span><span class=n>param_dict</span><span class=p>,</span><span class=n>cv</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>  
<a id=__codelineno-19-7 name=__codelineno-19-7></a><span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div></li> <li>最后的输出结果更加丰富 <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-20-1>1</a></span>
<span class=normal><a href=#__codelineno-20-2>2</a></span>
<span class=normal><a href=#__codelineno-20-3>3</a></span>
<span class=normal><a href=#__codelineno-20-4>4</a></span>
<span class=normal><a href=#__codelineno-20-5>5</a></span>
<span class=normal><a href=#__codelineno-20-6>6</a></span>
<span class=normal><a href=#__codelineno-20-7>7</a></span>
<span class=normal><a href=#__codelineno-20-8>8</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-20-1 name=__codelineno-20-1></a><span class=c1># 最佳参数：`best_params_`  </span>
<a id=__codelineno-20-2 name=__codelineno-20-2></a><span class=nb>print</span><span class=p>(</span><span class=s2>"最佳参数:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>estimator</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>  
<a id=__codelineno-20-3 name=__codelineno-20-3></a><span class=c1># 最佳结果：`best_score_`  </span>
<a id=__codelineno-20-4 name=__codelineno-20-4></a><span class=nb>print</span><span class=p>(</span><span class=s2>"最佳结果:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>estimator</span><span class=o>.</span><span class=n>best_score_</span><span class=p>)</span>  
<a id=__codelineno-20-5 name=__codelineno-20-5></a><span class=c1># 最佳估计器：`best_estimator_`  </span>
<a id=__codelineno-20-6 name=__codelineno-20-6></a><span class=nb>print</span><span class=p>(</span><span class=s2>"最佳估计器:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>estimator</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>  
<a id=__codelineno-20-7 name=__codelineno-20-7></a><span class=c1># 交叉验证结果：`cv_results_`  </span>
<a id=__codelineno-20-8 name=__codelineno-20-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>"最佳交叉验证结果:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>estimator</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div></li> </ol> <p>输出结果：<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250828213621.png><img alt src=../png/Pasted%20image%2020250828213621.png></a> </p> <p>我们现在的流程已经全部有了 </p> <h4 id=facebook>预测 facebook 签到位置<a class=headerlink href=#facebook title="Permanent link">¶</a></h4> <p>kaggle 上的比赛 </p> <ul> <li>train. csv. test. csv<ul> <li>x, y 坐标</li> <li>准确性：定位准确性</li> <li>时间：时间戳</li> <li>place_id：业务的 ID，预测的目标<br> 还是使用 <code>D:\dev\pythonProject1&gt;jupyter notebook</code> 新建（右侧）python 3<br> 这个 jupyter 好像是一步步手动运行的</li> </ul> </li> </ul> <div class="admonition tip"> <p class=admonition-title>步骤</p> </div> <ol> <li>数据的处理：（特征值 x 和目标值 y）<ol> <li>缩小数据范围的处理（将 x 的坐标放在 2,2.5，y 放在 1,1.5 之间）<code>data=data.query("x&lt;2.5&amp;x&gt;2&amp;y&gt;1&amp;y&lt;1.5") data</code></li> <li>（b.time-&gt;年月日和时分秒），使得时间有意义化</li> <li>过滤签到次数少的地点</li> </ol> </li> <li>特征工程：标准化</li> <li>KNN 算法预估流程</li> <li>模型选择与调优</li> <li>模型评估</li> </ol> <p>注意这个课程是需要在看完数据分析与挖掘基础之后再来学习的，数据分析课程下边会有链接点击后直接跳转至此课程的 </p> <hr> <p>发现最难的地方还是在数据处理上 </p> <h3 id=_51>朴素贝叶斯算法<a class=headerlink href=#_51 title="Permanent link">¶</a></h3> <h4 id=_52>什么是朴素贝叶斯算法的分类方式<a class=headerlink href=#_52 title="Permanent link">¶</a></h4> <p>KNN 直接出分到哪一类了<br> 但是朴素贝叶斯算法分完之后是各种结果的概率值<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250829132703.png><img alt src=../png/Pasted%20image%2020250829132703.png></a> </p> <h4 id=_53>概率的基础知识<a class=headerlink href=#_53 title="Permanent link">¶</a></h4> <ul> <li>概率的定义：<ul> <li>一件事情发生的可能性<ul> <li>扔出一个硬币，结果头像朝上的可能性</li> </ul> </li> <li>P (X)：取值在[0,1]</li> </ul> </li> </ul> <p>相互独立的定义，还有贝叶斯公式 </p> <div class=arithmatex>\[ P(C|W)=\frac{P(W|C)P(C)}{P(W)} \]</div> <ul> <li>朴素贝叶斯算法：<br> 朴素+贝叶斯<br> 朴素就是假定特征之间是相互独立的<br> 贝叶斯就是贝叶斯公式</li> <li>应用场景：<br> 文本分类（以单词作为特征，词与词之间是相互独立的）</li> </ul> <div class=arithmatex>\[ P(C|F1,F2,...)=\frac{P(F1,F2,...|C)P(C)}{P(F1,F2,...)} \]</div> <p>也就是这里的 <span class=arithmatex>\(F_1,F_2\)</span> …… 这些是相互独立的，所以右边分子上的条件概率可以分开计算（乘出来） </p> <div class=arithmatex>\[ 变为P(F_1|C)P(F_2|C)…… \]</div> <p>但是当这里的<strong>乘的一项为 0 时怎么办</strong>（样本的数据太少）： </p> <ul> <li> <p>拉普拉斯平滑系数：</p> <div class=arithmatex>\[ P(F1|C)=\frac{Ni+\alpha}{N+\alpha m} \]</div> <p><span class=arithmatex>\(\alpha\)</span> 为指定的系数，一般为 1，m 为训练集（不仅仅是 C 集）中统计出的特征词的个数（特征词的种类），<span class=arithmatex>\(Ni\)</span> 为该特征&nbsp;<strong>F₁</strong>&nbsp;在类别&nbsp;<strong>C</strong>&nbsp;中出现的次数<br> <strong>N</strong>&nbsp;通常表示在类别&nbsp;<strong>C</strong>&nbsp;中所有特征（或词语）出现的总次数，也就是类别&nbsp;<strong>C</strong>&nbsp;下的样本总量（或词频总和）<br> <strong>必须是在 C 集</strong>的条件下</p> </li> </ul> <h4 id=api_4>API<a class=headerlink href=#api_4 title="Permanent link">¶</a></h4> <ul> <li>sklearn. naive_bayes.MultinomialNB (alpha = 1.0)</li> <li>朴素贝叶斯分类</li> <li>alpha: 拉普拉斯<strong>平滑系数</strong></li> </ul> <h4 id=20>案例：20 类新闻分类<a class=headerlink href=#20 title="Permanent link">¶</a></h4> <div class="admonition tip"> <p class=admonition-title>步骤</p> <ol> <li>获取数据 <code>from sklearn.datasets import fetch_20newsgroups</code> </li> <li>划分数据集（文字的）<code>from sklearn.feature_extraction.text import TfidfVectorizer</code> </li> <li>特征工程<br> 文本特征抽取 </li> <li>朴素贝叶斯预估器流程 <code>from sklearn.naive_bayes import MultinomialNB</code> </li> <li>模型评估</li> </ol> </div> <p>代码：<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-21-1> 1</a></span>
<span class=normal><a href=#__codelineno-21-2> 2</a></span>
<span class=normal><a href=#__codelineno-21-3> 3</a></span>
<span class=normal><a href=#__codelineno-21-4> 4</a></span>
<span class=normal><a href=#__codelineno-21-5> 5</a></span>
<span class=normal><a href=#__codelineno-21-6> 6</a></span>
<span class=normal><a href=#__codelineno-21-7> 7</a></span>
<span class=normal><a href=#__codelineno-21-8> 8</a></span>
<span class=normal><a href=#__codelineno-21-9> 9</a></span>
<span class=normal><a href=#__codelineno-21-10>10</a></span>
<span class=normal><a href=#__codelineno-21-11>11</a></span>
<span class=normal><a href=#__codelineno-21-12>12</a></span>
<span class=normal><a href=#__codelineno-21-13>13</a></span>
<span class=normal><a href=#__codelineno-21-14>14</a></span>
<span class=normal><a href=#__codelineno-21-15>15</a></span>
<span class=normal><a href=#__codelineno-21-16>16</a></span>
<span class=normal><a href=#__codelineno-21-17>17</a></span>
<span class=normal><a href=#__codelineno-21-18>18</a></span>
<span class=normal><a href=#__codelineno-21-19>19</a></span>
<span class=normal><a href=#__codelineno-21-20>20</a></span>
<span class=normal><a href=#__codelineno-21-21>21</a></span>
<span class=normal><a href=#__codelineno-21-22>22</a></span>
<span class=normal><a href=#__codelineno-21-23>23</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-21-1 name=__codelineno-21-1></a><span class=k>def</span><span class=w> </span><span class=nf>nb_news</span><span class=p>():</span>  
<a id=__codelineno-21-2 name=__codelineno-21-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-21-3 name=__codelineno-21-3></a><span class=sd>    朴素贝叶斯算法新闻分类  </span>
<a id=__codelineno-21-4 name=__codelineno-21-4></a><span class=sd>    :return:    """</span>    <span class=c1># 1获取数据  </span>
<a id=__codelineno-21-5 name=__codelineno-21-5></a>    <span class=n>news</span><span class=o>=</span><span class=n>fetch_20newsgroups</span><span class=p>(</span><span class=n>subset</span><span class=o>=</span><span class=s2>"all"</span><span class=p>)</span>  
<a id=__codelineno-21-6 name=__codelineno-21-6></a>    <span class=c1>#2. 划分数据集  </span>
<a id=__codelineno-21-7 name=__codelineno-21-7></a>    <span class=n>x_train</span><span class=p>,</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_train</span><span class=p>,</span><span class=n>y_test</span><span class=o>=</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>news</span><span class=o>.</span><span class=n>data</span><span class=p>,</span><span class=n>news</span><span class=o>.</span><span class=n>target</span><span class=p>)</span>  
<a id=__codelineno-21-8 name=__codelineno-21-8></a>    <span class=c1>#3. 文本特征抽取  </span>
<a id=__codelineno-21-9 name=__codelineno-21-9></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>TfidfVectorizer</span><span class=p>()</span>  
<a id=__codelineno-21-10 name=__codelineno-21-10></a>    <span class=n>x_train</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>x_train</span><span class=p>)</span>  
<a id=__codelineno-21-11 name=__codelineno-21-11></a>    <span class=n>x_test</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-21-12 name=__codelineno-21-12></a>    <span class=c1># 朴素贝叶斯算法预估器  </span>
<a id=__codelineno-21-13 name=__codelineno-21-13></a>    <span class=n>estimator</span><span class=o>=</span><span class=n>MultinomialNB</span><span class=p>()</span>  
<a id=__codelineno-21-14 name=__codelineno-21-14></a>    <span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>  
<a id=__codelineno-21-15 name=__codelineno-21-15></a>    <span class=c1># 模型评估  </span>
<a id=__codelineno-21-16 name=__codelineno-21-16></a>    <span class=c1># 方法一：比较真实值和预测值  </span>
<a id=__codelineno-21-17 name=__codelineno-21-17></a>    <span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-21-18 name=__codelineno-21-18></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"y_predict:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-21-19 name=__codelineno-21-19></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"直接比较的准确率：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_test</span><span class=o>==</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-21-20 name=__codelineno-21-20></a>    <span class=c1># 方法二：计算准确率  </span>
<a id=__codelineno-21-21 name=__codelineno-21-21></a>    <span class=n>score</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_test</span><span class=p>)</span>  
<a id=__codelineno-21-22 name=__codelineno-21-22></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"准确率为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>score</span><span class=p>)</span>  
<a id=__codelineno-21-23 name=__codelineno-21-23></a>    <span class=k>return</span> <span class=kc>None</span>
</code></pre></div></td></tr></tbody></table></div><p></p> <h4 id=_54>总结<a class=headerlink href=#_54 title="Permanent link">¶</a></h4> <ul> <li>优点：<ul> <li>有稳定的分类效率</li> <li>对缺失的数据不敏感</li> <li>分类准确度高，速度快</li> </ul> </li> <li>缺点：<ul> <li>由于使用了样本属性独立性的假设，所以如果特征属性有关联时其效果不好</li> </ul> </li> </ul> <h3 id=_55>决策树<a class=headerlink href=#_55 title="Permanent link">¶</a></h3> <h4 id=_56>认识决策树<a class=headerlink href=#_56 title="Permanent link">¶</a></h4> <p>决策树，就是 if-else 的方式进行分类<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250829154631.png><img alt src=../png/Pasted%20image%2020250829154631.png></a> </p> <h4 id=_57>决策树的分类原理详解<a class=headerlink href=#_57 title="Permanent link">¶</a></h4> <p>怎么知道原理的先后 </p> <p>已知四个特征，预测是否贷款给某个人 </p> <ul> <li>有房子的都是<ul> <li>在没有房子的里面：有工作的都是<br> 已经能决定是否贷款了</li> </ul> </li> <li>先看年龄，再看信贷情况，最后看工作看了三个特征</li> <li>所以可以看出最高效的特征为第一种</li> </ul> <div class="admonition tip"> <p class=admonition-title>原理</p> <ul> <li>信息熵：信息增益 </li> <li>信息熵的定义： <ul> <li> <p>H 的专业术语称之为信息熵，单位为<strong>比特</strong></p> <div class=arithmatex>\[ H(X)=-\sum_{i=1}^nP(x_i)logbP(x_i)) \]</div> </li> </ul> </li> </ul> </div> <hr> <ol> <li>信息：消除随机不确定性的东西<br> 小明年龄：今年 18 岁（是信息）<br> 小华说小明明年 19 岁（在上面的基础上的推论，不是信息）</li> <li>如何量化信息量：<br> 信息熵：<span class=arithmatex>\(H(X)=-\sum_{i=1}^nP(x_i)logbP(x_i))\)</span>，这里对数的底数一般是 2</li> </ol> <p>已知某人的年龄，工作，房子，信贷情况等等，消除是否贷款的不确定性<br> 怎么使用上面的信息熵的公式求出 H (x)？ </p> <div class=arithmatex>\[ \bar{H}(\text{总})=-(6/15^{\star}\log6/15+9/15^{\star}\log9/15) \]</div> <ol> <li> <p>信息增益：</p> <div class=arithmatex>\[ g\left(D,A\right)=H\left(D\right)-H\left(D\right|A) \]</div> <p>计算公式 </p> <div class=arithmatex>\[ H(D|A)=\sum_{i=1}^n\frac{|D_i|}{|D|}H(D_i)=-\sum_{i=1}^n\frac{|D_i|}{|D|}\sum_{k=1}^K\frac{|D_{ik}|}{|D_i|}\log\frac{|D_{ik}|}{|D_i|} \]</div> <p>使用总的信息熵减去知道某个信息之后的信息熵就是信息增益<br> 例如上面的例子中，知道年龄之后的信息增益为为<br> A 是用于划分数据集的特征，如年龄，性别等，将数据集 D 划分为多个子集<br> 特征 A 取第 i 个值时，对应的样本子集（如 A 是 “性别”，D₁= 男性样本，D₂= 女性样本）</p> </li> </ol> <h4 id=api_5>决策树的 API<a class=headerlink href=#api_5 title="Permanent link">¶</a></h4> <ul> <li>class sklearn.tree.DecisionTreeClassifier (criterion='gini', max_depth=None, random_state=None)</li> <li>决策树分类器</li> <li>criterion: 默认是'gini'系数，也可以选择信息增益的熵'entropy'</li> <li>max_depth: 树的深度大小（深度过大的话会过拟合）</li> <li>random_state: 随机种子</li> </ul> <p>过拟合会导致模型泛化能力差，即过度适合当前样本集而缺乏适应（预测）新样本的能力 </p> <p>完整的代码：<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-22-1> 1</a></span>
<span class=normal><a href=#__codelineno-22-2> 2</a></span>
<span class=normal><a href=#__codelineno-22-3> 3</a></span>
<span class=normal><a href=#__codelineno-22-4> 4</a></span>
<span class=normal><a href=#__codelineno-22-5> 5</a></span>
<span class=normal><a href=#__codelineno-22-6> 6</a></span>
<span class=normal><a href=#__codelineno-22-7> 7</a></span>
<span class=normal><a href=#__codelineno-22-8> 8</a></span>
<span class=normal><a href=#__codelineno-22-9> 9</a></span>
<span class=normal><a href=#__codelineno-22-10>10</a></span>
<span class=normal><a href=#__codelineno-22-11>11</a></span>
<span class=normal><a href=#__codelineno-22-12>12</a></span>
<span class=normal><a href=#__codelineno-22-13>13</a></span>
<span class=normal><a href=#__codelineno-22-14>14</a></span>
<span class=normal><a href=#__codelineno-22-15>15</a></span>
<span class=normal><a href=#__codelineno-22-16>16</a></span>
<span class=normal><a href=#__codelineno-22-17>17</a></span>
<span class=normal><a href=#__codelineno-22-18>18</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-22-1 name=__codelineno-22-1></a><span class=k>def</span><span class=w> </span><span class=nf>decision_iris</span><span class=p>():</span>  
<a id=__codelineno-22-2 name=__codelineno-22-2></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-22-3 name=__codelineno-22-3></a><span class=sd>    用决策树对鸢尾花进行分类  </span>
<a id=__codelineno-22-4 name=__codelineno-22-4></a><span class=sd>    :return:    """</span>    <span class=c1># 1. 获取数据集  </span>
<a id=__codelineno-22-5 name=__codelineno-22-5></a>    <span class=n>iris</span><span class=o>=</span><span class=n>load_iris</span><span class=p>()</span>  
<a id=__codelineno-22-6 name=__codelineno-22-6></a>    <span class=c1># 2. 划分数据集  </span>
<a id=__codelineno-22-7 name=__codelineno-22-7></a>    <span class=n>x_train</span><span class=p>,</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_train</span><span class=p>,</span><span class=n>y_test</span><span class=o>=</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>iris</span><span class=o>.</span><span class=n>data</span><span class=p>,</span><span class=n>iris</span><span class=o>.</span><span class=n>target</span><span class=p>,</span><span class=n>random_state</span><span class=o>=</span><span class=mi>22</span><span class=p>)</span>  
<a id=__codelineno-22-8 name=__codelineno-22-8></a>    <span class=c1># 3. 决策树预估器  </span>
<a id=__codelineno-22-9 name=__codelineno-22-9></a>    <span class=n>estimator</span><span class=o>=</span><span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>criterion</span><span class=o>=</span><span class=s2>"entropy"</span><span class=p>)</span>  
<a id=__codelineno-22-10 name=__codelineno-22-10></a>    <span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>  
<a id=__codelineno-22-11 name=__codelineno-22-11></a>    <span class=c1># 4，模型评估  </span>
<a id=__codelineno-22-12 name=__codelineno-22-12></a>        <span class=c1># 方法一：比较真实值和预测值  </span>
<a id=__codelineno-22-13 name=__codelineno-22-13></a>    <span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-22-14 name=__codelineno-22-14></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"y_predict:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-22-15 name=__codelineno-22-15></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"直接比较的准确率：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_test</span><span class=o>==</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-22-16 name=__codelineno-22-16></a>        <span class=c1># 方法二：计算准确率  </span>
<a id=__codelineno-22-17 name=__codelineno-22-17></a>    <span class=n>score</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_test</span><span class=p>)</span>  
<a id=__codelineno-22-18 name=__codelineno-22-18></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"准确率为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>score</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div><p></p> <p>新加的头文件：<code>from sklearn.tree import DecisionTreeClassifier</code> </p> <h4 id=_58>决策树的可视化<a class=headerlink href=#_58 title="Permanent link">¶</a></h4> <p>保存树的结构到 dot 文件 </p> <ul> <li>sklearn. tree. export_graphviz () 该函数能够导出 DOT 格式</li> <li>tree. export_graphviz (estimator, out_file="tree. dot", feature_names=[""])<br> estimator：所求的预估器<br> out_file="tree. dot"：路径 </li> </ul> <hr> <p>之后需要借助网站显示文本文件 </p> <div class="admonition tip"> <p class=admonition-title>步骤</p> <ul> <li><code>from sklearn.tree import DecisionTreeClassifier,export_graphviz</code><br> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-23-1>1</a></span>
<span class=normal><a href=#__codelineno-23-2>2</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-23-1 name=__codelineno-23-1></a><span class=c1># 可视化决策树  </span>
<a id=__codelineno-23-2 name=__codelineno-23-2></a><span class=n>export_graphviz</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span> <span class=n>out_file</span><span class=o>=</span><span class=s2>"iris_tree.dot"</span><span class=p>)</span>  
</code></pre></div></td></tr></tbody></table></div></li> </ul> </div> <p>但是没有分类的特征名字：<br> <code>export_graphviz(estimator, out_file="iris_tree.dot",feature_names=iris.feature_names)</code><br> 这样就有特征的名字了 </p> <p>查看的网址：<br> https://dreampuf.github.io/GraphvizOnline/ </p> <p>最后的树：<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/graphviz.png><img alt src=../png/graphviz.png></a> </p> <h4 id=_59>总结<a class=headerlink href=#_59 title="Permanent link">¶</a></h4> <ul> <li>优点：<ul> <li>简单，易于理解</li> <li>可视化-可解释能力强（深度学习神经网络相反）</li> </ul> </li> <li>缺点<ul> <li>处理过于复杂的网络时，容易发生过拟合</li> </ul> </li> <li>改进：<ul> <li>剪枝 cart 算法</li> <li>随机森林</li> </ul> </li> </ul> <h4 id=_60>泰坦尼克号乘客生存的预测案例<a class=headerlink href=#_60 title="Permanent link">¶</a></h4> <ol> <li>获取数据</li> <li>数据处理<ol> <li>缺失值处理</li> <li>有多个特征是类别，将特征值转换为字典类型的</li> <li>筛选特征值和目标值</li> <li>划分数据集</li> <li>特征工程：字典特征获取</li> <li>决策树预估器流程</li> <li>模型评估<br> 最后的输出结果： </li> </ol> </li> </ol> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/31740f175a440817de8160d979da3208.png><img alt src=../png/31740f175a440817de8160d979da3208.png></a> </p> <div class="admonition tip"> <p class=admonition-title>代码</p> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-24-1>1</a></span>
<span class=normal><a href=#__codelineno-24-2>2</a></span>
<span class=normal><a href=#__codelineno-24-3>3</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-24-1 name=__codelineno-24-1></a><span class=c1># 2. 数据处理  </span>
<a id=__codelineno-24-2 name=__codelineno-24-2></a><span class=c1># 1. 缺失值处理  </span>
<a id=__codelineno-24-3 name=__codelineno-24-3></a><span class=n>x</span><span class=p>[</span><span class=s2>"Age"</span><span class=p>]</span><span class=o>.</span><span class=n>fillna</span><span class=p>(</span><span class=n>x</span><span class=p>[</span><span class=s2>"Age"</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>(),</span><span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>  
</code></pre></div></td></tr></tbody></table></div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-25-1>1</a></span>
<span class=normal><a href=#__codelineno-25-2>2</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-25-1 name=__codelineno-25-1></a><span class=c1># 2.转换为字典</span>
<a id=__codelineno-25-2 name=__codelineno-25-2></a><span class=n>x</span><span class=o>=</span><span class=n>x</span><span class=o>.</span><span class=n>to_dict</span><span class=p>(</span><span class=n>orient</span><span class=o>=</span><span class=s2>"records"</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-26-1>1</a></span>
<span class=normal><a href=#__codelineno-26-2>2</a></span>
<span class=normal><a href=#__codelineno-26-3>3</a></span>
<span class=normal><a href=#__codelineno-26-4>4</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-26-1 name=__codelineno-26-1></a><span class=c1># 检查y中是否有缺失值</span>
<a id=__codelineno-26-2 name=__codelineno-26-2></a><span class=nb>print</span><span class=p>(</span><span class=s2>"缺失值数量："</span><span class=p>,</span> <span class=n>pd</span><span class=o>.</span><span class=n>isna</span><span class=p>(</span><span class=n>y</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>())</span>
<a id=__codelineno-26-3 name=__codelineno-26-3></a><span class=c1># 查看缺失值的位置</span>
<a id=__codelineno-26-4 name=__codelineno-26-4></a><span class=nb>print</span><span class=p>(</span><span class=s2>"缺失值索引："</span><span class=p>,</span> <span class=n>pd</span><span class=o>.</span><span class=n>isna</span><span class=p>(</span><span class=n>y</span><span class=p>)</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>pd</span><span class=o>.</span><span class=n>isna</span><span class=p>(</span><span class=n>y</span><span class=p>))</span><span class=o>.</span><span class=n>dropna</span><span class=p>()</span><span class=o>.</span><span class=n>index</span><span class=o>.</span><span class=n>tolist</span><span class=p>())</span>
</code></pre></div></td></tr></tbody></table></div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-27-1>1</a></span>
<span class=normal><a href=#__codelineno-27-2>2</a></span>
<span class=normal><a href=#__codelineno-27-3>3</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-27-1 name=__codelineno-27-1></a><span class=c1># 划分后转换（推荐方法 1，更彻底）</span>
<a id=__codelineno-27-2 name=__codelineno-27-2></a><span class=n>y_test</span> <span class=o>=</span> <span class=n>y_test</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>  <span class=c1># 取第一列转为 Series</span>
<a id=__codelineno-27-3 name=__codelineno-27-3></a><span class=n>y_train</span> <span class=o>=</span> <span class=n>y_train</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>
</code></pre></div></td></tr></tbody></table></div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-28-1> 1</a></span>
<span class=normal><a href=#__codelineno-28-2> 2</a></span>
<span class=normal><a href=#__codelineno-28-3> 3</a></span>
<span class=normal><a href=#__codelineno-28-4> 4</a></span>
<span class=normal><a href=#__codelineno-28-5> 5</a></span>
<span class=normal><a href=#__codelineno-28-6> 6</a></span>
<span class=normal><a href=#__codelineno-28-7> 7</a></span>
<span class=normal><a href=#__codelineno-28-8> 8</a></span>
<span class=normal><a href=#__codelineno-28-9> 9</a></span>
<span class=normal><a href=#__codelineno-28-10>10</a></span>
<span class=normal><a href=#__codelineno-28-11>11</a></span>
<span class=normal><a href=#__codelineno-28-12>12</a></span>
<span class=normal><a href=#__codelineno-28-13>13</a></span>
<span class=normal><a href=#__codelineno-28-14>14</a></span>
<span class=normal><a href=#__codelineno-28-15>15</a></span>
<span class=normal><a href=#__codelineno-28-16>16</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-28-1 name=__codelineno-28-1></a><span class=c1># 3. 决策树预估器</span>
<a id=__codelineno-28-2 name=__codelineno-28-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.tree</span><span class=w> </span><span class=kn>import</span> <span class=n>DecisionTreeClassifier</span><span class=p>,</span> <span class=n>export_graphviz</span>
<a id=__codelineno-28-3 name=__codelineno-28-3></a><span class=n>estimator</span><span class=o>=</span><span class=n>DecisionTreeClassifier</span><span class=p>(</span><span class=n>criterion</span><span class=o>=</span><span class=s2>"entropy"</span><span class=p>,</span><span class=n>max_depth</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span><span class=c1># 设置了树的最大深度</span>
<a id=__codelineno-28-4 name=__codelineno-28-4></a><span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>
<a id=__codelineno-28-5 name=__codelineno-28-5></a><span class=c1># 4，模型评估</span>
<a id=__codelineno-28-6 name=__codelineno-28-6></a>    <span class=c1># 方法一：比较真实值和预测值</span>
<a id=__codelineno-28-7 name=__codelineno-28-7></a><span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
<a id=__codelineno-28-8 name=__codelineno-28-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>"y_test 类型:"</span><span class=p>,</span> <span class=nb>type</span><span class=p>(</span><span class=n>y_test</span><span class=p>))</span>  <span class=c1># 应显示 &lt;class 'pandas.core.series.Series'&gt;</span>
<a id=__codelineno-28-9 name=__codelineno-28-9></a><span class=nb>print</span><span class=p>(</span><span class=s2>"y_test 形状:"</span><span class=p>,</span> <span class=n>y_test</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  <span class=c1># 应显示 (n,)（一维）</span>
<a id=__codelineno-28-10 name=__codelineno-28-10></a><span class=nb>print</span><span class=p>(</span><span class=s2>"y_predict:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>
<a id=__codelineno-28-11 name=__codelineno-28-11></a><span class=nb>print</span><span class=p>(</span><span class=s2>"直接比较的准确率：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_test</span><span class=o>==</span><span class=n>y_predict</span><span class=p>)</span>
<a id=__codelineno-28-12 name=__codelineno-28-12></a>    <span class=c1># 方法二：计算准确率</span>
<a id=__codelineno-28-13 name=__codelineno-28-13></a><span class=n>score</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_test</span><span class=p>)</span>
<a id=__codelineno-28-14 name=__codelineno-28-14></a><span class=nb>print</span><span class=p>(</span><span class=s2>"准确率为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>score</span><span class=p>)</span>
<a id=__codelineno-28-15 name=__codelineno-28-15></a><span class=c1># 可视化决策树</span>
<a id=__codelineno-28-16 name=__codelineno-28-16></a><span class=n>export_graphviz</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span> <span class=n>out_file</span><span class=o>=</span><span class=s2>"titan_tree.dot"</span><span class=p>,</span><span class=n>feature_names</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>get_feature_names_out</span><span class=p>())</span>
</code></pre></div></td></tr></tbody></table></div> </div> <h3 id=_61>随机森林<a class=headerlink href=#_61 title="Permanent link">¶</a></h3> <h4 id=_62>什么是集成学习方法<a class=headerlink href=#_62 title="Permanent link">¶</a></h4> <p>就是众人拾柴火焰高，生成多个分类器，进行预测，取预测的<strong>众数</strong><br> 例如我们训练了 5 棵树，最后取结果的众数 </p> <h4 id=_63>随机森林的原理过程<a class=headerlink href=#_63 title="Permanent link">¶</a></h4> <p>N 个样本中 M 个特征：</p> <ol> <li>特征随机——从 M 个特征中随机抽取 m 个特征<ol> <li>M&gt;&gt;m（起到降维的作用）</li> <li>虽然我们的特征数量变少了，但是会有很多很多的树</li> </ol> </li> <li>训练集随机——每棵树的训练集是随机有放回生成的（N 个样本中随机有放回抽样 N 个）<ol> <li>使用 bootstrap 随机有放回抽样<br> 例如训练集样本为[1,2,3,4,5]<br> 新的训练集：[2,2,3,1,5]</li> </ol> </li> </ol> <h4 id=api_6>API<a class=headerlink href=#api_6 title="Permanent link">¶</a></h4> <ul> <li>class sklearn.ensemble.RandomForestClassifier (n_estimators=10, criterion='gini', max_depth=None, bootstrap=True, random_state=None, min_samples_split=2) <ul> <li>随机森林分类器 </li> <li>n_estimators: integer, optional (default = 10) 森林里的树木数量 120,200,300,500,800,1200 </li> <li>criteria: string, 可选 (default = "gini") 分割特征的测量方法 </li> <li>max_depth: integer 或 None, 可选 (默认=无) 树的最大深度 5,8,15,25,30</li> <li>max_features="auto", 每个决策树的<strong>最大特征数量</strong><ul> <li>If "auto", then max_features=sqrt (n_features).（对 M 求平方根）</li> <li>If "sqrt", then max_features=sqrt (n_features) (same as "auto").（求出平方根）</li> <li>If "log 2", then max_features=log 2 (n_features).（2 为底的对数）</li> <li>If None, then max_features=n_features.（取得值就是 M）</li> </ul> </li> <li>bootstrap: boolean, optional (default = True) 是否在构建树时使用放回抽样</li> <li>min_samples_split: 节点划分最少样本数</li> <li>min_samples_leaf: 叶子节点的最小样本数</li> </ul> </li> <li>超参数: n_estimator, max_depth, min_samples_split, min_samples_leaf</li> </ul> <div class="admonition tip"> <p class=admonition-title>使用</p> <ul> <li>头文件：<br> <code>from sklearn.ensemble import RandomForestClassifier #随机森林 from sklearn.model_selection import GridSearchCV #交叉验证</code> </li> <li>在网格搜索中加上所需的参数：<br> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-29-1>1</a></span>
<span class=normal><a href=#__codelineno-29-2>2</a></span>
<span class=normal><a href=#__codelineno-29-3>3</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-29-1 name=__codelineno-29-1></a><span class=n>param_dict</span><span class=o>=</span><span class=p>{</span><span class=s2>"n_estimators"</span><span class=p>:[</span><span class=mi>120</span><span class=p>,</span><span class=mi>200</span><span class=p>,</span><span class=mi>300</span><span class=p>,</span><span class=mi>500</span><span class=p>,</span><span class=mi>800</span><span class=p>,</span><span class=mi>1200</span><span class=p>],</span>  
<a id=__codelineno-29-2 name=__codelineno-29-2></a>           <span class=s2>"max_depth"</span><span class=p>:[</span><span class=mi>5</span><span class=p>,</span><span class=mi>8</span><span class=p>,</span><span class=mi>15</span><span class=p>,</span><span class=mi>25</span><span class=p>,</span><span class=mi>30</span><span class=p>]}</span>  
<a id=__codelineno-29-3 name=__codelineno-29-3></a><span class=n>estimator</span><span class=o>=</span><span class=n>GridSearchCV</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span><span class=n>param_grid</span><span class=o>=</span><span class=n>param_dict</span><span class=p>,</span><span class=n>cv</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>  
</code></pre></div></td></tr></tbody></table></div></li> <li>之后进行同样的验证即可：<br> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-30-1> 1</a></span>
<span class=normal><a href=#__codelineno-30-2> 2</a></span>
<span class=normal><a href=#__codelineno-30-3> 3</a></span>
<span class=normal><a href=#__codelineno-30-4> 4</a></span>
<span class=normal><a href=#__codelineno-30-5> 5</a></span>
<span class=normal><a href=#__codelineno-30-6> 6</a></span>
<span class=normal><a href=#__codelineno-30-7> 7</a></span>
<span class=normal><a href=#__codelineno-30-8> 8</a></span>
<span class=normal><a href=#__codelineno-30-9> 9</a></span>
<span class=normal><a href=#__codelineno-30-10>10</a></span>
<span class=normal><a href=#__codelineno-30-11>11</a></span>
<span class=normal><a href=#__codelineno-30-12>12</a></span>
<span class=normal><a href=#__codelineno-30-13>13</a></span>
<span class=normal><a href=#__codelineno-30-14>14</a></span>
<span class=normal><a href=#__codelineno-30-15>15</a></span>
<span class=normal><a href=#__codelineno-30-16>16</a></span>
<span class=normal><a href=#__codelineno-30-17>17</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-30-1 name=__codelineno-30-1></a><span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>  
<a id=__codelineno-30-2 name=__codelineno-30-2></a><span class=c1># 模型评估  </span>
<a id=__codelineno-30-3 name=__codelineno-30-3></a>    <span class=c1># 方法一：比较真实值和预测值  </span>
<a id=__codelineno-30-4 name=__codelineno-30-4></a><span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-30-5 name=__codelineno-30-5></a><span class=nb>print</span><span class=p>(</span><span class=s2>"y_predict:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-30-6 name=__codelineno-30-6></a><span class=nb>print</span><span class=p>(</span><span class=s2>"直接比较的准确率：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_test</span><span class=o>==</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-30-7 name=__codelineno-30-7></a>    <span class=c1># 方法二：计算准确率  </span>
<a id=__codelineno-30-8 name=__codelineno-30-8></a><span class=n>score</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_test</span><span class=p>)</span>  
<a id=__codelineno-30-9 name=__codelineno-30-9></a><span class=nb>print</span><span class=p>(</span><span class=s2>"准确率为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>score</span><span class=p>)</span>  
<a id=__codelineno-30-10 name=__codelineno-30-10></a><span class=c1># 最佳参数：`best_params_`  </span>
<a id=__codelineno-30-11 name=__codelineno-30-11></a><span class=nb>print</span><span class=p>(</span><span class=s2>"最佳参数:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>estimator</span><span class=o>.</span><span class=n>best_params_</span><span class=p>)</span>  
<a id=__codelineno-30-12 name=__codelineno-30-12></a><span class=c1># 最佳结果：`best_score_`  </span>
<a id=__codelineno-30-13 name=__codelineno-30-13></a><span class=nb>print</span><span class=p>(</span><span class=s2>"最佳结果:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>estimator</span><span class=o>.</span><span class=n>best_score_</span><span class=p>)</span>  
<a id=__codelineno-30-14 name=__codelineno-30-14></a><span class=c1># 最佳估计器：`best_estimator_`  </span>
<a id=__codelineno-30-15 name=__codelineno-30-15></a><span class=nb>print</span><span class=p>(</span><span class=s2>"最佳估计器:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>estimator</span><span class=o>.</span><span class=n>best_estimator_</span><span class=p>)</span>  
<a id=__codelineno-30-16 name=__codelineno-30-16></a><span class=c1># 交叉验证结果：`cv_results_`  </span>
<a id=__codelineno-30-17 name=__codelineno-30-17></a><span class=nb>print</span><span class=p>(</span><span class=s2>"最佳交叉验证结果:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span> <span class=n>estimator</span><span class=o>.</span><span class=n>cv_results_</span><span class=p>)</span>  
</code></pre></div></td></tr></tbody></table></div></li> </ul> </div> <h4 id=_64>总结<a class=headerlink href=#_64 title="Permanent link">¶</a></h4> <ul> <li>有极好的准确率</li> <li>有效地运行在大数据集上</li> </ul> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%201.png><img alt src=../png/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%201.png></a> </p> <h2 id=_65>回归与聚类算法<a class=headerlink href=#_65 title="Permanent link">¶</a></h2> <ul> <li>回归问题：<br> 目标值为连续性的数据</li> </ul> <h3 id=_66>线性回归<a class=headerlink href=#_66 title="Permanent link">¶</a></h3> <h4 id=_67>线性回归的原理<a class=headerlink href=#_67 title="Permanent link">¶</a></h4> <ul> <li>定义：利用回归方程（函数）对一个或多个自变量（特征值）和因变量（目标值）之间关系进行建模的一种分析方式（就是找到特征值和目标值之间的函数关系）</li> <li>特点：根据自变量的个数分为单变量回归和多元回归</li> </ul> <p>通用公式：（前面的 w 为权重系数，b 为偏置） </p> <div class=arithmatex>\[ h(w)=w_{1}x_{1}+w_{2}x_{2}+w_{3}x_{3}...+\mathrm{b}=w^{T}x+b \]</div> <p>其中的 w 和 x 可以理解为矩阵： </p> <div class=arithmatex>\[ \mathbf{w}=\begin{pmatrix}b\\w_1\\w_2\end{pmatrix},\mathbf{x}=\begin{pmatrix}1\\x_1\\x_2\end{pmatrix} \]</div> <ul> <li>线性模型：（不同于线性关系）<br> <strong>参数</strong>是一次的（也就是多项式也可以是线性模型）<br> 自变量是一次的（线性关系）<br> 这两种情况都可以叫做线性模型</li> </ul> <p>线性关系一定是线性模型，但是反之不一定的 </p> <h4 id=_68>线性回归的损失和优化原理（理解记忆）<a class=headerlink href=#_68 title="Permanent link">¶</a></h4> <p>有真实关系，还有假设的关系<br> 不断地迭代，消除误差<br> 所以怎么进行衡量呢——<strong>损失函数：cost</strong> </p> <div class="admonition tip"> <p class=admonition-title>损失函数</p> <p>定义为： </p> <div class=arithmatex>\[ \begin{aligned}J(\theta)&amp;=(h_{w}(x_{1})-y_{1})^{2}+(h_{w}(x_{2})-y_{2})^{2}+\cdots+(h_{w}(x_{m})-y_{m})^{2}\\&amp;=\sum_{i=1}^{m}(h_{w}(x_{i})-y_{i})^{2}\end{aligned} \]</div> <ul> <li>y_i 为第 i 个训练样本的真实值</li> <li>h (x_i) 为第 i 个训练样本特征值<strong>组合预测函数</strong></li> <li>又称为最小二乘法</li> </ul> </div> <p>优化算法：求出损失最小时对应的 w 的值 </p> <h4 id=_69>优化算法<a class=headerlink href=#_69 title="Permanent link">¶</a></h4> <p>有两种方式：正规方程和梯度下降<br> 正规方程：<br> 天才——直接求解 w 的值，只求一次 </p> <div class=arithmatex>\[ w=(X^{T}X)^{-1}X^{T}y \]</div> <p>梯度下降：<br> 努力的普通人——不断地试错，不断地改进，使得总损失最小 </p> <p>拓展内容：<br> 函数的最小值的求法：对函数进行求导<br> 得到导函数的零点就是 </p> <h4 id=_70>梯度下降<a class=headerlink href=#_70 title="Permanent link">¶</a></h4> <div class=arithmatex>\[ w_{1}:=\quad w_1-\alpha\frac{\partial cost(w_0+w_1x_1)}{\partial w1}\quad w_{0}:=\quad w_0-\alpha\frac{\partial cost(w_0+w_1x_1)}{\partial w1} \]</div> <p>沿着梯度下降（切线的方向），下降到最低点（<strong>微积分</strong>的思想）<br> 但是有可能到了局部的最小点（极点，也是导函数为 0 的点，但是不是最小值） </p> <h4 id=api_7>API<a class=headerlink href=#api_7 title="Permanent link">¶</a></h4> <div class="admonition tip"> <p class=admonition-title>API 的调用</p> <ul> <li>sklearn. linear_model.LinearRegression (fit_intercept=True) <ul> <li>通过<strong>正规方程</strong>优化 </li> <li>fit_intercept: 是否计算偏置（一般为 true，更加准确一点，因为没有偏置的话最后的结果必定过原点，是有局限性的） </li> <li>LinearRegression. coef_: 回归系数 </li> <li>LinearRegression. intercept_: 偏置 </li> </ul> </li> <li>sklearn. linear_model.SGDRegressor (loss="squared_loss", fit_intercept=True, learning_rate='invscaled', eta 0=0.01) <ul> <li>SGDRegressor 类实现了<strong>随机梯度下降</strong>学习，它支持不同的 loss 函数和正则化惩罚项来拟合线性回归模型。 </li> <li>loss: 损失类型 <ul> <li>loss="squared_loss": <strong>普通最小二乘法</strong> </li> </ul> </li> <li>fit_intercept: 是否计算偏置 </li> <li>learning_rate: string, optional <ul> <li><strong>学习率填充</strong> </li> <li>'constant': eta = eta 0 </li> <li>'optimal': eta = 1.0 / (alpha * (t + t 0)) [default] </li> <li>'invscaled': eta = eta 0 / pow (t, power_t) </li> <li>power_t=0.25: 存在父类当中 </li> <li>对于一个常数值的学习率来说，可以使用 learning_rate='constant', 并使用 eta 0 来指定学习率。 </li> </ul> </li> <li>SGDRegressor. coef_: 回归系数 </li> <li>SGDRegressor. intercept_: 偏置 </li> </ul> </li> </ul> </div> <p>两种 API 的调用 </p> <h4 id=_71>波士顿房价预测<a class=headerlink href=#_71 title="Permanent link">¶</a></h4> <div class="admonition tip"> <p class=admonition-title>流程</p> </div> <ol> <li>获取数据集</li> <li>划分数据集</li> <li>特征工程：<ol> <li>因为要进行损失函数的计算，所以需要进行无量纲化的处理（标准化）</li> </ol> </li> <li>预估器<ol> <li>fit ()——&gt;模型</li> <li>coef_intercept</li> </ol> </li> <li>模型评估</li> </ol> <p>代码：<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-31-1> 1</a></span>
<span class=normal><a href=#__codelineno-31-2> 2</a></span>
<span class=normal><a href=#__codelineno-31-3> 3</a></span>
<span class=normal><a href=#__codelineno-31-4> 4</a></span>
<span class=normal><a href=#__codelineno-31-5> 5</a></span>
<span class=normal><a href=#__codelineno-31-6> 6</a></span>
<span class=normal><a href=#__codelineno-31-7> 7</a></span>
<span class=normal><a href=#__codelineno-31-8> 8</a></span>
<span class=normal><a href=#__codelineno-31-9> 9</a></span>
<span class=normal><a href=#__codelineno-31-10>10</a></span>
<span class=normal><a href=#__codelineno-31-11>11</a></span>
<span class=normal><a href=#__codelineno-31-12>12</a></span>
<span class=normal><a href=#__codelineno-31-13>13</a></span>
<span class=normal><a href=#__codelineno-31-14>14</a></span>
<span class=normal><a href=#__codelineno-31-15>15</a></span>
<span class=normal><a href=#__codelineno-31-16>16</a></span>
<span class=normal><a href=#__codelineno-31-17>17</a></span>
<span class=normal><a href=#__codelineno-31-18>18</a></span>
<span class=normal><a href=#__codelineno-31-19>19</a></span>
<span class=normal><a href=#__codelineno-31-20>20</a></span>
<span class=normal><a href=#__codelineno-31-21>21</a></span>
<span class=normal><a href=#__codelineno-31-22>22</a></span>
<span class=normal><a href=#__codelineno-31-23>23</a></span>
<span class=normal><a href=#__codelineno-31-24>24</a></span>
<span class=normal><a href=#__codelineno-31-25>25</a></span>
<span class=normal><a href=#__codelineno-31-26>26</a></span>
<span class=normal><a href=#__codelineno-31-27>27</a></span>
<span class=normal><a href=#__codelineno-31-28>28</a></span>
<span class=normal><a href=#__codelineno-31-29>29</a></span>
<span class=normal><a href=#__codelineno-31-30>30</a></span>
<span class=normal><a href=#__codelineno-31-31>31</a></span>
<span class=normal><a href=#__codelineno-31-32>32</a></span>
<span class=normal><a href=#__codelineno-31-33>33</a></span>
<span class=normal><a href=#__codelineno-31-34>34</a></span>
<span class=normal><a href=#__codelineno-31-35>35</a></span>
<span class=normal><a href=#__codelineno-31-36>36</a></span>
<span class=normal><a href=#__codelineno-31-37>37</a></span>
<span class=normal><a href=#__codelineno-31-38>38</a></span>
<span class=normal><a href=#__codelineno-31-39>39</a></span>
<span class=normal><a href=#__codelineno-31-40>40</a></span>
<span class=normal><a href=#__codelineno-31-41>41</a></span>
<span class=normal><a href=#__codelineno-31-42>42</a></span>
<span class=normal><a href=#__codelineno-31-43>43</a></span>
<span class=normal><a href=#__codelineno-31-44>44</a></span>
<span class=normal><a href=#__codelineno-31-45>45</a></span>
<span class=normal><a href=#__codelineno-31-46>46</a></span>
<span class=normal><a href=#__codelineno-31-47>47</a></span>
<span class=normal><a href=#__codelineno-31-48>48</a></span>
<span class=normal><a href=#__codelineno-31-49>49</a></span>
<span class=normal><a href=#__codelineno-31-50>50</a></span>
<span class=normal><a href=#__codelineno-31-51>51</a></span>
<span class=normal><a href=#__codelineno-31-52>52</a></span>
<span class=normal><a href=#__codelineno-31-53>53</a></span>
<span class=normal><a href=#__codelineno-31-54>54</a></span>
<span class=normal><a href=#__codelineno-31-55>55</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-31-1 name=__codelineno-31-1></a><span class=kn>from</span><span class=w> </span><span class=nn>statistics</span><span class=w> </span><span class=kn>import</span> <span class=n>LinearRegression</span>  
<a id=__codelineno-31-2 name=__codelineno-31-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>fetch_california_housing</span>  
<a id=__codelineno-31-3 name=__codelineno-31-3></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>SGDClassifier</span><span class=p>,</span> <span class=n>SGDRegressor</span>  
<a id=__codelineno-31-4 name=__codelineno-31-4></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.model_selection</span><span class=w> </span><span class=kn>import</span> <span class=n>train_test_split</span>  
<a id=__codelineno-31-5 name=__codelineno-31-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.preprocessing</span><span class=w> </span><span class=kn>import</span> <span class=n>StandardScaler</span>  
<a id=__codelineno-31-6 name=__codelineno-31-6></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.linear_model</span><span class=w> </span><span class=kn>import</span> <span class=n>LinearRegression</span><span class=p>,</span> <span class=n>SGDRegressor</span>  
<a id=__codelineno-31-7 name=__codelineno-31-7></a>
<a id=__codelineno-31-8 name=__codelineno-31-8></a><span class=k>def</span><span class=w> </span><span class=nf>linear1</span><span class=p>():</span>  
<a id=__codelineno-31-9 name=__codelineno-31-9></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-31-10 name=__codelineno-31-10></a><span class=sd>    正规方程的优化方法对波士顿房价进行预测  </span>
<a id=__codelineno-31-11 name=__codelineno-31-11></a><span class=sd>    :return:    """</span>    <span class=c1># 1.获取数据  </span>
<a id=__codelineno-31-12 name=__codelineno-31-12></a>    <span class=n>boston</span> <span class=o>=</span> <span class=n>fetch_california_housing</span><span class=p>()</span>  
<a id=__codelineno-31-13 name=__codelineno-31-13></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"特征数量：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>boston</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>  
<a id=__codelineno-31-14 name=__codelineno-31-14></a>    <span class=c1># 2.划分数据集  </span>
<a id=__codelineno-31-15 name=__codelineno-31-15></a>    <span class=n>x_train</span><span class=p>,</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_train</span><span class=p>,</span><span class=n>y_test</span><span class=o>=</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>boston</span><span class=o>.</span><span class=n>data</span><span class=p>,</span><span class=n>boston</span><span class=o>.</span><span class=n>target</span><span class=p>,</span><span class=n>random_state</span><span class=o>=</span><span class=mi>22</span><span class=p>)</span>  
<a id=__codelineno-31-16 name=__codelineno-31-16></a>
<a id=__codelineno-31-17 name=__codelineno-31-17></a>    <span class=c1># 3.特征工程  </span>
<a id=__codelineno-31-18 name=__codelineno-31-18></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>StandardScaler</span><span class=p>()</span>  
<a id=__codelineno-31-19 name=__codelineno-31-19></a>    <span class=n>x_train</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>x_train</span><span class=p>)</span>  
<a id=__codelineno-31-20 name=__codelineno-31-20></a>    <span class=n>x_test</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-31-21 name=__codelineno-31-21></a>    <span class=c1># 4.预估器  </span>
<a id=__codelineno-31-22 name=__codelineno-31-22></a>    <span class=n>estimator</span><span class=o>=</span><span class=n>LinearRegression</span><span class=p>()</span>  
<a id=__codelineno-31-23 name=__codelineno-31-23></a>    <span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>  
<a id=__codelineno-31-24 name=__codelineno-31-24></a>
<a id=__codelineno-31-25 name=__codelineno-31-25></a>    <span class=c1># 5.得出模型  </span>
<a id=__codelineno-31-26 name=__codelineno-31-26></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"正规方程权重系数为:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>estimator</span><span class=o>.</span><span class=n>coef_</span><span class=p>)</span>  
<a id=__codelineno-31-27 name=__codelineno-31-27></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"正规方程偏置为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>estimator</span><span class=o>.</span><span class=n>intercept_</span><span class=p>)</span>  
<a id=__codelineno-31-28 name=__codelineno-31-28></a>    <span class=c1># 6.模型评估  </span>
<a id=__codelineno-31-29 name=__codelineno-31-29></a>    <span class=k>return</span> <span class=kc>None</span>  
<a id=__codelineno-31-30 name=__codelineno-31-30></a>
<a id=__codelineno-31-31 name=__codelineno-31-31></a><span class=k>def</span><span class=w> </span><span class=nf>linear2</span><span class=p>():</span>  
<a id=__codelineno-31-32 name=__codelineno-31-32></a><span class=w>    </span><span class=sd>"""  </span>
<a id=__codelineno-31-33 name=__codelineno-31-33></a><span class=sd>    梯度下降的优化方法对波士顿房价进行预测  </span>
<a id=__codelineno-31-34 name=__codelineno-31-34></a><span class=sd>    :return:    """</span>    <span class=c1># 1.获取数据  </span>
<a id=__codelineno-31-35 name=__codelineno-31-35></a>    <span class=n>boston</span> <span class=o>=</span> <span class=n>fetch_california_housing</span><span class=p>()</span>  
<a id=__codelineno-31-36 name=__codelineno-31-36></a>    <span class=c1># 2.划分数据集  </span>
<a id=__codelineno-31-37 name=__codelineno-31-37></a>    <span class=n>x_train</span><span class=p>,</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_train</span><span class=p>,</span><span class=n>y_test</span><span class=o>=</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>boston</span><span class=o>.</span><span class=n>data</span><span class=p>,</span><span class=n>boston</span><span class=o>.</span><span class=n>target</span><span class=p>,</span><span class=n>random_state</span><span class=o>=</span><span class=mi>22</span><span class=p>)</span>  
<a id=__codelineno-31-38 name=__codelineno-31-38></a>
<a id=__codelineno-31-39 name=__codelineno-31-39></a>    <span class=c1># 3.特征工程  </span>
<a id=__codelineno-31-40 name=__codelineno-31-40></a>    <span class=n>transfer</span><span class=o>=</span><span class=n>StandardScaler</span><span class=p>()</span>  
<a id=__codelineno-31-41 name=__codelineno-31-41></a>    <span class=n>x_train</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>x_train</span><span class=p>)</span>  
<a id=__codelineno-31-42 name=__codelineno-31-42></a>    <span class=n>x_test</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-31-43 name=__codelineno-31-43></a>    <span class=c1># 4.预估器  </span>
<a id=__codelineno-31-44 name=__codelineno-31-44></a>    <span class=n>estimator</span><span class=o>=</span><span class=n>SGDRegressor</span><span class=p>()</span>  
<a id=__codelineno-31-45 name=__codelineno-31-45></a>    <span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>  
<a id=__codelineno-31-46 name=__codelineno-31-46></a>
<a id=__codelineno-31-47 name=__codelineno-31-47></a>    <span class=c1># 5.得出模型  </span>
<a id=__codelineno-31-48 name=__codelineno-31-48></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"梯度下降权重系数为:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>estimator</span><span class=o>.</span><span class=n>coef_</span><span class=p>)</span>  
<a id=__codelineno-31-49 name=__codelineno-31-49></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>"梯度下降偏置为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>estimator</span><span class=o>.</span><span class=n>intercept_</span><span class=p>)</span>  
<a id=__codelineno-31-50 name=__codelineno-31-50></a>    <span class=c1># 6.模型评估  </span>
<a id=__codelineno-31-51 name=__codelineno-31-51></a>    <span class=k>return</span> <span class=kc>None</span>  
<a id=__codelineno-31-52 name=__codelineno-31-52></a><span class=c1># 1.正规方程  </span>
<a id=__codelineno-31-53 name=__codelineno-31-53></a><span class=n>linear1</span><span class=p>()</span>  
<a id=__codelineno-31-54 name=__codelineno-31-54></a><span class=c1># 2. 梯度下降  </span>
<a id=__codelineno-31-55 name=__codelineno-31-55></a><span class=n>linear2</span><span class=p>()</span>
</code></pre></div></td></tr></tbody></table></div><p></p> <p><code>boston.data</code> 这种用法好像只有 sklearn 内置的数据集才能使用（因为内置的自己就划分了哪些是特征值，哪些是目标值）</p> <h4 id=_72>模型的评估<a class=headerlink href=#_72 title="Permanent link">¶</a></h4> <p>均方误差评价机制： </p> <div class=arithmatex>\[ MSE=\frac{1}{m}\sum_{i=1}^m\left(y^i-\bar{y}\right)^2 \]</div> <p>实际上就是每一个样本的预测值减去平均值的平方的平均（方差）<br> 哪一个模型的均方误差小，哪个就好 </p> <ul> <li>sklearn. metrics. mean_squared_error (y_true, y_pred)<ul> <li>均方误差回归损失</li> <li>y_true: 真实值</li> <li>y_pred: 预测值</li> <li>return: 浮点数结果</li> </ul> </li> </ul> <p>头文件：<code>from sklearn.metrics import mean_squared_error</code> </p> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-32-1>1</a></span>
<span class=normal><a href=#__codelineno-32-2>2</a></span>
<span class=normal><a href=#__codelineno-32-3>3</a></span>
<span class=normal><a href=#__codelineno-32-4>4</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-32-1 name=__codelineno-32-1></a><span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-32-2 name=__codelineno-32-2></a><span class=nb>print</span><span class=p>(</span><span class=s2>"预测房价:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-32-3 name=__codelineno-32-3></a><span class=n>error</span><span class=o>=</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-32-4 name=__codelineno-32-4></a><span class=nb>print</span><span class=p>(</span><span class=s2>"正规方程的均方误差为:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>error</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div> <p>梯度下降可以条件的参数比较多！<br> <code>estimator=SGDRegressor(learning_rate="constant",eta0=0.000001,max_iter=100000)</code><br> 前面是 eta 0 为初始学习率（也就是步长，每一次迭代变化的幅度）<br> max_iter 为迭代的次数<br> learning_rate="constant"代表学习率不变 </p> <ul> <li>&lt;100 K 不用梯度下降，数据量足够多才使用 SGD</li> <li>小数据使用岭回归（一般不使用 <code>LinearRegression()</code>）</li> </ul> <h4 id=_73>梯度下降优化器<a class=headerlink href=#_73 title="Permanent link">¶</a></h4> <ol> <li>GD<br> 最原始的梯度下降，需要计算所有样本的值才能得出梯度，计算量大</li> <li>SGD<br> 随机梯度下降，在一次迭代时只考虑一个训练样本</li> <li>SAG<br> 计算平均梯度</li> </ol> <h3 id=_74>欠拟合与过拟合<a class=headerlink href=#_74 title="Permanent link">¶</a></h3> <h4 id=_75>什么是欠拟合与过拟合<a class=headerlink href=#_75 title="Permanent link">¶</a></h4> <p>在训练数据的时候，模型在训练集上表现很好，但是在测试集上有问题，这种就是出现了<strong>过拟合现象</strong> </p> <div class="admonition tip"> <p class=admonition-title>拟合</p> <p>欠拟合：<br> 天鹅的图片，但是识别到的特征是有翅膀和嘴巴长，识别到的特征太小了，很多的其他都归到了天鹅身上<br> <strong>在训练集和测试集上都不好（模型过于简单）</strong><br> 过拟合：<br> 过多了<br> 在训练集上好，但是在<strong>测试集上效果不好</strong>（模型过于复杂） </p> </div> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250908155901.png><img alt src=../png/Pasted%20image%2020250908155901.png></a></p> <h4 id=_76>解决方法<a class=headerlink href=#_76 title="Permanent link">¶</a></h4> <ul> <li>欠拟合：<ul> <li>增加<strong>数据的特征数量</strong></li> </ul> </li> <li>过拟合<ul> <li>原因：原始特征过多，存在一些嘈杂的特征，模型过于复杂，尝试去兼顾每一个测试数据点</li> <li>解决方法：正则化</li> </ul> </li> </ul> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250908162510.png><img alt src=../png/Pasted%20image%2020250908162510.png></a><br> 中间的最好，左边为欠拟合，右边为过拟合 </p> <div class="admonition tip"> <p class=admonition-title>过拟合的解决</p> <div class=arithmatex>\[ \theta_0+\theta_1x+\theta_2x^2+\theta_3x^3+\theta_4x^4 \]</div> <p>尽量减小高次项的系数<br> 解决方法：<strong>正则化</strong> </p> </div> <p><strong>正则化类型</strong> </p> <div class="admonition tip"> <p class=admonition-title>L 2 正则化</p> <ul> <li>作用：使得其中一些 w (系数) 很小，接近于 0，减小某个特征的影响 </li> <li> <p>加入损失函数： </p> <div class=arithmatex>\[ J(w)=\frac{1}{2m}\sum_{i=1}^{m}(h_{w}(x_{i})-y_{i})^{2}+\lambda\sum_{j=1}^{n}w_{j}^{2} \]</div> <p>L 2 正则化更加常用<br> 损失函数＋ <span class=arithmatex>\(\lambda\)</span> 惩罚项<br> Ridge——岭回归</p> </li> </ul> </div> <div class="admonition tip"> <p class=admonition-title>L 1 正则化</p> <p>损失函数＋ <span class=arithmatex>\(\lambda\)</span> 惩罚项，但是后面相乘的变成了 <strong>w（权重系数）</strong> 的绝对值<br> 使得一些 w 直接为 0，相当于<strong>删除了</strong>一些项，而 L 2 是减小影响</p> </div> <h3 id=_77>线性回归的改进——岭回归<a class=headerlink href=#_77 title="Permanent link">¶</a></h3> <p>是一种加上正则化的线性回归 </p> <h4 id=l-2>带有 L 2 正则化的线性回归——岭回归<a class=headerlink href=#l-2 title="Permanent link">¶</a></h4> <p><strong>API 调用</strong> </p> <ul> <li> <p>sklearn.linear_model.Ridge(alpha=1.0, fit_intercept=True, solver="auto", normalize=False)</p> <ul> <li>具有L2正则化的线性回归</li> <li>alpha: 正则化<strong>力度</strong>，也叫 λ（就是上面的 <span class=arithmatex>\(\lambda\)</span>）<ul> <li>λ取值：0-1 1-10</li> </ul> </li> <li>solver: 会根据数据自动选择优化方法<ul> <li>sag: 如果<strong>数据集</strong>、特征都比较大，选择该随机梯度下降<strong>优化</strong></li> </ul> </li> <li>normalize: 数据是否进行标准化（就是相当于之前的<strong>标准化</strong>）<ul> <li>normalize=False: 可以在fit之前调用preprocessing.StandardScaler标准化数据</li> </ul> </li> <li>Ridge.coef_: 回归权重（看模型的结果）</li> <li>Ridge.intercept_: 回归偏置（结果）</li> </ul> </li> <li> <p>正则化力度越大，权重系数越小</p> </li> <li>正则化力度越小，权重系数会越大</li> </ul> <div class="admonition tip"> <p class=admonition-title>用法</p> <ul> <li>头文件：<br> <code>from sklearn.linear_model import LinearRegression, SGDRegressor,Ridge</code> </li> <li> <p>总的代码： </p> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-33-1> 1</a></span>
<span class=normal><a href=#__codelineno-33-2> 2</a></span>
<span class=normal><a href=#__codelineno-33-3> 3</a></span>
<span class=normal><a href=#__codelineno-33-4> 4</a></span>
<span class=normal><a href=#__codelineno-33-5> 5</a></span>
<span class=normal><a href=#__codelineno-33-6> 6</a></span>
<span class=normal><a href=#__codelineno-33-7> 7</a></span>
<span class=normal><a href=#__codelineno-33-8> 8</a></span>
<span class=normal><a href=#__codelineno-33-9> 9</a></span>
<span class=normal><a href=#__codelineno-33-10>10</a></span>
<span class=normal><a href=#__codelineno-33-11>11</a></span>
<span class=normal><a href=#__codelineno-33-12>12</a></span>
<span class=normal><a href=#__codelineno-33-13>13</a></span>
<span class=normal><a href=#__codelineno-33-14>14</a></span>
<span class=normal><a href=#__codelineno-33-15>15</a></span>
<span class=normal><a href=#__codelineno-33-16>16</a></span>
<span class=normal><a href=#__codelineno-33-17>17</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-33-1 name=__codelineno-33-1></a><span class=c1># 3.特征工程  </span>
<a id=__codelineno-33-2 name=__codelineno-33-2></a><span class=n>transfer</span><span class=o>=</span><span class=n>StandardScaler</span><span class=p>()</span>  
<a id=__codelineno-33-3 name=__codelineno-33-3></a><span class=n>x_train</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>fit_transform</span><span class=p>(</span><span class=n>x_train</span><span class=p>)</span>  
<a id=__codelineno-33-4 name=__codelineno-33-4></a><span class=n>x_test</span><span class=o>=</span><span class=n>transfer</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-33-5 name=__codelineno-33-5></a><span class=c1># 4.预估器  </span>
<a id=__codelineno-33-6 name=__codelineno-33-6></a><span class=n>estimator</span><span class=o>=</span><span class=n>Ridge</span><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span><span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>  
<a id=__codelineno-33-7 name=__codelineno-33-7></a><span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>  
<a id=__codelineno-33-8 name=__codelineno-33-8></a>
<a id=__codelineno-33-9 name=__codelineno-33-9></a><span class=c1># 5.得出模型  </span>
<a id=__codelineno-33-10 name=__codelineno-33-10></a><span class=nb>print</span><span class=p>(</span><span class=s2>"岭回归权重系数为:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>estimator</span><span class=o>.</span><span class=n>coef_</span><span class=p>)</span>  
<a id=__codelineno-33-11 name=__codelineno-33-11></a><span class=nb>print</span><span class=p>(</span><span class=s2>"岭回归偏置为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>estimator</span><span class=o>.</span><span class=n>intercept_</span><span class=p>)</span>  
<a id=__codelineno-33-12 name=__codelineno-33-12></a><span class=c1># 6.模型评估  </span>
<a id=__codelineno-33-13 name=__codelineno-33-13></a><span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>  
<a id=__codelineno-33-14 name=__codelineno-33-14></a><span class=nb>print</span><span class=p>(</span><span class=s2>"预测房价:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-33-15 name=__codelineno-33-15></a><span class=n>error</span><span class=o>=</span><span class=n>mean_squared_error</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>  
<a id=__codelineno-33-16 name=__codelineno-33-16></a><span class=nb>print</span><span class=p>(</span><span class=s2>"岭回归的均方误差为:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>error</span><span class=p>)</span>  
<a id=__codelineno-33-17 name=__codelineno-33-17></a><span class=k>return</span> <span class=kc>None</span>
</code></pre></div></td></tr></tbody></table></div> </li> </ul> </div> <h3 id=->分类算法-逻辑回归与二分类<a class=headerlink href=#- title="Permanent link">¶</a></h3> <p>逻辑回归是一种分类算法 </p> <h4 id=_78>应用场景<a class=headerlink href=#_78 title="Permanent link">¶</a></h4> <ul> <li>广告点击率</li> <li>是否为垃圾邮件</li> <li>是否患病</li> <li>金融诈骗</li> <li>虚假账号</li> </ul> <p>上面的例子都是二分类的问题 （<strong>两个类别之间的</strong>）<br> 所以说<strong>逻辑回归</strong>是解决二分类问题的利器 </p> <h4 id=_79>逻辑回归的原理<a class=headerlink href=#_79 title="Permanent link">¶</a></h4> <p><strong>输入</strong> </p> <div class=arithmatex>\[ h(w)=w_{1}x_{1}+w_{2}x_{2}+w_{3}x_{3}…+b \]</div> <p>可见逻辑回归的输入就是线性回归的结果（输出） </p> <p><strong>激活函数</strong> </p> <ul> <li>sigmoid 函数</li> </ul> <div class=arithmatex>\[ g(\theta^Tx)=\frac{1}{1+e^{-\theta^Tx}} \]</div> <ul> <li>分析<ul> <li>回归的结果输入 sigmoid 函数中</li> <li>输出结果为[0,1]的概率值，一般默认0.5 为阈值，小于是某个类比，大于是另一个</li> </ul> </li> </ul> <p>总结：将线性回归的输出映射到 sigmoid 函数上，进行分类 </p> <p><strong>假设函数/线性模型</strong> </p> <ul> <li><strong>损失函数</strong><br> (y_predict-y_ture) 平方和/总数<br> 逻辑回归真实值是否属于某个示例</li> <li> <p><strong>对数似然损失函数</strong>：</p> <div class=arithmatex>\[ \left.cost(h_\theta(x),y)=\left\{\begin{array}{ll}-log(h_\theta(x))&amp;\mathrm{if~y=1}\\-log(1- h_\theta(x))&amp;\mathrm{if~y=0}\end{array}\right.\right. \]</div> <p>因为我们现在的 y 的值为 1,0（分类），所以需要有新的<strong>损失函数</strong>（就是预测的误差）<span class=arithmatex>\(h_\theta(x)\)</span> 为预测的概率值，最后算出来的值就是误差<br> 等价的表述：（就是把上面的分段函数写成一个的形式）</p> <div class=arithmatex>\[ cost(h_\theta(x),y)=\sum_{i=1}^m-y_ilog(h_\theta(x))-(1-y_i)log(1-h_\theta(x)) \]</div> </li> <li> <p>过程如图：<br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250908225104.png><img alt src=../png/Pasted%20image%2020250908225104.png></a><br> 由线性的结果（系数的值），将输入带入，计算出回归的值，之后带入 sigmoid 中，计算逻辑回归结果，与阈值 0.5 比较，得出真实的结果<br> 上面的图中，预测的结果为 0,1,0,1,1，真实的结果是 1,0,1,0,1<br> 所以带入上面的损失计算公式进行计算</p> <div class=arithmatex>\[ -[1\log(0.4)+(1-0)\log(1-0.68)+1\log(0.41)+(1-0)\log(1-0.55)+1\log(0.71)] \]</div> <p>我们总的损失就计算出来了</p> </li> </ul> <hr> <p>有了损失函数之后就要进行优化：<br> 调整 w（参数），使得结果越来越接近（损失减小）<br> 使用<strong>梯度下降</strong>的方法进行优化 </p> <h4 id=api_8>逻辑回归API 调用<a class=headerlink href=#api_8 title="Permanent link">¶</a></h4> <ul> <li>sklearn.linear_model.LogisticRegression(solver='liblinear', penalty='l2', C=1.0)<ul> <li>solver: 优化<strong>求解方式</strong>（默认开源的liblinear库实现，内部使用了坐标轴下降法来迭代优化损失函数）<ul> <li>sag: 根据数据集自动选择，随机平均梯度下降</li> </ul> </li> <li>penalty: 正则化的种类</li> <li>C: 正则化力度</li> </ul> </li> </ul> <p>可以实现 <strong>SAG</strong> </p> <h4 id=_80>案例：癌症分类预测的案例<a class=headerlink href=#_80 title="Permanent link">¶</a></h4> <p>数据集：<code>https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data</code><br> names：<code>https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.names</code> </p> <div class="admonition tip"> <p class=admonition-title>流程</p> </div> <ol> <li>获取数据<ol> <li>读取的时候加上 names</li> </ol> </li> <li>数据处理（因为不是使用 sklearn 的数据了）<ol> <li>处理缺失值</li> </ol> </li> <li>数据集划分</li> <li>特征工程<ol> <li>无量纲化（标准化）</li> </ol> </li> <li>逻辑回归预估器</li> <li>模型评估</li> </ol> <p>代码：<br> </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-34-1>1</a></span>
<span class=normal><a href=#__codelineno-34-2>2</a></span>
<span class=normal><a href=#__codelineno-34-3>3</a></span>
<span class=normal><a href=#__codelineno-34-4>4</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-34-1 name=__codelineno-34-1></a><span class=c1># 读取数据</span>
<a id=__codelineno-34-2 name=__codelineno-34-2></a><span class=n>path</span><span class=o>=</span><span class=s2>"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/breast-cancer-wisconsin.data"</span>
<a id=__codelineno-34-3 name=__codelineno-34-3></a><span class=n>names</span> <span class=o>=</span> <span class=p>[</span><span class=s1>'Sample code number'</span><span class=p>,</span> <span class=s1>'Clump Thickness'</span><span class=p>,</span> <span class=s1>'Uniformity of Cell Size'</span><span class=p>,</span> <span class=s1>'Uniformity of Cell Shape'</span><span class=p>,</span><span class=s1>'Marginal Adhesion'</span><span class=p>,</span> <span class=s1>'Single Epithelial Cell Size'</span><span class=p>,</span> <span class=s1>'Bare Nuclei'</span><span class=p>,</span> <span class=s1>'Bland Chromatin'</span><span class=p>,</span><span class=s1>'Normal Nucleoli'</span><span class=p>,</span> <span class=s1>'Mitoses'</span><span class=p>,</span> <span class=s1>'Class'</span><span class=p>]</span>
<a id=__codelineno-34-4 name=__codelineno-34-4></a><span class=n>data</span><span class=o>=</span><span class=n>pd</span><span class=o>.</span><span class=n>read_csv</span><span class=p>(</span><span class=n>path</span><span class=p>,</span><span class=n>names</span><span class=o>=</span><span class=n>names</span><span class=p>)</span><span class=c1># 因为之前的数据是没有名字的</span>
</code></pre></div></td></tr></tbody></table></div><p></p> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-35-1>1</a></span>
<span class=normal><a href=#__codelineno-35-2>2</a></span>
<span class=normal><a href=#__codelineno-35-3>3</a></span>
<span class=normal><a href=#__codelineno-35-4>4</a></span>
<span class=normal><a href=#__codelineno-35-5>5</a></span>
<span class=normal><a href=#__codelineno-35-6>6</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-35-1 name=__codelineno-35-1></a><span class=c1># 缺失值处理</span>
<a id=__codelineno-35-2 name=__codelineno-35-2></a>    <span class=c1># 将？替换为np.nan</span>
<a id=__codelineno-35-3 name=__codelineno-35-3></a><span class=n>data</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=n>to_replace</span><span class=o>=</span><span class=s2>"?"</span><span class=p>,</span><span class=n>value</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>nan</span><span class=p>)</span>
<a id=__codelineno-35-4 name=__codelineno-35-4></a>    <span class=c1># 删除缺失的样本</span>
<a id=__codelineno-35-5 name=__codelineno-35-5></a><span class=n>data</span><span class=o>.</span><span class=n>dropna</span><span class=p>(</span><span class=n>inplace</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
<a id=__codelineno-35-6 name=__codelineno-35-6></a><span class=n>data</span><span class=o>.</span><span class=n>isnull</span><span class=p>()</span><span class=o>.</span><span class=n>any</span><span class=p>()</span><span class=c1># 不存在缺失值</span>
</code></pre></div></td></tr></tbody></table></div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-36-1>1</a></span>
<span class=normal><a href=#__codelineno-36-2>2</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-36-1 name=__codelineno-36-1></a><span class=n>x</span><span class=o>=</span><span class=n>data</span><span class=o>.</span><span class=n>iloc</span><span class=p>[:,</span><span class=mi>1</span><span class=p>:</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
<a id=__codelineno-36-2 name=__codelineno-36-2></a><span class=n>y</span><span class=o>=</span><span class=n>data</span><span class=p>[</span><span class=s2>"Class"</span><span class=p>]</span>
</code></pre></div></td></tr></tbody></table></div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-37-1>1</a></span>
<span class=normal><a href=#__codelineno-37-2>2</a></span>
<span class=normal><a href=#__codelineno-37-3>3</a></span>
<span class=normal><a href=#__codelineno-37-4>4</a></span>
<span class=normal><a href=#__codelineno-37-5>5</a></span>
<span class=normal><a href=#__codelineno-37-6>6</a></span>
<span class=normal><a href=#__codelineno-37-7>7</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-37-1 name=__codelineno-37-1></a><span class=c1># 模型评估</span>
<a id=__codelineno-37-2 name=__codelineno-37-2></a><span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>x_test</span><span class=p>)</span>
<a id=__codelineno-37-3 name=__codelineno-37-3></a><span class=nb>print</span><span class=p>(</span><span class=s2>"y_predict:</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>
<a id=__codelineno-37-4 name=__codelineno-37-4></a><span class=nb>print</span><span class=p>(</span><span class=s2>"直接比较的准确率：</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>y_test</span><span class=o>==</span><span class=n>y_predict</span><span class=p>)</span>
<a id=__codelineno-37-5 name=__codelineno-37-5></a>    <span class=c1># 方法二：计算准确率</span>
<a id=__codelineno-37-6 name=__codelineno-37-6></a><span class=n>score</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>score</span><span class=p>(</span><span class=n>x_test</span><span class=p>,</span><span class=n>y_test</span><span class=p>)</span>
<a id=__codelineno-37-7 name=__codelineno-37-7></a><span class=nb>print</span><span class=p>(</span><span class=s2>"准确率为</span><span class=se>\n</span><span class=s2>"</span><span class=p>,</span><span class=n>score</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div> <hr> <p>我们现在要引入一些新的评估方法 </p> <h4 id=_81>分类的评估方法<a class=headerlink href=#_81 title="Permanent link">¶</a></h4> <p><strong>1 精确率和召回率</strong> </p> <p>预测与正确之间的关系可能有</p> <table> <thead> <tr> <th style="text-align: center;"></th> <th style="text-align: center;"></th> <th style="text-align: center;">预测结果</th> <th style="text-align: center;"></th> </tr> </thead> <tbody> <tr> <td style="text-align: center;"></td> <td style="text-align: center;"></td> <td style="text-align: center;">正例</td> <td style="text-align: center;">假例</td> </tr> <tr> <td style="text-align: center;">真实结果</td> <td style="text-align: center;">正例</td> <td style="text-align: center;">真正例 TP</td> <td style="text-align: center;">伪反FN</td> </tr> <tr> <td style="text-align: center;"></td> <td style="text-align: center;">假例</td> <td style="text-align: center;">伪正FP</td> <td style="text-align: center;">正反TN</td> </tr> </tbody> </table> <ul> <li>精确率(Precision)：预测结果为<strong>正例中真实为正例</strong>的比例</li> <li>召回率(Recall)：真实为正例中，预测结果也是正例的比例，<strong>看查的全不全</strong></li> <li> <p>F 1_score: 保证了模型的稳健性</p> <div class=arithmatex>\[ F1=\frac{2TP}{2TP+FN+FP}=\frac{2\cdot Precision\cdot Recall}{Precision+Recall} \]</div> </li> </ul> <p>在癌症中，恶性是正例，所以召回率就非常重要 </p> <p><strong>API</strong><br> - sklearn.metrics.classification_report(y_true, y_pred, labels=[], target_names=None) - y_true: 真实目标值 - y_pred: 估计器预测目标值 - labels: 指定类别对应的数字 - target_names: 目标类别名称 - return: 每个类别精确率与召回率（该函数的返回值）</p> <p>这个在均方误差中也是出现过的 </p> <div class="admonition tip"> <p class=admonition-title>步骤</p> </div> <ol> <li>头文件：<code>from sklearn.metrics import classification_report</code> </li> <li>设定：<code>report=classification_report(y_test,y_predict,labels=[2,4],target_names=["良性","恶性"])</code></li> <li>最后的结果：<code>print(report)</code><br> precision recall f1-score support<div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Text Only</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal>1</span>
<span class=normal>2</span></pre></div></td><td class=code><div><pre><span></span><code>  良性       0.98      0.98      0.98       111
  恶性       0.97      0.97      0.97        60
</code></pre></div></td></tr></tbody></table></div> </li> </ol> <p>总共的样本：99 个是癌症，1 个不是癌症，模型全部预测为正例<br> 此时的准确率为 99%，召回率为 100%，精确率为 99%，F 1_score：99.497%<br> 但是这种模型是不负责任的，怎么办？（样本不均衡） </p> <hr> <p><strong>ROC 曲线和 AUC 指标</strong><br> AUC 越接近 1 越好 </p> <div class="admonition tip"> <p class=admonition-title>TPR 和 FPR</p> <ul> <li>TPR = TP / (TP + FN)(召回率) <ul> <li>所有真实类别为1的样本中，预测类别为1的比例 </li> </ul> </li> <li>FPR = FP / (FP + TN) <ul> <li>所有真实类别为0的样本中，预测类别为1的比例</li> </ul> </li> </ul> <div class="admonition tip"> <p class=admonition-title>ROC 曲线</p> </div> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250909000629.png><img alt src=../png/Pasted%20image%2020250909000629.png></a><br> 横坐标是 FPR，纵坐标是 TPR, 两者相等时，表示的含义是无论真实的类别是 1 还是 0，分类器预测为 1 的概率是相等的（也就是瞎猜，不按真实的情况）啊，此时的 AUC 为 0.5（就是曲线与右部分围成的面积）</p> </div> <p>!!! tip "指标"<br> - 最小值为 0.5，最大值为 1，取值越高越好<br> - 小于 0.5 的时候就反着预测即可</p> <p><strong>API</strong><br> - from sklearn.metrics import roc_auc_score - sklearn.metrics.roc_auc_score(y_true, y_score) - 计算ROC曲线面积，即AUC值 - y_true: 每个样本的真实类别，<strong>必须为0(反例).1(正例)标记</strong> - y_score: 预测得分，可以是正类的估计概率、置信值或者分类器方法的返回值 </p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-38-1>1</a></span>
<span class=normal><a href=#__codelineno-38-2>2</a></span>
<span class=normal><a href=#__codelineno-38-3>3</a></span>
<span class=normal><a href=#__codelineno-38-4>4</a></span>
<span class=normal><a href=#__codelineno-38-5>5</a></span>
<span class=normal><a href=#__codelineno-38-6>6</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-38-1 name=__codelineno-38-1></a><span class=c1># y_true: 每个样本的真实类别，**必须为0(反例).1(正例)标记**</span>
<a id=__codelineno-38-2 name=__codelineno-38-2></a><span class=c1># 所以将y_test转换</span>
<a id=__codelineno-38-3 name=__codelineno-38-3></a><span class=n>y_true</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>where</span><span class=p>(</span><span class=n>y_test</span><span class=o>&gt;</span><span class=mi>3</span><span class=p>,</span><span class=mi>1</span><span class=p>,</span><span class=mi>0</span><span class=p>)</span>
<a id=__codelineno-38-4 name=__codelineno-38-4></a>
<a id=__codelineno-38-5 name=__codelineno-38-5></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.metrics</span><span class=w> </span><span class=kn>import</span> <span class=n>roc_auc_score</span>
<a id=__codelineno-38-6 name=__codelineno-38-6></a><span class=n>roc_auc_score</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div><p></p> <p>非常适合评价样本不均衡时的 </p> <h3 id=_82>模型的保存和加载<a class=headerlink href=#_82 title="Permanent link">¶</a></h3> <h4 id=sklearn_1>sklearn 中的<a class=headerlink href=#sklearn_1 title="Permanent link">¶</a></h4> <ul> <li>from sklearn.externals import joblib<ul> <li>保存: joblib.dump(rf, 'test.pkl')</li> <li>加载: estimator = joblib.load('test.pkl')</li> </ul> </li> </ul> <div class="admonition tip"> <p class=admonition-title>保存线性回归的模型</p> <p></p><div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-39-1>1</a></span>
<span class=normal><a href=#__codelineno-39-2>2</a></span>
<span class=normal><a href=#__codelineno-39-3>3</a></span>
<span class=normal><a href=#__codelineno-39-4>4</a></span>
<span class=normal><a href=#__codelineno-39-5>5</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-39-1 name=__codelineno-39-1></a><span class=c1># 4.预估器  </span>
<a id=__codelineno-39-2 name=__codelineno-39-2></a><span class=n>estimator</span><span class=o>=</span><span class=n>Ridge</span><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span><span class=n>alpha</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>  
<a id=__codelineno-39-3 name=__codelineno-39-3></a><span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>x_train</span><span class=p>,</span><span class=n>y_train</span><span class=p>)</span>  
<a id=__codelineno-39-4 name=__codelineno-39-4></a><span class=c1># 保存模型  </span>
<a id=__codelineno-39-5 name=__codelineno-39-5></a><span class=n>joblib</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>estimator</span><span class=p>,</span> <span class=s1>'my.pkl'</span><span class=p>)</span>  
</code></pre></div></td></tr></tbody></table></div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-40-1>1</a></span>
<span class=normal><a href=#__codelineno-40-2>2</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-40-1 name=__codelineno-40-1></a><span class=c1># 加载模型  </span>
<a id=__codelineno-40-2 name=__codelineno-40-2></a><span class=n>estimator</span> <span class=o>=</span> <span class=n>joblib</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>'my.pkl'</span><span class=p>)</span>  
</code></pre></div></td></tr></tbody></table></div><p></p> </div> <h3 id=-k-means>无监督学习-K-means 算法<a class=headerlink href=#-k-means title="Permanent link">¶</a></h3> <h4 id=_83>什么是无监督学习<a class=headerlink href=#_83 title="Permanent link">¶</a></h4> <p>看目标值：没有目标值的话就是无监督学习 </p> <h4 id=_84>包含的算法<a class=headerlink href=#_84 title="Permanent link">¶</a></h4> <ul> <li>聚类：<ul> <li>K-means（K 均值聚类）</li> </ul> </li> <li>降维<ul> <li>PCA</li> </ul> </li> </ul> <h4 id=k-means>K-means 原理<a class=headerlink href=#k-means title="Permanent link">¶</a></h4> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250909122920.png><img alt src=../png/Pasted%20image%2020250909122920.png></a><br> 实现上面将数据分为三类 </p> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250909122956.png><img alt src=../png/Pasted%20image%2020250909122956.png></a> </p> <div class="admonition tip"> <p class=admonition-title>步骤</p> <ol> <li>随机设置 k 个特征空间内的点作为初始的聚类中心<br> K：超参数 <ol> <li>看需求（分为几类） </li> <li>网格搜索，调节超参数 </li> </ol> </li> <li>对于其他的每个点计算到 k 个中心的距离，未知的点选择最近的聚类中心作为标记类别 </li> <li>接着对着标记的聚类，重新计算每个聚类的新中心点（平均值） </li> <li>如果计算得出的新中心点与原中心点一样，那么结束，否则重新进行第二步的步骤</li> </ol> </div> <p>中心点是怎么求的<br> <span class=arithmatex>\(A(a1,b1,c1)\)</span> <span class=arithmatex>\({B}(\)</span> a2, b2, c2)<br> <span class=arithmatex>\({Z}(\)</span>a26, b26, c26)<br> 中心点(a平均，b平均，c平均) </p> <h4 id=api_9>API<a class=headerlink href=#api_9 title="Permanent link">¶</a></h4> <ul> <li>sklearn.cluster.KMeans(n_clusters=8,init='k-means++')<ul> <li>k-means聚类</li> <li>n_clusters:开始的聚类中心数量 (就是 K 值)</li> <li>init:初始化方法，默认为'k-means++'</li> <li>labels_:默认标记的类型，可以和真实值比较（不是值比较）（可以查看标记的类型）</li> </ul> </li> </ul> <h4 id=instacart-market>案例：Instacart Market 用户聚类<a class=headerlink href=#instacart-market title="Permanent link">¶</a></h4> <p>分为三种（这个数据已经处理了） </p> <div class="admonition tip"> <p class=admonition-title>流程分析</p> <ol> <li>预估器流程 </li> <li>看结果 </li> <li>模型评估</li> </ol> </div> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-41-1>1</a></span>
<span class=normal><a href=#__codelineno-41-2>2</a></span>
<span class=normal><a href=#__codelineno-41-3>3</a></span>
<span class=normal><a href=#__codelineno-41-4>4</a></span>
<span class=normal><a href=#__codelineno-41-5>5</a></span>
<span class=normal><a href=#__codelineno-41-6>6</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-41-1 name=__codelineno-41-1></a><span class=c1># 预估器流程</span>
<a id=__codelineno-41-2 name=__codelineno-41-2></a><span class=kn>from</span><span class=w> </span><span class=nn>sklearn.cluster</span><span class=w> </span><span class=kn>import</span> <span class=n>KMeans</span>
<a id=__codelineno-41-3 name=__codelineno-41-3></a><span class=n>estimator</span><span class=o>=</span><span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
<a id=__codelineno-41-4 name=__codelineno-41-4></a><span class=n>estimator</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>data_new</span><span class=p>)</span>
<a id=__codelineno-41-5 name=__codelineno-41-5></a><span class=n>y_predict</span><span class=o>=</span><span class=n>estimator</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>data_new</span><span class=p>)</span>
<a id=__codelineno-41-6 name=__codelineno-41-6></a><span class=n>y_predict</span><span class=p>[:</span><span class=mi>300</span><span class=p>]</span>
</code></pre></div></td></tr></tbody></table></div> <h4 id=kmeans>Kmeans 性能评估的指标<a class=headerlink href=#kmeans title="Permanent link">¶</a></h4> <p><strong>轮廓系数</strong> </p> <div class=arithmatex>\[ sc_i=\frac{b_{i-}a_i}{\max(b_i,a_i)} \]</div> <blockquote> <p>对于每个点 i，为已经聚类数据中的样本，b_i 为 i 到<strong>其他的族群</strong>的所有样本距离的最小值，a_i 为到<strong>本身蔟的距离的平均值</strong>，最终计算出所有样本点的轮廓系数平均值 </p> </blockquote> <p><strong>轮廓系数分析</strong><br> <a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/Pasted%20image%2020250909180931.png><img alt src=../png/Pasted%20image%2020250909180931.png></a><br> 使得外部的距离（b_i）大，内部距离小 (a_i)<br> 取极限的情况时，分子为 b_i，分母为 a_i，此时的系数为 1，时最好的情况<br> 最差的情况为-1 </p> <div class="admonition tip"> <p class=admonition-title>结论</p> <p>介于[-1,1]，越接近 1 越好，越接近-1 越差</p> </div> <ul> <li>sklearn.metrics.silhouette_score(X, labels)<ul> <li>计算所有样本的平均轮廓系数</li> <li>X: <strong>特征值</strong></li> <li>labels: 被聚类标记的<strong>目标值</strong></li> </ul> </li> </ul> <div class=highlight><table class=highlighttable><tbody><tr><th class=filename colspan=2><span class=filename>Python</span></th></tr><tr><td class=linenos><div class=linenodiv><pre><span></span><span class=normal><a href=#__codelineno-42-1>1</a></span></pre></div></td><td class=code><div><pre><span></span><code><a id=__codelineno-42-1 name=__codelineno-42-1></a><span class=n>silhouette_score</span><span class=p>(</span><span class=n>data_new</span><span class=p>,</span><span class=n>y_predict</span><span class=p>)</span>
</code></pre></div></td></tr></tbody></table></div> <h4 id=_85>聚类的总结<a class=headerlink href=#_85 title="Permanent link">¶</a></h4> <ul> <li>特点：迭代算法，直观易懂</li> <li>缺点：容易收敛到局部最优解（开始的初始中心点挨在一起了）（可以使用多次聚类解决）</li> </ul> <p>聚类一般在<strong>分类之前</strong>，我们还是要分类的（最终的目标）<br> 就是给分类提供一个<strong>目标值</strong> </p> <p><strong>完结</strong>：前面有数据挖掘，后面有深度学习 </p> <p>猫咪 </p> <h3 id=_86>总结<a class=headerlink href=#_86 title="Permanent link">¶</a></h3> <p><a class=glightbox data-desc-position=bottom data-height=auto data-type=image data-width=auto href=../png/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%202.png><img alt src=../png/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%202.png></a><br> 💐💐💐</p> <aside class=md-source-file> <span class=md-source-file__fact> <span class=md-icon title=最后更新> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M21 13.1c-.1 0-.3.1-.4.2l-1 1 2.1 2.1 1-1c.2-.2.2-.6 0-.8l-1.3-1.3c-.1-.1-.2-.2-.4-.2m-1.9 1.8-6.1 6V23h2.1l6.1-6.1zM12.5 7v5.2l4 2.4-1 1L11 13V7zM11 21.9c-5.1-.5-9-4.8-9-9.9C2 6.5 6.5 2 12 2c5.3 0 9.6 4.1 10 9.3-.3-.1-.6-.2-1-.2s-.7.1-1 .2C19.6 7.2 16.2 4 12 4c-4.4 0-8 3.6-8 8 0 4.1 3.1 7.5 7.1 7.9l-.1.2z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="2025年9月9日 10:41:11 UTC">2025年9月9日</span> </span> <span class=md-source-file__fact> <span class=md-icon title=创建日期> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M14.47 15.08 11 13V7h1.5v5.25l3.08 1.83c-.41.28-.79.62-1.11 1m-1.39 4.84c-.36.05-.71.08-1.08.08-4.42 0-8-3.58-8-8s3.58-8 8-8 8 3.58 8 8c0 .37-.03.72-.08 1.08.69.1 1.33.32 1.92.64.1-.56.16-1.13.16-1.72 0-5.5-4.5-10-10-10S2 6.5 2 12s4.47 10 10 10c.59 0 1.16-.06 1.72-.16-.32-.59-.54-1.23-.64-1.92M18 15v3h-3v2h3v3h2v-3h3v-2h-3v-3z"></path></svg> </span> <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-date" title="2025年6月27日 08:37:23 UTC">2025年6月27日</span> </span> </aside> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> 回到页面顶部 </button> </main> <!-- Footer --> <footer class=md-footer> <!-- Link to previous and/or next page --> <nav class="md-footer__inner md-grid" aria-label=页脚> <!-- Link to previous page --> <a href=../../../%E5%A4%A7%E4%B8%89%E7%A7%8B%E5%86%AC/%E8%AE%BE%E8%AE%A1/%E8%AE%BE%E8%AE%A1/ class="md-footer__link md-footer__link--prev" aria-label="上一页: 前"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> 上一页 </span> <div class=md-ellipsis> 前 </div> </div> </a> <!-- Link to next page --> <a href=../%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/ class="md-footer__link md-footer__link--next" aria-label="下一页: 深度学习"> <div class=md-footer__title> <span class=md-footer__direction> 下一页 </span> <div class=md-ellipsis> 深度学习 </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg> </div> </a> </nav> <!-- Further information --> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> Made with <a href=https://squidfunk.github.io/mkdocs-material/ target=_blank rel=noopener> Material for MkDocs </a> </div> <font color=#B9B9B9> <div class=footer-visit-count style="display: flex; justify-content: center; align-items: center;"> 本站访问量：<script async src=//finicounter.eu.org/finicounter.js></script> <span id=finicount_views></span> &nbsp;|&nbsp; <footer> <a href="https://icp.gov.moe/?keyword=20230640" target=_blank>Brent050830号</a> </footer> </div> </font> <style>
        .footer-visit-count {
            height: fit-content;
            min-height: 55px; /* 根据实际情况调整此高度 */
        }
        </style> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <script id=__config type=application/json>{"base": "../../..", "features": ["announce.dismiss", "toc.follow", "content.action.edit", "navigation.tracking", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.tabs", "navigation.top", "navigation.footer", "search.suggest", "search.highlight", "search.share", "navigation.indexes", "content.tabs.link", "content.tooltips", "content.code.copy", "content.code.select", "content.action.edit", "content.action.view", "content.code.annotate"], "search": "../../../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}, "version": null}</script> <script src=../../../assets/javascripts/bundle.f55a23d4.min.js></script> <script src=../../../javascripts/katex.js></script> <script src=https://cdn.jsdelivr.net/npm/katex@latest/dist/katex.min.js></script> <script src=https://cdn.jsdelivr.net/npm/katex@latest/dist/contrib/auto-render.min.js></script> <script src=../../../javascripts/extra.js></script> <script src=../../../javascripts/custom.js></script> <script src=../../../javascripts/toc.js></script> <script id=init-glightbox>const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});
document$.subscribe(()=>{ lightbox.reload(); });
</script></body></html>